[
  {
    "domain": "data processing",
    "task": "Implement a time series resampler with custom aggregation functions",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to implement a time series resampler with custom aggregation functions for analyzing weekly sales data from hourly sales records.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom typing import Tuple\n\n\ndef load_sales_data(file_path: str) -> pd.DataFrame:\n    \"\"\"\n    Load sales data from a CSV file and parse the timestamp.\n    \n    Args:\n        file_path (str): The path to the CSV file containing sales data.\n    \n    Returns:\n        pd.DataFrame: A DataFrame containing the sales data with the timestamp set as the index.\n    \"\"\"\n    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n    df.set_index('timestamp', inplace=True)\n    return df\n\n\ndef aggregate_weekly_sales(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Resample the sales data to calculate weekly totals and average daily sales.\n    \n    Args:\n        df (pd.DataFrame): A DataFrame containing hourly sales data with a datetime index.\n    \n    Returns:\n        pd.DataFrame: A DataFrame containing the total sales and average daily sales for each week.\n    \"\"\"\n    weekly_sales = df.resample('W').agg(\n        total_sales=('sales', 'sum'),\n        average_daily_sales=('sales', lambda x: x.sum() / x.count())\n    )\n    return weekly_sales\n\n\ndef main(file_path: str) -> None:\n    \"\"\"\n    Main function to load sales data and aggregate it into weekly sales.\n    \n    Args:\n        file_path (str): The path to the CSV file containing sales data.\n    \"\"\"\n    sales_data = load_sales_data(file_path)\n    weekly_sales = aggregate_weekly_sales(sales_data)\n    print(weekly_sales)\n\n\nif __name__ == '__main__':\n    # Path to the CSV file containing sales data\n    file_path = 'sales_data.csv'\n    main(file_path)",
    "rejected_code": "import pandas as pd\n\ndf = pd.read_csv('sales_data.csv', parse_dates=['timestamp'])\ndf.set_index('timestamp', inplace=True)\n\nweekly_sales = df.resample('W').agg(total_sales=('sales', 'sum'), average_daily_sales=('sales', lambda x: x.sum() / x.count()))\nprint(weekly_sales)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.019230769230769232,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 52, in <module>\n  File \"<string>\", line 44, in main\n  File \"<string>\", line 15, in load_sales_data\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n    return mapping[engine](f, **self.options)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 161, in __init__\n    self._validate_parse_dates_presence(self.names)  # type: ignore[has-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py\", line 243, in _validate_parse_dates_presence\n    raise ValueError(\nValueError: Missing column provided to 'parse_dates': 'timestamp'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n    return mapping[engine](f, **self.options)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 161, in __init__\n    self._validate_parse_dates_presence(self.names)  # type: ignore[has-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py\", line 243, in _validate_parse_dates_presence\n    raise ValueError(\nValueError: Missing column provided to 'parse_dates': 'timestamp'"
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Implement a time series resampler with custom aggregation functions",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a Python class to implement a time series resampler with custom aggregation functions for analyzing weekly sales data from hourly sales records.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom typing import Tuple\n\n\ndef load_sales_data(file_path: str) -> pd.DataFrame:\n    \"\"\"\n    Load sales data from a CSV file and parse the timestamp.\n    \n    Args:\n        file_path (str): The path to the CSV file containing sales data.\n    \n    Returns:\n        pd.DataFrame: A DataFrame containing the sales data with the timestamp set as the index.\n    \"\"\"\n    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n    df.set_index('timestamp', inplace=True)\n    return df\n\n\ndef aggregate_weekly_sales(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Resample the sales data to calculate weekly totals and average daily sales.\n    \n    Args:\n        df (pd.DataFrame): A DataFrame containing hourly sales data with a datetime index.\n    \n    Returns:\n        pd.DataFrame: A DataFrame containing the total sales and average daily sales for each week.\n    \"\"\"\n    weekly_sales = df.resample('W').agg(\n        total_sales=('sales', 'sum'),\n        average_daily_sales=('sales', lambda x: x.sum() / x.count())\n    )\n    return weekly_sales\n\n\ndef main(file_path: str) -> None:\n    \"\"\"\n    Main function to load sales data and aggregate it into weekly sales.\n    \n    Args:\n        file_path (str): The path to the CSV file containing sales data.\n    \"\"\"\n    sales_data = load_sales_data(file_path)\n    weekly_sales = aggregate_weekly_sales(sales_data)\n    print(weekly_sales)\n\n\nif __name__ == '__main__':\n    # Path to the CSV file containing sales data\n    file_path = 'sales_data.csv'\n    main(file_path)",
    "rejected_code": "import pandas as pd\n\ndf = pd.read_csv('sales_data.csv', parse_dates=['timestamp'])\ndf.set_index('timestamp', inplace=True)\n\nweekly_sales = df.resample('W').agg(total_sales=('sales', 'sum'), average_daily_sales=('sales', lambda x: x.sum() / x.count()))\nprint(weekly_sales)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.019230769230769232,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 52, in <module>\n  File \"<string>\", line 44, in main\n  File \"<string>\", line 15, in load_sales_data\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n    return mapping[engine](f, **self.options)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 161, in __init__\n    self._validate_parse_dates_presence(self.names)  # type: ignore[has-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py\", line 243, in _validate_parse_dates_presence\n    raise ValueError(\nValueError: Missing column provided to 'parse_dates': 'timestamp'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n    return mapping[engine](f, **self.options)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 161, in __init__\n    self._validate_parse_dates_presence(self.names)  # type: ignore[has-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py\", line 243, in _validate_parse_dates_presence\n    raise ValueError(\nValueError: Missing column provided to 'parse_dates': 'timestamp'"
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Implement a time series resampler with custom aggregation functions",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python function that takes a file path as input and returns a DataFrame with weekly sales totals and average daily sales from hourly sales data.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom typing import Tuple\n\n\ndef load_sales_data(file_path: str) -> pd.DataFrame:\n    \"\"\"\n    Load sales data from a CSV file and parse the timestamp.\n    \n    Args:\n        file_path (str): The path to the CSV file containing sales data.\n    \n    Returns:\n        pd.DataFrame: A DataFrame containing the sales data with the timestamp set as the index.\n    \"\"\"\n    df = pd.read_csv(file_path, parse_dates=['timestamp'])\n    df.set_index('timestamp', inplace=True)\n    return df\n\n\ndef aggregate_weekly_sales(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Resample the sales data to calculate weekly totals and average daily sales.\n    \n    Args:\n        df (pd.DataFrame): A DataFrame containing hourly sales data with a datetime index.\n    \n    Returns:\n        pd.DataFrame: A DataFrame containing the total sales and average daily sales for each week.\n    \"\"\"\n    weekly_sales = df.resample('W').agg(\n        total_sales=('sales', 'sum'),\n        average_daily_sales=('sales', lambda x: x.sum() / x.count())\n    )\n    return weekly_sales\n\n\ndef main(file_path: str) -> None:\n    \"\"\"\n    Main function to load sales data and aggregate it into weekly sales.\n    \n    Args:\n        file_path (str): The path to the CSV file containing sales data.\n    \"\"\"\n    sales_data = load_sales_data(file_path)\n    weekly_sales = aggregate_weekly_sales(sales_data)\n    print(weekly_sales)\n\n\nif __name__ == '__main__':\n    # Path to the CSV file containing sales data\n    file_path = 'sales_data.csv'\n    main(file_path)",
    "rejected_code": "import pandas as pd\n\ndf = pd.read_csv('sales_data.csv', parse_dates=['timestamp'])\ndf.set_index('timestamp', inplace=True)\n\nweekly_sales = df.resample('W').agg(total_sales=('sales', 'sum'), average_daily_sales=('sales', lambda x: x.sum() / x.count()))\nprint(weekly_sales)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.019230769230769232,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 52, in <module>\n  File \"<string>\", line 44, in main\n  File \"<string>\", line 15, in load_sales_data\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n    return mapping[engine](f, **self.options)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 161, in __init__\n    self._validate_parse_dates_presence(self.names)  # type: ignore[has-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py\", line 243, in _validate_parse_dates_presence\n    raise ValueError(\nValueError: Missing column provided to 'parse_dates': 'timestamp'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n    return mapping[engine](f, **self.options)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 161, in __init__\n    self._validate_parse_dates_presence(self.names)  # type: ignore[has-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py\", line 243, in _validate_parse_dates_presence\n    raise ValueError(\nValueError: Missing column provided to 'parse_dates': 'timestamp'"
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Develop a dataset merger function with conflict resolution strategies",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to merge sales data from two branches with conflict resolution for overlapping records?",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas import DataFrame\n\n\ndef merge_datasets(branch1_data: DataFrame, branch2_data: DataFrame) -> DataFrame:\n    \"\"\"\n    Merges two sales datasets from different branches, resolving conflicts by retaining the maximum sales amount\n    for overlapping records.\n\n    Args:\n        branch1_data (DataFrame): The sales data from the first branch.\n        branch2_data (DataFrame): The sales data from the second branch.\n\n    Returns:\n        DataFrame: A DataFrame containing merged sales data with resolved conflicts.\n    \"\"\"\n    # Concatenate the two datasets into one\n    merged_data = pd.concat([branch1_data, branch2_data], ignore_index=True)\n    \n    # Group by 'date' and 'product_id' and aggregate to find the maximum sales amount\n    resolved_data = merged_data.groupby(['date', 'product_id'], as_index=False).agg({'sales_amount': 'max'})\n    \n    return resolved_data\n\n\n# Example usage:\nif __name__ == '__main__':\n    branch1 = pd.DataFrame({\n        'date': ['2021-01-01', '2021-01-02'],\n        'product_id': [1, 2],\n        'sales_amount': [100, 200]\n    })\n    branch2 = pd.DataFrame({\n        'date': ['2021-01-01', '2021-01-02'],\n        'product_id': [1, 2],\n        'sales_amount': [150, 180]\n    })\n    merged_result = merge_datasets(branch1, branch2)\n    print(merged_result)",
    "rejected_code": "import pandas as pd\n\ndef merge_datasets(branch1_data, branch2_data):\n    merged_data = pd.concat([branch1_data, branch2_data])\n    resolved_data = merged_data.groupby(['date', 'product_id'], as_index=False).agg({'sales_amount': 'max'})\n    return resolved_data\n\n# Example usage:\nbranch1 = pd.DataFrame({'date': ['2021-01-01', '2021-01-02'], 'product_id': [1, 2], 'sales_amount': [100, 200]})\nbranch2 = pd.DataFrame({'date': ['2021-01-01', '2021-01-02'], 'product_id': [1, 2], 'sales_amount': [150, 180]})\nmerged_result = merge_datasets(branch1, branch2)\nprint(merged_result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.07692307692307693,
      "execution_result": {
        "success": true,
        "output": "date  product_id  sales_amount\n0  2021-01-01           1           150\n1  2021-01-02           2           200",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.08333333333333333,
      "execution_result": {
        "success": true,
        "output": "date  product_id  sales_amount\n0  2021-01-01           1           150\n1  2021-01-02           2           200",
        "error": ""
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Develop a dataset merger function with conflict resolution strategies",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a function in Python that merges sales data from two branches, resolving conflicts in overlapping records.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas import DataFrame\n\n\ndef merge_datasets(branch1_data: DataFrame, branch2_data: DataFrame) -> DataFrame:\n    \"\"\"\n    Merges two sales datasets from different branches, resolving conflicts by retaining the maximum sales amount\n    for overlapping records.\n\n    Args:\n        branch1_data (DataFrame): The sales data from the first branch.\n        branch2_data (DataFrame): The sales data from the second branch.\n\n    Returns:\n        DataFrame: A DataFrame containing merged sales data with resolved conflicts.\n    \"\"\"\n    # Concatenate the two datasets into one\n    merged_data = pd.concat([branch1_data, branch2_data], ignore_index=True)\n    \n    # Group by 'date' and 'product_id' and aggregate to find the maximum sales amount\n    resolved_data = merged_data.groupby(['date', 'product_id'], as_index=False).agg({'sales_amount': 'max'})\n    \n    return resolved_data\n\n\n# Example usage:\nif __name__ == '__main__':\n    branch1 = pd.DataFrame({\n        'date': ['2021-01-01', '2021-01-02'],\n        'product_id': [1, 2],\n        'sales_amount': [100, 200]\n    })\n    branch2 = pd.DataFrame({\n        'date': ['2021-01-01', '2021-01-02'],\n        'product_id': [1, 2],\n        'sales_amount': [150, 180]\n    })\n    merged_result = merge_datasets(branch1, branch2)\n    print(merged_result)",
    "rejected_code": "import pandas as pd\n\ndef merge_datasets(branch1_data, branch2_data):\n    merged_data = pd.concat([branch1_data, branch2_data])\n    resolved_data = merged_data.groupby(['date', 'product_id'], as_index=False).agg({'sales_amount': 'max'})\n    return resolved_data\n\n# Example usage:\nbranch1 = pd.DataFrame({'date': ['2021-01-01', '2021-01-02'], 'product_id': [1, 2], 'sales_amount': [100, 200]})\nbranch2 = pd.DataFrame({'date': ['2021-01-01', '2021-01-02'], 'product_id': [1, 2], 'sales_amount': [150, 180]})\nmerged_result = merge_datasets(branch1, branch2)\nprint(merged_result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.07692307692307693,
      "execution_result": {
        "success": true,
        "output": "date  product_id  sales_amount\n0  2021-01-01           1           150\n1  2021-01-02           2           200",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.08333333333333333,
      "execution_result": {
        "success": true,
        "output": "date  product_id  sales_amount\n0  2021-01-01           1           150\n1  2021-01-02           2           200",
        "error": ""
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Develop a dataset merger function with conflict resolution strategies",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python function that takes two DataFrame inputs for sales data from two branches and returns a merged DataFrame with conflict resolution for overlapping records.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas import DataFrame\n\n\ndef merge_datasets(branch1_data: DataFrame, branch2_data: DataFrame) -> DataFrame:\n    \"\"\"\n    Merges two sales datasets from different branches, resolving conflicts by retaining the maximum sales amount\n    for overlapping records.\n\n    Args:\n        branch1_data (DataFrame): The sales data from the first branch.\n        branch2_data (DataFrame): The sales data from the second branch.\n\n    Returns:\n        DataFrame: A DataFrame containing merged sales data with resolved conflicts.\n    \"\"\"\n    # Concatenate the two datasets into one\n    merged_data = pd.concat([branch1_data, branch2_data], ignore_index=True)\n    \n    # Group by 'date' and 'product_id' and aggregate to find the maximum sales amount\n    resolved_data = merged_data.groupby(['date', 'product_id'], as_index=False).agg({'sales_amount': 'max'})\n    \n    return resolved_data\n\n\n# Example usage:\nif __name__ == '__main__':\n    branch1 = pd.DataFrame({\n        'date': ['2021-01-01', '2021-01-02'],\n        'product_id': [1, 2],\n        'sales_amount': [100, 200]\n    })\n    branch2 = pd.DataFrame({\n        'date': ['2021-01-01', '2021-01-02'],\n        'product_id': [1, 2],\n        'sales_amount': [150, 180]\n    })\n    merged_result = merge_datasets(branch1, branch2)\n    print(merged_result)",
    "rejected_code": "import pandas as pd\n\ndef merge_datasets(branch1_data, branch2_data):\n    merged_data = pd.concat([branch1_data, branch2_data])\n    resolved_data = merged_data.groupby(['date', 'product_id'], as_index=False).agg({'sales_amount': 'max'})\n    return resolved_data\n\n# Example usage:\nbranch1 = pd.DataFrame({'date': ['2021-01-01', '2021-01-02'], 'product_id': [1, 2], 'sales_amount': [100, 200]})\nbranch2 = pd.DataFrame({'date': ['2021-01-01', '2021-01-02'], 'product_id': [1, 2], 'sales_amount': [150, 180]})\nmerged_result = merge_datasets(branch1, branch2)\nprint(merged_result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.07692307692307693,
      "execution_result": {
        "success": true,
        "output": "date  product_id  sales_amount\n0  2021-01-01           1           150\n1  2021-01-02           2           200",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.08333333333333333,
      "execution_result": {
        "success": true,
        "output": "date  product_id  sales_amount\n0  2021-01-01           1           150\n1  2021-01-02           2           200",
        "error": ""
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Create a dataframe cleaner for handling missing values with customizable strategies",
    "code_form": "processor class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create a DataFrame cleaner for handling missing values with customizable strategies?",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas import DataFrame, Series\nfrom typing import Literal, Union\n\nclass DataFrameCleaner:\n    \"\"\"\n    A class to clean a DataFrame by handling missing values with customizable strategies.\n    \"\"\"\n\n    def __init__(self, df: DataFrame) -> None:\n        \"\"\"\n        Initializes the DataFrameCleaner with a DataFrame.\n        \n        :param df: The DataFrame to be cleaned.\n        \"\"\"\n        self.df = df\n\n    def fill_missing(self, column: str, strategy: Literal['mean', 'zero']) -> None:\n        \"\"\"\n        Fills missing values in the specified column using the provided strategy.\n        \n        :param column: The column name where missing values need to be filled.\n        :param strategy: The strategy to use for filling missing values ('mean' or 'zero').\n        \"\"\"\n        if strategy == 'mean':\n            self.df[column].fillna(self.df[column].mean(), inplace=True)\n        elif strategy == 'zero':\n            self.df[column].fillna(0, inplace=True)\n        else:\n            raise ValueError(\"Invalid strategy. Use 'mean' or 'zero'.\")\n\n    def drop_missing(self, column: str) -> None:\n        \"\"\"\n        Drops rows from the DataFrame where the specified column has missing values.\n        \n        :param column: The column name where rows with missing values will be dropped.\n        \"\"\"\n        self.df.dropna(subset=[column], inplace=True)\n\n    def clean(self) -> None:\n        \"\"\"\n        Cleans the DataFrame by applying the fill and drop strategies for missing values.\n        \"\"\"\n        self.fill_missing('price', 'mean')\n        self.fill_missing('quantity', 'zero')\n        self.drop_missing('customer_id')\n\n# Example usage\nif __name__ == '__main__':\n    sales_data = pd.DataFrame({\n        'customer_id': [1, 2, None, 4],\n        'price': [10.0, None, 15.0, 20.0],\n        'quantity': [1, None, 2, 3]\n    })\n    cleaner = DataFrameCleaner(sales_data)\n    cleaner.clean()\n    print(cleaner.df)",
    "rejected_code": "import pandas as pd\n\nclass DataFrameCleaner:\n    def __init__(self, df):\n        self.df = df\n\n    def fill_missing(self, column, strategy):\n        if strategy == 'mean':\n            self.df[column].fillna(self.df[column].mean(), inplace=True)\n        elif strategy == 'zero':\n            self.df[column].fillna(0, inplace=True)\n\n    def drop_missing(self, column):\n        self.df.dropna(subset=[column], inplace=True)\n\n    def clean(self):\n        self.fill_missing('price', 'mean')\n        self.fill_missing('quantity', 'zero')\n        self.drop_missing('customer_id')\n\n# Example usage\nsales_data = pd.DataFrame({\n    'customer_id': [1, 2, None, 4],\n    'price': [10.0, None, 15.0, 20.0],\n    'quantity': [1, None, 2, 3]\n})\ncleaner = DataFrameCleaner(sales_data)\ncleaner.clean()\nprint(cleaner.df)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.017543859649122806,
      "execution_result": {
        "success": true,
        "output": "customer_id  price  quantity\n0          1.0   10.0       1.0\n1          2.0   15.0       0.0\n3          4.0   20.0       3.0",
        "error": "<string>:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n<string>:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object."
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.034482758620689655,
      "execution_result": {
        "success": true,
        "output": "customer_id  price  quantity\n0          1.0   10.0       1.0\n1          2.0   15.0       0.0\n3          4.0   20.0       3.0",
        "error": "<string>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n<string>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object."
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Create a dataframe cleaner for handling missing values with customizable strategies",
    "code_form": "processor class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python class to create a DataFrame cleaner for handling missing values with customizable strategies.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas import DataFrame, Series\nfrom typing import Literal, Union\n\nclass DataFrameCleaner:\n    \"\"\"\n    A class to clean a DataFrame by handling missing values with customizable strategies.\n    \"\"\"\n\n    def __init__(self, df: DataFrame) -> None:\n        \"\"\"\n        Initializes the DataFrameCleaner with a DataFrame.\n        \n        :param df: The DataFrame to be cleaned.\n        \"\"\"\n        self.df = df\n\n    def fill_missing(self, column: str, strategy: Literal['mean', 'zero']) -> None:\n        \"\"\"\n        Fills missing values in the specified column using the provided strategy.\n        \n        :param column: The column name where missing values need to be filled.\n        :param strategy: The strategy to use for filling missing values ('mean' or 'zero').\n        \"\"\"\n        if strategy == 'mean':\n            self.df[column].fillna(self.df[column].mean(), inplace=True)\n        elif strategy == 'zero':\n            self.df[column].fillna(0, inplace=True)\n        else:\n            raise ValueError(\"Invalid strategy. Use 'mean' or 'zero'.\")\n\n    def drop_missing(self, column: str) -> None:\n        \"\"\"\n        Drops rows from the DataFrame where the specified column has missing values.\n        \n        :param column: The column name where rows with missing values will be dropped.\n        \"\"\"\n        self.df.dropna(subset=[column], inplace=True)\n\n    def clean(self) -> None:\n        \"\"\"\n        Cleans the DataFrame by applying the fill and drop strategies for missing values.\n        \"\"\"\n        self.fill_missing('price', 'mean')\n        self.fill_missing('quantity', 'zero')\n        self.drop_missing('customer_id')\n\n# Example usage\nif __name__ == '__main__':\n    sales_data = pd.DataFrame({\n        'customer_id': [1, 2, None, 4],\n        'price': [10.0, None, 15.0, 20.0],\n        'quantity': [1, None, 2, 3]\n    })\n    cleaner = DataFrameCleaner(sales_data)\n    cleaner.clean()\n    print(cleaner.df)",
    "rejected_code": "import pandas as pd\n\nclass DataFrameCleaner:\n    def __init__(self, df):\n        self.df = df\n\n    def fill_missing(self, column, strategy):\n        if strategy == 'mean':\n            self.df[column].fillna(self.df[column].mean(), inplace=True)\n        elif strategy == 'zero':\n            self.df[column].fillna(0, inplace=True)\n\n    def drop_missing(self, column):\n        self.df.dropna(subset=[column], inplace=True)\n\n    def clean(self):\n        self.fill_missing('price', 'mean')\n        self.fill_missing('quantity', 'zero')\n        self.drop_missing('customer_id')\n\n# Example usage\nsales_data = pd.DataFrame({\n    'customer_id': [1, 2, None, 4],\n    'price': [10.0, None, 15.0, 20.0],\n    'quantity': [1, None, 2, 3]\n})\ncleaner = DataFrameCleaner(sales_data)\ncleaner.clean()\nprint(cleaner.df)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.017543859649122806,
      "execution_result": {
        "success": true,
        "output": "customer_id  price  quantity\n0          1.0   10.0       1.0\n1          2.0   15.0       0.0\n3          4.0   20.0       3.0",
        "error": "<string>:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n<string>:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object."
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.034482758620689655,
      "execution_result": {
        "success": true,
        "output": "customer_id  price  quantity\n0          1.0   10.0       1.0\n1          2.0   15.0       0.0\n3          4.0   20.0       3.0",
        "error": "<string>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n<string>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object."
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Create a dataframe cleaner for handling missing values with customizable strategies",
    "code_form": "processor class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python class that implements a DataFrame cleaner for handling missing values, specifying input as a DataFrame and output as a cleaned DataFrame.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas import DataFrame, Series\nfrom typing import Literal, Union\n\nclass DataFrameCleaner:\n    \"\"\"\n    A class to clean a DataFrame by handling missing values with customizable strategies.\n    \"\"\"\n\n    def __init__(self, df: DataFrame) -> None:\n        \"\"\"\n        Initializes the DataFrameCleaner with a DataFrame.\n        \n        :param df: The DataFrame to be cleaned.\n        \"\"\"\n        self.df = df\n\n    def fill_missing(self, column: str, strategy: Literal['mean', 'zero']) -> None:\n        \"\"\"\n        Fills missing values in the specified column using the provided strategy.\n        \n        :param column: The column name where missing values need to be filled.\n        :param strategy: The strategy to use for filling missing values ('mean' or 'zero').\n        \"\"\"\n        if strategy == 'mean':\n            self.df[column].fillna(self.df[column].mean(), inplace=True)\n        elif strategy == 'zero':\n            self.df[column].fillna(0, inplace=True)\n        else:\n            raise ValueError(\"Invalid strategy. Use 'mean' or 'zero'.\")\n\n    def drop_missing(self, column: str) -> None:\n        \"\"\"\n        Drops rows from the DataFrame where the specified column has missing values.\n        \n        :param column: The column name where rows with missing values will be dropped.\n        \"\"\"\n        self.df.dropna(subset=[column], inplace=True)\n\n    def clean(self) -> None:\n        \"\"\"\n        Cleans the DataFrame by applying the fill and drop strategies for missing values.\n        \"\"\"\n        self.fill_missing('price', 'mean')\n        self.fill_missing('quantity', 'zero')\n        self.drop_missing('customer_id')\n\n# Example usage\nif __name__ == '__main__':\n    sales_data = pd.DataFrame({\n        'customer_id': [1, 2, None, 4],\n        'price': [10.0, None, 15.0, 20.0],\n        'quantity': [1, None, 2, 3]\n    })\n    cleaner = DataFrameCleaner(sales_data)\n    cleaner.clean()\n    print(cleaner.df)",
    "rejected_code": "import pandas as pd\n\nclass DataFrameCleaner:\n    def __init__(self, df):\n        self.df = df\n\n    def fill_missing(self, column, strategy):\n        if strategy == 'mean':\n            self.df[column].fillna(self.df[column].mean(), inplace=True)\n        elif strategy == 'zero':\n            self.df[column].fillna(0, inplace=True)\n\n    def drop_missing(self, column):\n        self.df.dropna(subset=[column], inplace=True)\n\n    def clean(self):\n        self.fill_missing('price', 'mean')\n        self.fill_missing('quantity', 'zero')\n        self.drop_missing('customer_id')\n\n# Example usage\nsales_data = pd.DataFrame({\n    'customer_id': [1, 2, None, 4],\n    'price': [10.0, None, 15.0, 20.0],\n    'quantity': [1, None, 2, 3]\n})\ncleaner = DataFrameCleaner(sales_data)\ncleaner.clean()\nprint(cleaner.df)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.017543859649122806,
      "execution_result": {
        "success": true,
        "output": "customer_id  price  quantity\n0          1.0   10.0       1.0\n1          2.0   15.0       0.0\n3          4.0   20.0       3.0",
        "error": "<string>:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n<string>:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object."
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.034482758620689655,
      "execution_result": {
        "success": true,
        "output": "customer_id  price  quantity\n0          1.0   10.0       1.0\n1          2.0   15.0       0.0\n3          4.0   20.0       3.0",
        "error": "<string>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n<string>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object."
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Build a named entity recognition system with custom entity types",
    "code_form": "processor class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide a Python code example to build a named entity recognition system for categorizing customer reviews into custom entity types like 'Book Title', 'Author Name', and 'Genre'?",
      "role": "user"
    },
    "chosen_code": "import spacy\nfrom spacy.matcher import Matcher\nfrom typing import List, Tuple\n\nclass CustomNERProcessor:\n    \"\"\"\n    A class to process text and extract custom named entities such as Book Titles,\n    Author Names, and Genres from customer reviews.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the NER processor with a blank English NLP model and sets up\n        the matcher with defined patterns for custom entities.\n        \"\"\"\n        self.nlp = spacy.blank('en')\n        self.matcher = Matcher(self.nlp.vocab)\n        self._create_patterns()\n\n    def _create_patterns(self) -> None:\n        \"\"\"\n        Defines patterns for matching custom entities. Patterns include:\n        - Book Titles (preceded by 'the')\n        - Author Names (two proper nouns)\n        - Genres (specific combinations of keywords)\n        \"\"\"\n        patterns = [\n            [{'LOWER': 'the'}, {'POS': 'PROPN'}],  # Book Title\n            [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # Author Name\n            [{'LOWER': 'fiction'}, {'LOWER': 'drama'}],  # Genre\n        ]\n        self.matcher.add('CUSTOM_ENTITIES', patterns)\n\n    def process_text(self, text: str) -> List[Tuple[str, str]]:\n        \"\"\"\n        Processes the input text to extract custom entities.\n\n        Args:\n            text (str): The input text from which to extract entities.\n\n        Returns:\n            List[Tuple[str, str]]: A list of tuples containing the entity text and its label.\n        \"\"\"\n        doc = self.nlp(text)\n        matches = self.matcher(doc)\n        entities = []\n        for match_id, start, end in matches:\n            span = doc[start:end]\n            entities.append((span.text, span.label_))\n        return entities\n\n# Sample reviews to process\nreviews: List[str] = [\n    'I loved The Great Gatsby by F. Scott Fitzgerald. It is a classic fiction drama.',\n    'Harry Potter by J.K. Rowling is my favorite fantasy fiction.',\n]\n\n# Create an instance of the CustomNERProcessor\nprocessor = CustomNERProcessor()\n\n# Process each review and print the extracted entities\nfor review in reviews:\n    entities = processor.process_text(review)\n    print(entities)",
    "rejected_code": "import spacy\nfrom spacy.matcher import Matcher\n\nclass CustomNERProcessor:\n    def __init__(self):\n        self.nlp = spacy.blank('en')\n        self.matcher = Matcher(self.nlp.vocab)\n        self._create_patterns()\n\n    def _create_patterns(self):\n        patterns = [\n            [{'LOWER': 'the'}, {'POS': 'PROPN'}],  # Book Title\n            [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # Author Name\n            [{'LOWER': 'fiction'}, {'LOWER': 'drama'}],  # Genre\n        ]\n        self.matcher.add('CUSTOM_ENTITIES', patterns)\n\n    def process_text(self, text):\n        doc = self.nlp(text)\n        matches = self.matcher(doc)\n        entities = []\n        for match_id, start, end in matches:\n            span = doc[start:end]\n            entities.append((span.text, span.label_))\n        return entities\n\nreviews = [\n    'I loved The Great Gatsby by F. Scott Fitzgerald. It is a classic fiction drama.',\n    'Harry Potter by J.K. Rowling is my favorite fantasy fiction.',\n]\n\nprocessor = CustomNERProcessor()\nfor review in reviews:\n    entities = processor.process_text(review)\n    print(entities)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.046875,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'spacy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'spacy'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Build a named entity recognition system with custom entity types",
    "code_form": "processor class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class in Python that implements a named entity recognition system for categorizing customer reviews into custom entity types such as 'Book Title', 'Author Name', and 'Genre'.",
      "role": "user"
    },
    "chosen_code": "import spacy\nfrom spacy.matcher import Matcher\nfrom typing import List, Tuple\n\nclass CustomNERProcessor:\n    \"\"\"\n    A class to process text and extract custom named entities such as Book Titles,\n    Author Names, and Genres from customer reviews.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the NER processor with a blank English NLP model and sets up\n        the matcher with defined patterns for custom entities.\n        \"\"\"\n        self.nlp = spacy.blank('en')\n        self.matcher = Matcher(self.nlp.vocab)\n        self._create_patterns()\n\n    def _create_patterns(self) -> None:\n        \"\"\"\n        Defines patterns for matching custom entities. Patterns include:\n        - Book Titles (preceded by 'the')\n        - Author Names (two proper nouns)\n        - Genres (specific combinations of keywords)\n        \"\"\"\n        patterns = [\n            [{'LOWER': 'the'}, {'POS': 'PROPN'}],  # Book Title\n            [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # Author Name\n            [{'LOWER': 'fiction'}, {'LOWER': 'drama'}],  # Genre\n        ]\n        self.matcher.add('CUSTOM_ENTITIES', patterns)\n\n    def process_text(self, text: str) -> List[Tuple[str, str]]:\n        \"\"\"\n        Processes the input text to extract custom entities.\n\n        Args:\n            text (str): The input text from which to extract entities.\n\n        Returns:\n            List[Tuple[str, str]]: A list of tuples containing the entity text and its label.\n        \"\"\"\n        doc = self.nlp(text)\n        matches = self.matcher(doc)\n        entities = []\n        for match_id, start, end in matches:\n            span = doc[start:end]\n            entities.append((span.text, span.label_))\n        return entities\n\n# Sample reviews to process\nreviews: List[str] = [\n    'I loved The Great Gatsby by F. Scott Fitzgerald. It is a classic fiction drama.',\n    'Harry Potter by J.K. Rowling is my favorite fantasy fiction.',\n]\n\n# Create an instance of the CustomNERProcessor\nprocessor = CustomNERProcessor()\n\n# Process each review and print the extracted entities\nfor review in reviews:\n    entities = processor.process_text(review)\n    print(entities)",
    "rejected_code": "import spacy\nfrom spacy.matcher import Matcher\n\nclass CustomNERProcessor:\n    def __init__(self):\n        self.nlp = spacy.blank('en')\n        self.matcher = Matcher(self.nlp.vocab)\n        self._create_patterns()\n\n    def _create_patterns(self):\n        patterns = [\n            [{'LOWER': 'the'}, {'POS': 'PROPN'}],  # Book Title\n            [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # Author Name\n            [{'LOWER': 'fiction'}, {'LOWER': 'drama'}],  # Genre\n        ]\n        self.matcher.add('CUSTOM_ENTITIES', patterns)\n\n    def process_text(self, text):\n        doc = self.nlp(text)\n        matches = self.matcher(doc)\n        entities = []\n        for match_id, start, end in matches:\n            span = doc[start:end]\n            entities.append((span.text, span.label_))\n        return entities\n\nreviews = [\n    'I loved The Great Gatsby by F. Scott Fitzgerald. It is a classic fiction drama.',\n    'Harry Potter by J.K. Rowling is my favorite fantasy fiction.',\n]\n\nprocessor = CustomNERProcessor()\nfor review in reviews:\n    entities = processor.process_text(review)\n    print(entities)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.046875,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'spacy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'spacy'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Build a named entity recognition system with custom entity types",
    "code_form": "processor class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you create a Python class that takes a string input representing customer reviews and outputs a list of tuples, where each tuple contains a custom entity and its type? The entities should include 'Book Title', 'Author Name', and 'Genre'.",
      "role": "user"
    },
    "chosen_code": "import spacy\nfrom spacy.matcher import Matcher\nfrom typing import List, Tuple\n\nclass CustomNERProcessor:\n    \"\"\"\n    A class to process text and extract custom named entities such as Book Titles,\n    Author Names, and Genres from customer reviews.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the NER processor with a blank English NLP model and sets up\n        the matcher with defined patterns for custom entities.\n        \"\"\"\n        self.nlp = spacy.blank('en')\n        self.matcher = Matcher(self.nlp.vocab)\n        self._create_patterns()\n\n    def _create_patterns(self) -> None:\n        \"\"\"\n        Defines patterns for matching custom entities. Patterns include:\n        - Book Titles (preceded by 'the')\n        - Author Names (two proper nouns)\n        - Genres (specific combinations of keywords)\n        \"\"\"\n        patterns = [\n            [{'LOWER': 'the'}, {'POS': 'PROPN'}],  # Book Title\n            [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # Author Name\n            [{'LOWER': 'fiction'}, {'LOWER': 'drama'}],  # Genre\n        ]\n        self.matcher.add('CUSTOM_ENTITIES', patterns)\n\n    def process_text(self, text: str) -> List[Tuple[str, str]]:\n        \"\"\"\n        Processes the input text to extract custom entities.\n\n        Args:\n            text (str): The input text from which to extract entities.\n\n        Returns:\n            List[Tuple[str, str]]: A list of tuples containing the entity text and its label.\n        \"\"\"\n        doc = self.nlp(text)\n        matches = self.matcher(doc)\n        entities = []\n        for match_id, start, end in matches:\n            span = doc[start:end]\n            entities.append((span.text, span.label_))\n        return entities\n\n# Sample reviews to process\nreviews: List[str] = [\n    'I loved The Great Gatsby by F. Scott Fitzgerald. It is a classic fiction drama.',\n    'Harry Potter by J.K. Rowling is my favorite fantasy fiction.',\n]\n\n# Create an instance of the CustomNERProcessor\nprocessor = CustomNERProcessor()\n\n# Process each review and print the extracted entities\nfor review in reviews:\n    entities = processor.process_text(review)\n    print(entities)",
    "rejected_code": "import spacy\nfrom spacy.matcher import Matcher\n\nclass CustomNERProcessor:\n    def __init__(self):\n        self.nlp = spacy.blank('en')\n        self.matcher = Matcher(self.nlp.vocab)\n        self._create_patterns()\n\n    def _create_patterns(self):\n        patterns = [\n            [{'LOWER': 'the'}, {'POS': 'PROPN'}],  # Book Title\n            [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # Author Name\n            [{'LOWER': 'fiction'}, {'LOWER': 'drama'}],  # Genre\n        ]\n        self.matcher.add('CUSTOM_ENTITIES', patterns)\n\n    def process_text(self, text):\n        doc = self.nlp(text)\n        matches = self.matcher(doc)\n        entities = []\n        for match_id, start, end in matches:\n            span = doc[start:end]\n            entities.append((span.text, span.label_))\n        return entities\n\nreviews = [\n    'I loved The Great Gatsby by F. Scott Fitzgerald. It is a classic fiction drama.',\n    'Harry Potter by J.K. Rowling is my favorite fantasy fiction.',\n]\n\nprocessor = CustomNERProcessor()\nfor review in reviews:\n    entities = processor.process_text(review)\n    print(entities)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.046875,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'spacy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'spacy'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Implement a text summarization function with length control",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to implement a text summarization function that allows for length control.",
      "role": "user"
    },
    "chosen_code": "from gensim.summarization import summarize\nfrom typing import Union\n\n\ndef summarize_text(text: str, num_sentences: int) -> str:\n    \"\"\"\n    Summarizes the given text while controlling the length of the summary by the number of sentences.\n\n    Args:\n        text (str): The text to be summarized.\n        num_sentences (int): The desired number of sentences in the summary.\n\n    Returns:\n        str: A summary of the text containing the specified number of sentences.\n    \"\"\"\n    # Split the text into sentences based on period and space.\n    sentences = text.split('. ')\n    # Determine the actual number of sentences to include in the summary.\n    length = min(num_sentences, len(sentences))\n    # Generate a summary using Gensim's summarize function, controlling length by word count.\n    summary = summarize(text, word_count=100)  # This may not always guarantee the exact sentence count.\n    # Return the summary limited to the specified number of sentences.\n    return '. '.join(summary.split('. ')[:length])\n\n\nif __name__ == '__main__':\n    # Example article to summarize.\n    article = \"The quick brown fox jumps over the lazy dog. The lazy dog, however, is not as lazy as it seems. It quickly pounces back and chases the fox around the field. This unexpected turn of events surprises everyone in the park. The fox, realizing it is outmatched, runs away to safety.\"\n    # Desired length of the summary in terms of sentences.\n    desired_length = 2\n    # Generate the summary.\n    summary = summarize_text(article, desired_length)\n    # Print the generated summary.\n    print(summary)",
    "rejected_code": "from gensim.summarization import summarize\n\ndef summarize_text(text, num_sentences):\n    sentences = text.split('. ')\n    length = min(num_sentences, len(sentences))\n    summary = summarize(text, word_count=100)  # Roughly control length by word count\n    return '. '.join(summary.split('. ')[:length])\n\narticle = \"The quick brown fox jumps over the lazy dog. The lazy dog, however, is not as lazy as it seems. It quickly pounces back and chases the fox around the field. This unexpected turn of events surprises everyone in the park. The fox, realizing it is outmatched, runs away to safety.\"  \ndesired_length = 2\nsummary = summarize_text(article, desired_length)\nprint(summary)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.23529411764705882,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'gensim'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'gensim'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Implement a text summarization function with length control",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Could you write a function to perform text summarization with length control?",
      "role": "user"
    },
    "chosen_code": "from gensim.summarization import summarize\nfrom typing import Union\n\n\ndef summarize_text(text: str, num_sentences: int) -> str:\n    \"\"\"\n    Summarizes the given text while controlling the length of the summary by the number of sentences.\n\n    Args:\n        text (str): The text to be summarized.\n        num_sentences (int): The desired number of sentences in the summary.\n\n    Returns:\n        str: A summary of the text containing the specified number of sentences.\n    \"\"\"\n    # Split the text into sentences based on period and space.\n    sentences = text.split('. ')\n    # Determine the actual number of sentences to include in the summary.\n    length = min(num_sentences, len(sentences))\n    # Generate a summary using Gensim's summarize function, controlling length by word count.\n    summary = summarize(text, word_count=100)  # This may not always guarantee the exact sentence count.\n    # Return the summary limited to the specified number of sentences.\n    return '. '.join(summary.split('. ')[:length])\n\n\nif __name__ == '__main__':\n    # Example article to summarize.\n    article = \"The quick brown fox jumps over the lazy dog. The lazy dog, however, is not as lazy as it seems. It quickly pounces back and chases the fox around the field. This unexpected turn of events surprises everyone in the park. The fox, realizing it is outmatched, runs away to safety.\"\n    # Desired length of the summary in terms of sentences.\n    desired_length = 2\n    # Generate the summary.\n    summary = summarize_text(article, desired_length)\n    # Print the generated summary.\n    print(summary)",
    "rejected_code": "from gensim.summarization import summarize\n\ndef summarize_text(text, num_sentences):\n    sentences = text.split('. ')\n    length = min(num_sentences, len(sentences))\n    summary = summarize(text, word_count=100)  # Roughly control length by word count\n    return '. '.join(summary.split('. ')[:length])\n\narticle = \"The quick brown fox jumps over the lazy dog. The lazy dog, however, is not as lazy as it seems. It quickly pounces back and chases the fox around the field. This unexpected turn of events surprises everyone in the park. The fox, realizing it is outmatched, runs away to safety.\"  \ndesired_length = 2\nsummary = summarize_text(article, desired_length)\nprint(summary)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.23529411764705882,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'gensim'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'gensim'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Implement a text summarization function with length control",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you create a function that takes a string and an integer as input and returns a string summary with controlled sentence length?",
      "role": "user"
    },
    "chosen_code": "from gensim.summarization import summarize\nfrom typing import Union\n\n\ndef summarize_text(text: str, num_sentences: int) -> str:\n    \"\"\"\n    Summarizes the given text while controlling the length of the summary by the number of sentences.\n\n    Args:\n        text (str): The text to be summarized.\n        num_sentences (int): The desired number of sentences in the summary.\n\n    Returns:\n        str: A summary of the text containing the specified number of sentences.\n    \"\"\"\n    # Split the text into sentences based on period and space.\n    sentences = text.split('. ')\n    # Determine the actual number of sentences to include in the summary.\n    length = min(num_sentences, len(sentences))\n    # Generate a summary using Gensim's summarize function, controlling length by word count.\n    summary = summarize(text, word_count=100)  # This may not always guarantee the exact sentence count.\n    # Return the summary limited to the specified number of sentences.\n    return '. '.join(summary.split('. ')[:length])\n\n\nif __name__ == '__main__':\n    # Example article to summarize.\n    article = \"The quick brown fox jumps over the lazy dog. The lazy dog, however, is not as lazy as it seems. It quickly pounces back and chases the fox around the field. This unexpected turn of events surprises everyone in the park. The fox, realizing it is outmatched, runs away to safety.\"\n    # Desired length of the summary in terms of sentences.\n    desired_length = 2\n    # Generate the summary.\n    summary = summarize_text(article, desired_length)\n    # Print the generated summary.\n    print(summary)",
    "rejected_code": "from gensim.summarization import summarize\n\ndef summarize_text(text, num_sentences):\n    sentences = text.split('. ')\n    length = min(num_sentences, len(sentences))\n    summary = summarize(text, word_count=100)  # Roughly control length by word count\n    return '. '.join(summary.split('. ')[:length])\n\narticle = \"The quick brown fox jumps over the lazy dog. The lazy dog, however, is not as lazy as it seems. It quickly pounces back and chases the fox around the field. This unexpected turn of events surprises everyone in the park. The fox, realizing it is outmatched, runs away to safety.\"  \ndesired_length = 2\nsummary = summarize_text(article, desired_length)\nprint(summary)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.23529411764705882,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'gensim'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'gensim'"
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Build a data validation pipeline with schema enforcement",
    "code_form": "validator class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to build a data validation pipeline with schema enforcement for sales data.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas.errors import EmptyDataError\nfrom datetime import datetime\nfrom typing import Dict, Callable, Any\n\nclass DataValidator:\n    \"\"\"\n    A class to validate a DataFrame against a predefined schema.\n    The schema defines the expected data types for each column.\n    \"\"\"\n\n    def __init__(self, schema: Dict[str, str]) -> None:\n        \"\"\"\n        Initializes the DataValidator with a schema.\n\n        :param schema: A dictionary where keys are column names and values are expected data types.\n        \"\"\"\n        self.schema = schema\n\n    def validate(self, df: pd.DataFrame) -> bool:\n        \"\"\"\n        Validates the DataFrame against the schema.\n\n        :param df: The DataFrame to validate.\n        :raises ValueError: If any column is missing or contains invalid data.\n        :return: True if validation succeeds.\n        \"\"\"\n        for column, dtype in self.schema.items():\n            if column not in df.columns:\n                raise ValueError(f'Missing column: {column}')\n            if not all(df[column].apply(self.check_dtype(dtype))):\n                raise ValueError(f'Invalid data in column: {column}')\n        return True\n\n    def check_dtype(self, dtype: str) -> Callable[[Any], bool]:\n        \"\"\"\n        Returns a function that checks if a value matches the expected data type.\n\n        :param dtype: The expected data type as a string.\n        :return: A function that checks the type of a value.\n        \"\"\"\n        if dtype == 'date':\n            return lambda x: isinstance(x, str) and self.is_valid_date(x)\n        elif dtype == 'store_id':\n            return lambda x: isinstance(x, int)\n        elif dtype == 'sales_amount':\n            return lambda x: isinstance(x, float)\n        else:\n            raise ValueError(f'Unknown data type: {dtype}')\n\n    def is_valid_date(self, date_str: str) -> bool:\n        \"\"\"\n        Checks if the given string is a valid date in YYYY-MM-DD format.\n\n        :param date_str: The date string to validate.\n        :return: True if the date is valid, False otherwise.\n        \"\"\"\n        try:\n            datetime.strptime(date_str, '%Y-%m-%d')\n            return True\n        except ValueError:\n            return False\n\n\nschema: Dict[str, str] = {'date': 'date', 'store_id': 'store_id', 'sales_amount': 'sales_amount'}\nvalidator = DataValidator(schema)\n\ntry:\n    df: pd.DataFrame = pd.read_csv('sales_data.csv')\n    validator.validate(df)\n    print('Data is valid')\nexcept (ValueError, EmptyDataError) as e:\n    print(e)",
    "rejected_code": "import pandas as pd\nfrom pandas.errors import EmptyDataError\nfrom datetime import datetime\n\nclass DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, df):\n        for column, dtype in self.schema.items():\n            if column not in df.columns:\n                raise ValueError(f'Missing column: {column}')\n            if not all(df[column].apply(self.check_dtype(dtype))):\n                raise ValueError(f'Invalid data in column: {column}')\n        return True\n\n    def check_dtype(self, dtype):\n        if dtype == 'date':\n            return lambda x: isinstance(x, str) and self.is_valid_date(x)\n        elif dtype == 'store_id':\n            return lambda x: isinstance(x, int)\n        elif dtype == 'sales_amount':\n            return lambda x: isinstance(x, float)\n\n    def is_valid_date(self, date_str):\n        try:\n            datetime.strptime(date_str, '%Y-%m-%d')\n            return True\n        except ValueError:\n            return False\n\nschema = {'date': 'date', 'store_id': 'store_id', 'sales_amount': 'sales_amount'}\nvalidator = DataValidator(schema)\n\ntry:\n    df = pd.read_csv('sales_data.csv')\n    validator.validate(df)\n    print('Data is valid')\nexcept (ValueError, EmptyDataError) as e:\n    print(e)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Missing column: date",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Missing column: date",
        "error": ""
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Build a data validation pipeline with schema enforcement",
    "code_form": "validator class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a Python class that builds a data validation pipeline with schema enforcement for sales data.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas.errors import EmptyDataError\nfrom datetime import datetime\nfrom typing import Dict, Callable, Any\n\nclass DataValidator:\n    \"\"\"\n    A class to validate a DataFrame against a predefined schema.\n    The schema defines the expected data types for each column.\n    \"\"\"\n\n    def __init__(self, schema: Dict[str, str]) -> None:\n        \"\"\"\n        Initializes the DataValidator with a schema.\n\n        :param schema: A dictionary where keys are column names and values are expected data types.\n        \"\"\"\n        self.schema = schema\n\n    def validate(self, df: pd.DataFrame) -> bool:\n        \"\"\"\n        Validates the DataFrame against the schema.\n\n        :param df: The DataFrame to validate.\n        :raises ValueError: If any column is missing or contains invalid data.\n        :return: True if validation succeeds.\n        \"\"\"\n        for column, dtype in self.schema.items():\n            if column not in df.columns:\n                raise ValueError(f'Missing column: {column}')\n            if not all(df[column].apply(self.check_dtype(dtype))):\n                raise ValueError(f'Invalid data in column: {column}')\n        return True\n\n    def check_dtype(self, dtype: str) -> Callable[[Any], bool]:\n        \"\"\"\n        Returns a function that checks if a value matches the expected data type.\n\n        :param dtype: The expected data type as a string.\n        :return: A function that checks the type of a value.\n        \"\"\"\n        if dtype == 'date':\n            return lambda x: isinstance(x, str) and self.is_valid_date(x)\n        elif dtype == 'store_id':\n            return lambda x: isinstance(x, int)\n        elif dtype == 'sales_amount':\n            return lambda x: isinstance(x, float)\n        else:\n            raise ValueError(f'Unknown data type: {dtype}')\n\n    def is_valid_date(self, date_str: str) -> bool:\n        \"\"\"\n        Checks if the given string is a valid date in YYYY-MM-DD format.\n\n        :param date_str: The date string to validate.\n        :return: True if the date is valid, False otherwise.\n        \"\"\"\n        try:\n            datetime.strptime(date_str, '%Y-%m-%d')\n            return True\n        except ValueError:\n            return False\n\n\nschema: Dict[str, str] = {'date': 'date', 'store_id': 'store_id', 'sales_amount': 'sales_amount'}\nvalidator = DataValidator(schema)\n\ntry:\n    df: pd.DataFrame = pd.read_csv('sales_data.csv')\n    validator.validate(df)\n    print('Data is valid')\nexcept (ValueError, EmptyDataError) as e:\n    print(e)",
    "rejected_code": "import pandas as pd\nfrom pandas.errors import EmptyDataError\nfrom datetime import datetime\n\nclass DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, df):\n        for column, dtype in self.schema.items():\n            if column not in df.columns:\n                raise ValueError(f'Missing column: {column}')\n            if not all(df[column].apply(self.check_dtype(dtype))):\n                raise ValueError(f'Invalid data in column: {column}')\n        return True\n\n    def check_dtype(self, dtype):\n        if dtype == 'date':\n            return lambda x: isinstance(x, str) and self.is_valid_date(x)\n        elif dtype == 'store_id':\n            return lambda x: isinstance(x, int)\n        elif dtype == 'sales_amount':\n            return lambda x: isinstance(x, float)\n\n    def is_valid_date(self, date_str):\n        try:\n            datetime.strptime(date_str, '%Y-%m-%d')\n            return True\n        except ValueError:\n            return False\n\nschema = {'date': 'date', 'store_id': 'store_id', 'sales_amount': 'sales_amount'}\nvalidator = DataValidator(schema)\n\ntry:\n    df = pd.read_csv('sales_data.csv')\n    validator.validate(df)\n    print('Data is valid')\nexcept (ValueError, EmptyDataError) as e:\n    print(e)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Missing column: date",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Missing column: date",
        "error": ""
      }
    }
  },
  {
    "domain": "data processing",
    "task": "Build a data validation pipeline with schema enforcement",
    "code_form": "validator class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a Python class that builds a data validation pipeline with schema enforcement for sales data, ensuring to include type annotations for inputs and outputs.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nfrom pandas.errors import EmptyDataError\nfrom datetime import datetime\nfrom typing import Dict, Callable, Any\n\nclass DataValidator:\n    \"\"\"\n    A class to validate a DataFrame against a predefined schema.\n    The schema defines the expected data types for each column.\n    \"\"\"\n\n    def __init__(self, schema: Dict[str, str]) -> None:\n        \"\"\"\n        Initializes the DataValidator with a schema.\n\n        :param schema: A dictionary where keys are column names and values are expected data types.\n        \"\"\"\n        self.schema = schema\n\n    def validate(self, df: pd.DataFrame) -> bool:\n        \"\"\"\n        Validates the DataFrame against the schema.\n\n        :param df: The DataFrame to validate.\n        :raises ValueError: If any column is missing or contains invalid data.\n        :return: True if validation succeeds.\n        \"\"\"\n        for column, dtype in self.schema.items():\n            if column not in df.columns:\n                raise ValueError(f'Missing column: {column}')\n            if not all(df[column].apply(self.check_dtype(dtype))):\n                raise ValueError(f'Invalid data in column: {column}')\n        return True\n\n    def check_dtype(self, dtype: str) -> Callable[[Any], bool]:\n        \"\"\"\n        Returns a function that checks if a value matches the expected data type.\n\n        :param dtype: The expected data type as a string.\n        :return: A function that checks the type of a value.\n        \"\"\"\n        if dtype == 'date':\n            return lambda x: isinstance(x, str) and self.is_valid_date(x)\n        elif dtype == 'store_id':\n            return lambda x: isinstance(x, int)\n        elif dtype == 'sales_amount':\n            return lambda x: isinstance(x, float)\n        else:\n            raise ValueError(f'Unknown data type: {dtype}')\n\n    def is_valid_date(self, date_str: str) -> bool:\n        \"\"\"\n        Checks if the given string is a valid date in YYYY-MM-DD format.\n\n        :param date_str: The date string to validate.\n        :return: True if the date is valid, False otherwise.\n        \"\"\"\n        try:\n            datetime.strptime(date_str, '%Y-%m-%d')\n            return True\n        except ValueError:\n            return False\n\n\nschema: Dict[str, str] = {'date': 'date', 'store_id': 'store_id', 'sales_amount': 'sales_amount'}\nvalidator = DataValidator(schema)\n\ntry:\n    df: pd.DataFrame = pd.read_csv('sales_data.csv')\n    validator.validate(df)\n    print('Data is valid')\nexcept (ValueError, EmptyDataError) as e:\n    print(e)",
    "rejected_code": "import pandas as pd\nfrom pandas.errors import EmptyDataError\nfrom datetime import datetime\n\nclass DataValidator:\n    def __init__(self, schema):\n        self.schema = schema\n\n    def validate(self, df):\n        for column, dtype in self.schema.items():\n            if column not in df.columns:\n                raise ValueError(f'Missing column: {column}')\n            if not all(df[column].apply(self.check_dtype(dtype))):\n                raise ValueError(f'Invalid data in column: {column}')\n        return True\n\n    def check_dtype(self, dtype):\n        if dtype == 'date':\n            return lambda x: isinstance(x, str) and self.is_valid_date(x)\n        elif dtype == 'store_id':\n            return lambda x: isinstance(x, int)\n        elif dtype == 'sales_amount':\n            return lambda x: isinstance(x, float)\n\n    def is_valid_date(self, date_str):\n        try:\n            datetime.strptime(date_str, '%Y-%m-%d')\n            return True\n        except ValueError:\n            return False\n\nschema = {'date': 'date', 'store_id': 'store_id', 'sales_amount': 'sales_amount'}\nvalidator = DataValidator(schema)\n\ntry:\n    df = pd.read_csv('sales_data.csv')\n    validator.validate(df)\n    print('Data is valid')\nexcept (ValueError, EmptyDataError) as e:\n    print(e)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Missing column: date",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Missing column: date",
        "error": ""
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Create a sentiment analysis class with multiple algorithm options",
    "code_form": "analyzer class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to create a sentiment analysis tool that uses multiple algorithms.",
      "role": "user"
    },
    "chosen_code": "from nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\nfrom typing import Union, List\n\nclass SentimentAnalyzer:\n    \"\"\"\n    A class to perform sentiment analysis on text using different algorithms.\n    Supported methods: 'textblob' and 'vader'.\n    \"\"\"\n\n    def __init__(self, method: str = 'textblob') -> None:\n        \"\"\"\n        Initializes the SentimentAnalyzer with a specified method.\n\n        Args:\n            method (str): The algorithm to use for sentiment analysis. Default is 'textblob'.\n\n        Raises:\n            ValueError: If an unsupported method is provided.\n        \"\"\"\n        self.method = method.lower()\n        if self.method == 'vader':\n            self.analyzer = SentimentIntensityAnalyzer()\n        elif self.method != 'textblob':\n            raise ValueError(f\"Unsupported method: {self.method}. Use 'textblob' or 'vader'.\")\n\n    def analyze(self, text: str) -> float:\n        \"\"\"\n        Analyzes the sentiment of the given text using the selected method.\n\n        Args:\n            text (str): The text to analyze.\n\n        Returns:\n            float: The sentiment score of the text, ranging from -1 (negative) to 1 (positive).\n        \"\"\"\n        if self.method == 'textblob':\n            return TextBlob(text).sentiment.polarity\n        elif self.method == 'vader':\n            return self.analyzer.polarity_scores(text)['compound']\n\n# Example Usage\nif __name__ == '__main__':\n    feedbacks: List[str] = [\n        \"The food was amazing and the service was excellent!\",\n        \"I had a terrible experience, the wait was too long.\"\n    ]\n\n    # Create an instance of SentimentAnalyzer using the VADER method\n    analyzer = SentimentAnalyzer(method='vader')\n    for feedback in feedbacks:\n        score = analyzer.analyze(feedback)\n        print(f'Feedback: {feedback} | Sentiment Score: {score}')",
    "rejected_code": "from nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\n\nclass SentimentAnalyzer:\n    def __init__(self, method='textblob'):\n        self.method = method\n        if method == 'vader':\n            self.analyzer = SentimentIntensityAnalyzer()\n\n    def analyze(self, text):\n        if self.method == 'textblob':\n            return TextBlob(text).sentiment.polarity\n        elif self.method == 'vader':\n            return self.analyzer.polarity_scores(text)['compound']\n\n# Example Usage\nfeedbacks = [\n    \"The food was amazing and the service was excellent!\",\n    \"I had a terrible experience, the wait was too long.\"\n]\n\nfor feedback in feedbacks:\n    analyzer = SentimentAnalyzer(method='vader')\n    score = analyzer.analyze(feedback)\n    print(f'Feedback: {feedback} | Sentiment Score: {score}')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.03773584905660377,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.04,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Create a sentiment analysis class with multiple algorithm options",
    "code_form": "analyzer class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a Python class that implements a sentiment analysis tool using multiple algorithms.",
      "role": "user"
    },
    "chosen_code": "from nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\nfrom typing import Union, List\n\nclass SentimentAnalyzer:\n    \"\"\"\n    A class to perform sentiment analysis on text using different algorithms.\n    Supported methods: 'textblob' and 'vader'.\n    \"\"\"\n\n    def __init__(self, method: str = 'textblob') -> None:\n        \"\"\"\n        Initializes the SentimentAnalyzer with a specified method.\n\n        Args:\n            method (str): The algorithm to use for sentiment analysis. Default is 'textblob'.\n\n        Raises:\n            ValueError: If an unsupported method is provided.\n        \"\"\"\n        self.method = method.lower()\n        if self.method == 'vader':\n            self.analyzer = SentimentIntensityAnalyzer()\n        elif self.method != 'textblob':\n            raise ValueError(f\"Unsupported method: {self.method}. Use 'textblob' or 'vader'.\")\n\n    def analyze(self, text: str) -> float:\n        \"\"\"\n        Analyzes the sentiment of the given text using the selected method.\n\n        Args:\n            text (str): The text to analyze.\n\n        Returns:\n            float: The sentiment score of the text, ranging from -1 (negative) to 1 (positive).\n        \"\"\"\n        if self.method == 'textblob':\n            return TextBlob(text).sentiment.polarity\n        elif self.method == 'vader':\n            return self.analyzer.polarity_scores(text)['compound']\n\n# Example Usage\nif __name__ == '__main__':\n    feedbacks: List[str] = [\n        \"The food was amazing and the service was excellent!\",\n        \"I had a terrible experience, the wait was too long.\"\n    ]\n\n    # Create an instance of SentimentAnalyzer using the VADER method\n    analyzer = SentimentAnalyzer(method='vader')\n    for feedback in feedbacks:\n        score = analyzer.analyze(feedback)\n        print(f'Feedback: {feedback} | Sentiment Score: {score}')",
    "rejected_code": "from nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\n\nclass SentimentAnalyzer:\n    def __init__(self, method='textblob'):\n        self.method = method\n        if method == 'vader':\n            self.analyzer = SentimentIntensityAnalyzer()\n\n    def analyze(self, text):\n        if self.method == 'textblob':\n            return TextBlob(text).sentiment.polarity\n        elif self.method == 'vader':\n            return self.analyzer.polarity_scores(text)['compound']\n\n# Example Usage\nfeedbacks = [\n    \"The food was amazing and the service was excellent!\",\n    \"I had a terrible experience, the wait was too long.\"\n]\n\nfor feedback in feedbacks:\n    analyzer = SentimentAnalyzer(method='vader')\n    score = analyzer.analyze(feedback)\n    print(f'Feedback: {feedback} | Sentiment Score: {score}')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.03773584905660377,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.04,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Create a sentiment analysis class with multiple algorithm options",
    "code_form": "analyzer class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a Python class for sentiment analysis that takes a string input and returns a float output, supporting multiple algorithms.",
      "role": "user"
    },
    "chosen_code": "from nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\nfrom typing import Union, List\n\nclass SentimentAnalyzer:\n    \"\"\"\n    A class to perform sentiment analysis on text using different algorithms.\n    Supported methods: 'textblob' and 'vader'.\n    \"\"\"\n\n    def __init__(self, method: str = 'textblob') -> None:\n        \"\"\"\n        Initializes the SentimentAnalyzer with a specified method.\n\n        Args:\n            method (str): The algorithm to use for sentiment analysis. Default is 'textblob'.\n\n        Raises:\n            ValueError: If an unsupported method is provided.\n        \"\"\"\n        self.method = method.lower()\n        if self.method == 'vader':\n            self.analyzer = SentimentIntensityAnalyzer()\n        elif self.method != 'textblob':\n            raise ValueError(f\"Unsupported method: {self.method}. Use 'textblob' or 'vader'.\")\n\n    def analyze(self, text: str) -> float:\n        \"\"\"\n        Analyzes the sentiment of the given text using the selected method.\n\n        Args:\n            text (str): The text to analyze.\n\n        Returns:\n            float: The sentiment score of the text, ranging from -1 (negative) to 1 (positive).\n        \"\"\"\n        if self.method == 'textblob':\n            return TextBlob(text).sentiment.polarity\n        elif self.method == 'vader':\n            return self.analyzer.polarity_scores(text)['compound']\n\n# Example Usage\nif __name__ == '__main__':\n    feedbacks: List[str] = [\n        \"The food was amazing and the service was excellent!\",\n        \"I had a terrible experience, the wait was too long.\"\n    ]\n\n    # Create an instance of SentimentAnalyzer using the VADER method\n    analyzer = SentimentAnalyzer(method='vader')\n    for feedback in feedbacks:\n        score = analyzer.analyze(feedback)\n        print(f'Feedback: {feedback} | Sentiment Score: {score}')",
    "rejected_code": "from nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\n\nclass SentimentAnalyzer:\n    def __init__(self, method='textblob'):\n        self.method = method\n        if method == 'vader':\n            self.analyzer = SentimentIntensityAnalyzer()\n\n    def analyze(self, text):\n        if self.method == 'textblob':\n            return TextBlob(text).sentiment.polarity\n        elif self.method == 'vader':\n            return self.analyzer.polarity_scores(text)['compound']\n\n# Example Usage\nfeedbacks = [\n    \"The food was amazing and the service was excellent!\",\n    \"I had a terrible experience, the wait was too long.\"\n]\n\nfor feedback in feedbacks:\n    analyzer = SentimentAnalyzer(method='vader')\n    score = analyzer.analyze(feedback)\n    print(f'Feedback: {feedback} | Sentiment Score: {score}')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.03773584905660377,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.04,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Develop a text normalization function with configurable steps",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide a Python code example for a text normalization function with configurable steps?",
      "role": "user"
    },
    "chosen_code": "import re\nfrom typing import Optional\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\n\n# Ensure required NLTK resources are downloaded\nnltk.download('punkt')\nnltk.download('wordnet')\n\nclass TextNormalizer:\n    \"\"\"\n    A class to normalize text by applying configurable preprocessing steps.\n    The normalization can include converting to lowercase, removing special\n    characters, and lemmatization based on user preferences.\n    \"\"\"\n\n    def __init__(self, lower: bool = True, remove_special: bool = True, lemmatize: bool = False) -> None:\n        \"\"\"\n        Initialize the TextNormalizer with specified options.\n        \n        :param lower: If True, convert text to lowercase.\n        :param remove_special: If True, remove special characters from the text.\n        :param lemmatize: If True, apply lemmatization to the words.\n        \"\"\"\n        self.lower = lower\n        self.remove_special = remove_special\n        self.lemmatize = lemmatize\n        self.lemmatizer = WordNetLemmatizer()\n\n    def normalize(self, text: str) -> str:\n        \"\"\"\n        Normalize the input text based on the configured options.\n        \n        :param text: The input text to normalize.\n        :return: The normalized text as a string.\n        \"\"\"\n        if self.lower:\n            text = text.lower()\n        if self.remove_special:\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        words = word_tokenize(text)\n        if self.lemmatize:\n            words = [self.lemmatizer.lemmatize(word) for word in words]\n        return ' '.join(words)\n\n# Example usage of the TextNormalizer class\nif __name__ == '__main__':\n    normalizer = TextNormalizer(lower=True, remove_special=True, lemmatize=True)\n    text = \"I love programming! It's fun and exciting!\"\n    normalized_text = normalizer.normalize(text)\n    print(normalized_text)",
    "rejected_code": "import re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nnltk.download('punkt')\nnltk.download('wordnet')\n\nclass TextNormalizer:\n    def __init__(self, lower=True, remove_special=True, lemmatize=False):\n        self.lower = lower\n        self.remove_special = remove_special\n        self.lemmatize = lemmatize\n        self.lemmatizer = WordNetLemmatizer()\n\n    def normalize(self, text):\n        if self.lower:\n            text = text.lower()\n        if self.remove_special:\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        words = word_tokenize(text)\n        if self.lemmatize:\n            words = [self.lemmatizer.lemmatize(word) for word in words]\n        return ' '.join(words)\n\nnormalizer = TextNormalizer(lower=True, remove_special=True, lemmatize=True)\ntext = \"I love programming! It's fun and exciting!\"\nnormalized_text = normalizer.normalize(text)\nprint(normalized_text)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.038461538461538464,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Develop a text normalization function with configurable steps",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you provide a Python class for a text normalization function with configurable steps?",
      "role": "user"
    },
    "chosen_code": "import re\nfrom typing import Optional\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\n\n# Ensure required NLTK resources are downloaded\nnltk.download('punkt')\nnltk.download('wordnet')\n\nclass TextNormalizer:\n    \"\"\"\n    A class to normalize text by applying configurable preprocessing steps.\n    The normalization can include converting to lowercase, removing special\n    characters, and lemmatization based on user preferences.\n    \"\"\"\n\n    def __init__(self, lower: bool = True, remove_special: bool = True, lemmatize: bool = False) -> None:\n        \"\"\"\n        Initialize the TextNormalizer with specified options.\n        \n        :param lower: If True, convert text to lowercase.\n        :param remove_special: If True, remove special characters from the text.\n        :param lemmatize: If True, apply lemmatization to the words.\n        \"\"\"\n        self.lower = lower\n        self.remove_special = remove_special\n        self.lemmatize = lemmatize\n        self.lemmatizer = WordNetLemmatizer()\n\n    def normalize(self, text: str) -> str:\n        \"\"\"\n        Normalize the input text based on the configured options.\n        \n        :param text: The input text to normalize.\n        :return: The normalized text as a string.\n        \"\"\"\n        if self.lower:\n            text = text.lower()\n        if self.remove_special:\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        words = word_tokenize(text)\n        if self.lemmatize:\n            words = [self.lemmatizer.lemmatize(word) for word in words]\n        return ' '.join(words)\n\n# Example usage of the TextNormalizer class\nif __name__ == '__main__':\n    normalizer = TextNormalizer(lower=True, remove_special=True, lemmatize=True)\n    text = \"I love programming! It's fun and exciting!\"\n    normalized_text = normalizer.normalize(text)\n    print(normalized_text)",
    "rejected_code": "import re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nnltk.download('punkt')\nnltk.download('wordnet')\n\nclass TextNormalizer:\n    def __init__(self, lower=True, remove_special=True, lemmatize=False):\n        self.lower = lower\n        self.remove_special = remove_special\n        self.lemmatize = lemmatize\n        self.lemmatizer = WordNetLemmatizer()\n\n    def normalize(self, text):\n        if self.lower:\n            text = text.lower()\n        if self.remove_special:\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        words = word_tokenize(text)\n        if self.lemmatize:\n            words = [self.lemmatizer.lemmatize(word) for word in words]\n        return ' '.join(words)\n\nnormalizer = TextNormalizer(lower=True, remove_special=True, lemmatize=True)\ntext = \"I love programming! It's fun and exciting!\"\nnormalized_text = normalizer.normalize(text)\nprint(normalized_text)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.038461538461538464,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    }
  },
  {
    "domain": "text processing",
    "task": "Develop a text normalization function with configurable steps",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you provide a Python class with a method for a text normalization function that takes a string as input and returns a string, with configurable steps?",
      "role": "user"
    },
    "chosen_code": "import re\nfrom typing import Optional\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\n\n# Ensure required NLTK resources are downloaded\nnltk.download('punkt')\nnltk.download('wordnet')\n\nclass TextNormalizer:\n    \"\"\"\n    A class to normalize text by applying configurable preprocessing steps.\n    The normalization can include converting to lowercase, removing special\n    characters, and lemmatization based on user preferences.\n    \"\"\"\n\n    def __init__(self, lower: bool = True, remove_special: bool = True, lemmatize: bool = False) -> None:\n        \"\"\"\n        Initialize the TextNormalizer with specified options.\n        \n        :param lower: If True, convert text to lowercase.\n        :param remove_special: If True, remove special characters from the text.\n        :param lemmatize: If True, apply lemmatization to the words.\n        \"\"\"\n        self.lower = lower\n        self.remove_special = remove_special\n        self.lemmatize = lemmatize\n        self.lemmatizer = WordNetLemmatizer()\n\n    def normalize(self, text: str) -> str:\n        \"\"\"\n        Normalize the input text based on the configured options.\n        \n        :param text: The input text to normalize.\n        :return: The normalized text as a string.\n        \"\"\"\n        if self.lower:\n            text = text.lower()\n        if self.remove_special:\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        words = word_tokenize(text)\n        if self.lemmatize:\n            words = [self.lemmatizer.lemmatize(word) for word in words]\n        return ' '.join(words)\n\n# Example usage of the TextNormalizer class\nif __name__ == '__main__':\n    normalizer = TextNormalizer(lower=True, remove_special=True, lemmatize=True)\n    text = \"I love programming! It's fun and exciting!\"\n    normalized_text = normalizer.normalize(text)\n    print(normalized_text)",
    "rejected_code": "import re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nnltk.download('punkt')\nnltk.download('wordnet')\n\nclass TextNormalizer:\n    def __init__(self, lower=True, remove_special=True, lemmatize=False):\n        self.lower = lower\n        self.remove_special = remove_special\n        self.lemmatize = lemmatize\n        self.lemmatizer = WordNetLemmatizer()\n\n    def normalize(self, text):\n        if self.lower:\n            text = text.lower()\n        if self.remove_special:\n            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        words = word_tokenize(text)\n        if self.lemmatize:\n            words = [self.lemmatizer.lemmatize(word) for word in words]\n        return ' '.join(words)\n\nnormalizer = TextNormalizer(lower=True, remove_special=True, lemmatize=True)\ntext = \"I love programming! It's fun and exciting!\"\nnormalized_text = normalizer.normalize(text)\nprint(normalized_text)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.038461538461538464,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.3333333333333335,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'nltk'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Develop an API client function with automatic retries",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide a Python code example that creates an API client function with automatic retries for fetching available time slots?",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom typing import Optional, Any\n\n\ndef fetch_available_slots(api_url: str) -> Optional[Any]:\n    \"\"\"\n    Fetch available time slots from the specified API URL.\n\n    This function attempts to retrieve the available slots by sending a GET request to the provided\n    API URL. It will automatically retry the request up to three times in case of server errors\n    or network issues.\n\n    Args:\n        api_url (str): The URL of the API endpoint to fetch available slots.\n\n    Returns:\n        Optional[Any]: A JSON response containing available time slots if the request is successful,\n        or None if the request fails after retries.\n    \"\"\"\n    retries: int = 3  # Number of retry attempts\n\n    for attempt in range(retries):\n        try:\n            response = requests.get(api_url)\n            response.raise_for_status()  # Raise an error for bad responses (4xx and 5xx)\n            return response.json()  # Return the JSON response if successful\n\n        except RequestException as e:\n            # Log the exception if needed (logging can be added here)\n            if attempt < retries - 1:\n                continue  # Retry on network or server errors\n            else:\n                # Log final failure if needed\n                return None  # Return None after exhausting retries",
    "rejected_code": "import requests\n\ndef fetch_available_slots(api_url):\n    retries = 3\n    for i in range(retries):\n        response = requests.get(api_url)\n        if response.status_code == 200:\n            return response.json()\n        if response.status_code in [500, 502, 503, 504]:\n            continue\n    return None",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.05714285714285714,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "web development",
    "task": "Develop an API client function with automatic retries",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python function that implements an API client with automatic retries for fetching available time slots.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom typing import Optional, Any\n\n\ndef fetch_available_slots(api_url: str) -> Optional[Any]:\n    \"\"\"\n    Fetch available time slots from the specified API URL.\n\n    This function attempts to retrieve the available slots by sending a GET request to the provided\n    API URL. It will automatically retry the request up to three times in case of server errors\n    or network issues.\n\n    Args:\n        api_url (str): The URL of the API endpoint to fetch available slots.\n\n    Returns:\n        Optional[Any]: A JSON response containing available time slots if the request is successful,\n        or None if the request fails after retries.\n    \"\"\"\n    retries: int = 3  # Number of retry attempts\n\n    for attempt in range(retries):\n        try:\n            response = requests.get(api_url)\n            response.raise_for_status()  # Raise an error for bad responses (4xx and 5xx)\n            return response.json()  # Return the JSON response if successful\n\n        except RequestException as e:\n            # Log the exception if needed (logging can be added here)\n            if attempt < retries - 1:\n                continue  # Retry on network or server errors\n            else:\n                # Log final failure if needed\n                return None  # Return None after exhausting retries",
    "rejected_code": "import requests\n\ndef fetch_available_slots(api_url):\n    retries = 3\n    for i in range(retries):\n        response = requests.get(api_url)\n        if response.status_code == 200:\n            return response.json()\n        if response.status_code in [500, 502, 503, 504]:\n            continue\n    return None",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.05714285714285714,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "web development",
    "task": "Develop an API client function with automatic retries",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python function that takes a string input for the API URL and returns either JSON data or None, implementing automatic retries for fetching available time slots.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom typing import Optional, Any\n\n\ndef fetch_available_slots(api_url: str) -> Optional[Any]:\n    \"\"\"\n    Fetch available time slots from the specified API URL.\n\n    This function attempts to retrieve the available slots by sending a GET request to the provided\n    API URL. It will automatically retry the request up to three times in case of server errors\n    or network issues.\n\n    Args:\n        api_url (str): The URL of the API endpoint to fetch available slots.\n\n    Returns:\n        Optional[Any]: A JSON response containing available time slots if the request is successful,\n        or None if the request fails after retries.\n    \"\"\"\n    retries: int = 3  # Number of retry attempts\n\n    for attempt in range(retries):\n        try:\n            response = requests.get(api_url)\n            response.raise_for_status()  # Raise an error for bad responses (4xx and 5xx)\n            return response.json()  # Return the JSON response if successful\n\n        except RequestException as e:\n            # Log the exception if needed (logging can be added here)\n            if attempt < retries - 1:\n                continue  # Retry on network or server errors\n            else:\n                # Log final failure if needed\n                return None  # Return None after exhausting retries",
    "rejected_code": "import requests\n\ndef fetch_available_slots(api_url):\n    retries = 3\n    for i in range(retries):\n        response = requests.get(api_url)\n        if response.status_code == 200:\n            return response.json()\n        if response.status_code in [500, 502, 503, 504]:\n            continue\n    return None",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.05714285714285714,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "web development",
    "task": "Build a request validation class with customizable rule sets",
    "code_form": "validator class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to build a request validation class with customizable rule sets for a web application that handles user account creation.",
      "role": "user"
    },
    "chosen_code": "from flask import Flask, request, jsonify\nfrom typing import Callable, Dict, Any\n\napp = Flask(__name__)\n\nclass Validator:\n    \"\"\"\n    A class to validate input data against customizable rules.\n    \"\"\"\n\n    def __init__(self, rules: Dict[str, Callable[[Any], bool]]) -> None:\n        \"\"\"\n        Initializes the Validator with a set of rules.\n\n        Args:\n            rules (Dict[str, Callable[[Any], bool]]): A dictionary where keys are field names and values are validation functions.\n        \"\"\"\n        self.rules = rules\n\n    def validate(self, data: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"\n        Validates the provided data against the rules.\n\n        Args:\n            data (Dict[str, Any]): The data to validate.\n\n        Returns:\n            Dict[str, str]: A dictionary of errors, if any.\n        \"\"\"\n        errors = {}\n        for field, rule in self.rules.items():\n            if field not in data:\n                errors[field] = 'This field is required.'\n            elif not rule(data[field]):\n                errors[field] = 'Invalid value.'\n        return errors\n\ndef validate_username(username: str) -> bool:\n    \"\"\"\n    Validates the username.\n\n    Args:\n        username (str): The username to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return len(username) >= 3\n\n\ndef validate_password(password: str) -> bool:\n    \"\"\"\n    Validates the password.\n\n    Args:\n        password (str): The password to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return len(password) >= 6\n\n\ndef validate_email(email: str) -> bool:\n    \"\"\"\n    Validates the email address.\n\n    Args:\n        email (str): The email to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return '@' in email\n\n@app.route('/register', methods=['POST'])\ndef register() -> Any:\n    \"\"\"\n    Handles user registration by validating input data.\n\n    Returns:\n        Any: A JSON response indicating success or error.\n    \"\"\"\n    data = request.json\n    rules = {\n        'username': validate_username,\n        'password': validate_password,\n        'email': validate_email,\n    }\n    validator = Validator(rules)\n    errors = validator.validate(data)\n    if errors:\n        return jsonify(errors), 400\n    return jsonify({'message': 'User registered successfully!'}), 201\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "rejected_code": "from flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\nclass Validator:\n    def __init__(self, rules):\n        self.rules = rules\n\n    def validate(self, data):\n        errors = {}\n        for field, rule in self.rules.items():\n            if field not in data:\n                errors[field] = 'This field is required.'\n            elif not rule(data[field]):\n                errors[field] = 'Invalid value.'\n        return errors\n\ndef validate_username(username):\n    return len(username) >= 3\n\ndef validate_password(password):\n    return len(password) >= 6\n\ndef validate_email(email):\n    return '@' in email\n\n@app.route('/register', methods=['POST'])\ndef register():\n    data = request.json\n    rules = {\n        'username': validate_username,\n        'password': validate_password,\n        'email': validate_email,\n    }\n    validator = Validator(rules)\n    errors = validator.validate(data)\n    if errors:\n        return jsonify(errors), 400\n    return jsonify({'message': 'User registered successfully!'}), 201\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Build a request validation class with customizable rule sets",
    "code_form": "validator class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a Python class that implements a request validation system with customizable rules for validating user input in a web application?",
      "role": "user"
    },
    "chosen_code": "from flask import Flask, request, jsonify\nfrom typing import Callable, Dict, Any\n\napp = Flask(__name__)\n\nclass Validator:\n    \"\"\"\n    A class to validate input data against customizable rules.\n    \"\"\"\n\n    def __init__(self, rules: Dict[str, Callable[[Any], bool]]) -> None:\n        \"\"\"\n        Initializes the Validator with a set of rules.\n\n        Args:\n            rules (Dict[str, Callable[[Any], bool]]): A dictionary where keys are field names and values are validation functions.\n        \"\"\"\n        self.rules = rules\n\n    def validate(self, data: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"\n        Validates the provided data against the rules.\n\n        Args:\n            data (Dict[str, Any]): The data to validate.\n\n        Returns:\n            Dict[str, str]: A dictionary of errors, if any.\n        \"\"\"\n        errors = {}\n        for field, rule in self.rules.items():\n            if field not in data:\n                errors[field] = 'This field is required.'\n            elif not rule(data[field]):\n                errors[field] = 'Invalid value.'\n        return errors\n\ndef validate_username(username: str) -> bool:\n    \"\"\"\n    Validates the username.\n\n    Args:\n        username (str): The username to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return len(username) >= 3\n\n\ndef validate_password(password: str) -> bool:\n    \"\"\"\n    Validates the password.\n\n    Args:\n        password (str): The password to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return len(password) >= 6\n\n\ndef validate_email(email: str) -> bool:\n    \"\"\"\n    Validates the email address.\n\n    Args:\n        email (str): The email to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return '@' in email\n\n@app.route('/register', methods=['POST'])\ndef register() -> Any:\n    \"\"\"\n    Handles user registration by validating input data.\n\n    Returns:\n        Any: A JSON response indicating success or error.\n    \"\"\"\n    data = request.json\n    rules = {\n        'username': validate_username,\n        'password': validate_password,\n        'email': validate_email,\n    }\n    validator = Validator(rules)\n    errors = validator.validate(data)\n    if errors:\n        return jsonify(errors), 400\n    return jsonify({'message': 'User registered successfully!'}), 201\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "rejected_code": "from flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\nclass Validator:\n    def __init__(self, rules):\n        self.rules = rules\n\n    def validate(self, data):\n        errors = {}\n        for field, rule in self.rules.items():\n            if field not in data:\n                errors[field] = 'This field is required.'\n            elif not rule(data[field]):\n                errors[field] = 'Invalid value.'\n        return errors\n\ndef validate_username(username):\n    return len(username) >= 3\n\ndef validate_password(password):\n    return len(password) >= 6\n\ndef validate_email(email):\n    return '@' in email\n\n@app.route('/register', methods=['POST'])\ndef register():\n    data = request.json\n    rules = {\n        'username': validate_username,\n        'password': validate_password,\n        'email': validate_email,\n    }\n    validator = Validator(rules)\n    errors = validator.validate(data)\n    if errors:\n        return jsonify(errors), 400\n    return jsonify({'message': 'User registered successfully!'}), 201\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Build a request validation class with customizable rule sets",
    "code_form": "validator class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python class that validates user input for account creation, specifying input types for the validation methods and the expected output types for the validation results.",
      "role": "user"
    },
    "chosen_code": "from flask import Flask, request, jsonify\nfrom typing import Callable, Dict, Any\n\napp = Flask(__name__)\n\nclass Validator:\n    \"\"\"\n    A class to validate input data against customizable rules.\n    \"\"\"\n\n    def __init__(self, rules: Dict[str, Callable[[Any], bool]]) -> None:\n        \"\"\"\n        Initializes the Validator with a set of rules.\n\n        Args:\n            rules (Dict[str, Callable[[Any], bool]]): A dictionary where keys are field names and values are validation functions.\n        \"\"\"\n        self.rules = rules\n\n    def validate(self, data: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"\n        Validates the provided data against the rules.\n\n        Args:\n            data (Dict[str, Any]): The data to validate.\n\n        Returns:\n            Dict[str, str]: A dictionary of errors, if any.\n        \"\"\"\n        errors = {}\n        for field, rule in self.rules.items():\n            if field not in data:\n                errors[field] = 'This field is required.'\n            elif not rule(data[field]):\n                errors[field] = 'Invalid value.'\n        return errors\n\ndef validate_username(username: str) -> bool:\n    \"\"\"\n    Validates the username.\n\n    Args:\n        username (str): The username to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return len(username) >= 3\n\n\ndef validate_password(password: str) -> bool:\n    \"\"\"\n    Validates the password.\n\n    Args:\n        password (str): The password to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return len(password) >= 6\n\n\ndef validate_email(email: str) -> bool:\n    \"\"\"\n    Validates the email address.\n\n    Args:\n        email (str): The email to validate.\n\n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    return '@' in email\n\n@app.route('/register', methods=['POST'])\ndef register() -> Any:\n    \"\"\"\n    Handles user registration by validating input data.\n\n    Returns:\n        Any: A JSON response indicating success or error.\n    \"\"\"\n    data = request.json\n    rules = {\n        'username': validate_username,\n        'password': validate_password,\n        'email': validate_email,\n    }\n    validator = Validator(rules)\n    errors = validator.validate(data)\n    if errors:\n        return jsonify(errors), 400\n    return jsonify({'message': 'User registered successfully!'}), 201\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "rejected_code": "from flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\nclass Validator:\n    def __init__(self, rules):\n        self.rules = rules\n\n    def validate(self, data):\n        errors = {}\n        for field, rule in self.rules.items():\n            if field not in data:\n                errors[field] = 'This field is required.'\n            elif not rule(data[field]):\n                errors[field] = 'Invalid value.'\n        return errors\n\ndef validate_username(username):\n    return len(username) >= 3\n\ndef validate_password(password):\n    return len(password) >= 6\n\ndef validate_email(email):\n    return '@' in email\n\n@app.route('/register', methods=['POST'])\ndef register():\n    data = request.json\n    rules = {\n        'username': validate_username,\n        'password': validate_password,\n        'email': validate_email,\n    }\n    validator = Validator(rules)\n    errors = validator.validate(data)\n    if errors:\n        return jsonify(errors), 400\n    return jsonify({'message': 'User registered successfully!'}), 201\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Create a request middleware for authentication and rate limiting",
    "code_form": "middleware class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code for a middleware that handles authentication and rate limiting for a web application.",
      "role": "user"
    },
    "chosen_code": "from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware import Middleware\nfrom starlette.middleware.base import BaseHTTPMiddleware\nimport time\nimport jwt\nfrom typing import Callable, Dict, List, Any\n\nclass AuthRateLimitMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware for handling authentication and rate limiting for requests.\n    It checks for a valid JWT token and limits the number of requests per user.\n    \"\"\"\n\n    def __init__(self, app: FastAPI) -> None:\n        \"\"\"\n        Initializes the middleware with the FastAPI application.\n        \n        Parameters:\n        app (FastAPI): The FastAPI application instance.\n        \"\"\"\n        super().__init__(app)\n        self.user_requests: Dict[str, List[float]] = {}\n\n    async def dispatch(self, request: Request, call_next: Callable[[Request], Any]) -> Any:\n        \"\"\"\n        Processes the incoming request, checking for authentication and rate limiting.\n        \n        Parameters:\n        request (Request): The incoming request.\n        call_next (Callable[[Request], Any]): The next middleware or route handler.\n        \n        Returns:\n        Any: The response from the next middleware or route handler.\n        \"\"\"\n        auth_header = request.headers.get('Authorization')\n        if not auth_header:\n            raise HTTPException(status_code=401, detail='Unauthorized')\n\n        token = auth_header.split(' ')[1]  # Assumes 'Bearer <token>' format\n        user_id = self._verify_token(token)\n\n        current_time = time.time()\n        self._limit_requests(user_id, current_time)\n\n        # Process the request and get the response\n        response = await call_next(request)\n        return response\n\n    def _verify_token(self, token: str) -> str:\n        \"\"\"\n        Verifies the JWT token and extracts the user ID.\n        \n        Parameters:\n        token (str): The JWT token to verify.\n        \n        Returns:\n        str: The user ID extracted from the token.\n        \n        Raises:\n        HTTPException: If the token is invalid or expired.\n        \"\"\"\n        try:\n            payload = jwt.decode(token, 'secret', algorithms=['HS256'])\n            return payload['sub']\n        except jwt.ExpiredSignatureError:\n            raise HTTPException(status_code=401, detail='Token expired')\n        except jwt.InvalidTokenError:\n            raise HTTPException(status_code=401, detail='Invalid token')\n\n    def _limit_requests(self, user_id: str, current_time: float) -> None:\n        \"\"\"\n        Limits the number of requests a user can make within an hour.\n        \n        Parameters:\n        user_id (str): The ID of the user making the request.\n        current_time (float): The current time in seconds since the epoch.\n        \n        Raises:\n        HTTPException: If the rate limit is exceeded.\n        \"\"\"\n        if user_id not in self.user_requests:\n            self.user_requests[user_id] = []\n        # Filter out requests older than one hour\n        self.user_requests[user_id] = [t for t in self.user_requests[user_id] if t > current_time - 3600]\n\n        if len(self.user_requests[user_id]) >= 100:\n            raise HTTPException(status_code=429, detail='Rate limit exceeded')\n\n        self.user_requests[user_id].append(current_time)\n\napp = FastAPI(middleware=[Middleware(AuthRateLimitMiddleware)])\n\n@app.get('/projects')\nasync def get_projects() -> Dict[str, List[str]]:\n    \"\"\"\n    Endpoint to retrieve projects.\n    \n    Returns:\n    Dict[str, List[str]]: A dictionary containing a list of projects.\n    \"\"\"\n    return {'projects': ['Project A', 'Project B']}",
    "rejected_code": "from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware import Middleware\nfrom starlette.middleware.base import BaseHTTPMiddleware\nimport time\nimport jwt\n\nclass AuthRateLimitMiddleware(BaseHTTPMiddleware):\n    def __init__(self, app):\n        super().__init__(app)\n        self.user_requests = {}\n\n    async def dispatch(self, request: Request, call_next):\n        auth_header = request.headers.get('Authorization')\n        if not auth_header:\n            raise HTTPException(status_code=401, detail='Unauthorized')\n        token = auth_header.split(' ')[1]\n        try:\n            payload = jwt.decode(token, 'secret', algorithms=['HS256'])\n            user_id = payload['sub']\n        except jwt.ExpiredSignatureError:\n            raise HTTPException(status_code=401, detail='Token expired')\n        except jwt.InvalidTokenError:\n            raise HTTPException(status_code=401, detail='Invalid token')\n\n        current_time = time.time()\n        if user_id not in self.user_requests:\n            self.user_requests[user_id] = []\n        self.user_requests[user_id] = [t for t in self.user_requests[user_id] if t > current_time - 3600]\n\n        if len(self.user_requests[user_id]) >= 100:\n            raise HTTPException(status_code=429, detail='Rate limit exceeded')\n\n        self.user_requests[user_id].append(current_time)\n        response = await call_next(request)\n        return response\n\napp = FastAPI(middleware=[Middleware(AuthRateLimitMiddleware)])\n\n@app.get('/projects')\nasync def get_projects():\n    return {'projects': ['Project A', 'Project B']}",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.6666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.019801980198019802,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Create a request middleware for authentication and rate limiting",
    "code_form": "middleware class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a class in Python that implements middleware for authentication and rate limiting in a web application?",
      "role": "user"
    },
    "chosen_code": "from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware import Middleware\nfrom starlette.middleware.base import BaseHTTPMiddleware\nimport time\nimport jwt\nfrom typing import Callable, Dict, List, Any\n\nclass AuthRateLimitMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware for handling authentication and rate limiting for requests.\n    It checks for a valid JWT token and limits the number of requests per user.\n    \"\"\"\n\n    def __init__(self, app: FastAPI) -> None:\n        \"\"\"\n        Initializes the middleware with the FastAPI application.\n        \n        Parameters:\n        app (FastAPI): The FastAPI application instance.\n        \"\"\"\n        super().__init__(app)\n        self.user_requests: Dict[str, List[float]] = {}\n\n    async def dispatch(self, request: Request, call_next: Callable[[Request], Any]) -> Any:\n        \"\"\"\n        Processes the incoming request, checking for authentication and rate limiting.\n        \n        Parameters:\n        request (Request): The incoming request.\n        call_next (Callable[[Request], Any]): The next middleware or route handler.\n        \n        Returns:\n        Any: The response from the next middleware or route handler.\n        \"\"\"\n        auth_header = request.headers.get('Authorization')\n        if not auth_header:\n            raise HTTPException(status_code=401, detail='Unauthorized')\n\n        token = auth_header.split(' ')[1]  # Assumes 'Bearer <token>' format\n        user_id = self._verify_token(token)\n\n        current_time = time.time()\n        self._limit_requests(user_id, current_time)\n\n        # Process the request and get the response\n        response = await call_next(request)\n        return response\n\n    def _verify_token(self, token: str) -> str:\n        \"\"\"\n        Verifies the JWT token and extracts the user ID.\n        \n        Parameters:\n        token (str): The JWT token to verify.\n        \n        Returns:\n        str: The user ID extracted from the token.\n        \n        Raises:\n        HTTPException: If the token is invalid or expired.\n        \"\"\"\n        try:\n            payload = jwt.decode(token, 'secret', algorithms=['HS256'])\n            return payload['sub']\n        except jwt.ExpiredSignatureError:\n            raise HTTPException(status_code=401, detail='Token expired')\n        except jwt.InvalidTokenError:\n            raise HTTPException(status_code=401, detail='Invalid token')\n\n    def _limit_requests(self, user_id: str, current_time: float) -> None:\n        \"\"\"\n        Limits the number of requests a user can make within an hour.\n        \n        Parameters:\n        user_id (str): The ID of the user making the request.\n        current_time (float): The current time in seconds since the epoch.\n        \n        Raises:\n        HTTPException: If the rate limit is exceeded.\n        \"\"\"\n        if user_id not in self.user_requests:\n            self.user_requests[user_id] = []\n        # Filter out requests older than one hour\n        self.user_requests[user_id] = [t for t in self.user_requests[user_id] if t > current_time - 3600]\n\n        if len(self.user_requests[user_id]) >= 100:\n            raise HTTPException(status_code=429, detail='Rate limit exceeded')\n\n        self.user_requests[user_id].append(current_time)\n\napp = FastAPI(middleware=[Middleware(AuthRateLimitMiddleware)])\n\n@app.get('/projects')\nasync def get_projects() -> Dict[str, List[str]]:\n    \"\"\"\n    Endpoint to retrieve projects.\n    \n    Returns:\n    Dict[str, List[str]]: A dictionary containing a list of projects.\n    \"\"\"\n    return {'projects': ['Project A', 'Project B']}",
    "rejected_code": "from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware import Middleware\nfrom starlette.middleware.base import BaseHTTPMiddleware\nimport time\nimport jwt\n\nclass AuthRateLimitMiddleware(BaseHTTPMiddleware):\n    def __init__(self, app):\n        super().__init__(app)\n        self.user_requests = {}\n\n    async def dispatch(self, request: Request, call_next):\n        auth_header = request.headers.get('Authorization')\n        if not auth_header:\n            raise HTTPException(status_code=401, detail='Unauthorized')\n        token = auth_header.split(' ')[1]\n        try:\n            payload = jwt.decode(token, 'secret', algorithms=['HS256'])\n            user_id = payload['sub']\n        except jwt.ExpiredSignatureError:\n            raise HTTPException(status_code=401, detail='Token expired')\n        except jwt.InvalidTokenError:\n            raise HTTPException(status_code=401, detail='Invalid token')\n\n        current_time = time.time()\n        if user_id not in self.user_requests:\n            self.user_requests[user_id] = []\n        self.user_requests[user_id] = [t for t in self.user_requests[user_id] if t > current_time - 3600]\n\n        if len(self.user_requests[user_id]) >= 100:\n            raise HTTPException(status_code=429, detail='Rate limit exceeded')\n\n        self.user_requests[user_id].append(current_time)\n        response = await call_next(request)\n        return response\n\napp = FastAPI(middleware=[Middleware(AuthRateLimitMiddleware)])\n\n@app.get('/projects')\nasync def get_projects():\n    return {'projects': ['Project A', 'Project B']}",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.6666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.019801980198019802,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Create a request middleware for authentication and rate limiting",
    "code_form": "middleware class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a class in Python with proper input/output types that implements middleware for authentication and rate limiting in a web application.",
      "role": "user"
    },
    "chosen_code": "from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware import Middleware\nfrom starlette.middleware.base import BaseHTTPMiddleware\nimport time\nimport jwt\nfrom typing import Callable, Dict, List, Any\n\nclass AuthRateLimitMiddleware(BaseHTTPMiddleware):\n    \"\"\"\n    Middleware for handling authentication and rate limiting for requests.\n    It checks for a valid JWT token and limits the number of requests per user.\n    \"\"\"\n\n    def __init__(self, app: FastAPI) -> None:\n        \"\"\"\n        Initializes the middleware with the FastAPI application.\n        \n        Parameters:\n        app (FastAPI): The FastAPI application instance.\n        \"\"\"\n        super().__init__(app)\n        self.user_requests: Dict[str, List[float]] = {}\n\n    async def dispatch(self, request: Request, call_next: Callable[[Request], Any]) -> Any:\n        \"\"\"\n        Processes the incoming request, checking for authentication and rate limiting.\n        \n        Parameters:\n        request (Request): The incoming request.\n        call_next (Callable[[Request], Any]): The next middleware or route handler.\n        \n        Returns:\n        Any: The response from the next middleware or route handler.\n        \"\"\"\n        auth_header = request.headers.get('Authorization')\n        if not auth_header:\n            raise HTTPException(status_code=401, detail='Unauthorized')\n\n        token = auth_header.split(' ')[1]  # Assumes 'Bearer <token>' format\n        user_id = self._verify_token(token)\n\n        current_time = time.time()\n        self._limit_requests(user_id, current_time)\n\n        # Process the request and get the response\n        response = await call_next(request)\n        return response\n\n    def _verify_token(self, token: str) -> str:\n        \"\"\"\n        Verifies the JWT token and extracts the user ID.\n        \n        Parameters:\n        token (str): The JWT token to verify.\n        \n        Returns:\n        str: The user ID extracted from the token.\n        \n        Raises:\n        HTTPException: If the token is invalid or expired.\n        \"\"\"\n        try:\n            payload = jwt.decode(token, 'secret', algorithms=['HS256'])\n            return payload['sub']\n        except jwt.ExpiredSignatureError:\n            raise HTTPException(status_code=401, detail='Token expired')\n        except jwt.InvalidTokenError:\n            raise HTTPException(status_code=401, detail='Invalid token')\n\n    def _limit_requests(self, user_id: str, current_time: float) -> None:\n        \"\"\"\n        Limits the number of requests a user can make within an hour.\n        \n        Parameters:\n        user_id (str): The ID of the user making the request.\n        current_time (float): The current time in seconds since the epoch.\n        \n        Raises:\n        HTTPException: If the rate limit is exceeded.\n        \"\"\"\n        if user_id not in self.user_requests:\n            self.user_requests[user_id] = []\n        # Filter out requests older than one hour\n        self.user_requests[user_id] = [t for t in self.user_requests[user_id] if t > current_time - 3600]\n\n        if len(self.user_requests[user_id]) >= 100:\n            raise HTTPException(status_code=429, detail='Rate limit exceeded')\n\n        self.user_requests[user_id].append(current_time)\n\napp = FastAPI(middleware=[Middleware(AuthRateLimitMiddleware)])\n\n@app.get('/projects')\nasync def get_projects() -> Dict[str, List[str]]:\n    \"\"\"\n    Endpoint to retrieve projects.\n    \n    Returns:\n    Dict[str, List[str]]: A dictionary containing a list of projects.\n    \"\"\"\n    return {'projects': ['Project A', 'Project B']}",
    "rejected_code": "from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.middleware import Middleware\nfrom starlette.middleware.base import BaseHTTPMiddleware\nimport time\nimport jwt\n\nclass AuthRateLimitMiddleware(BaseHTTPMiddleware):\n    def __init__(self, app):\n        super().__init__(app)\n        self.user_requests = {}\n\n    async def dispatch(self, request: Request, call_next):\n        auth_header = request.headers.get('Authorization')\n        if not auth_header:\n            raise HTTPException(status_code=401, detail='Unauthorized')\n        token = auth_header.split(' ')[1]\n        try:\n            payload = jwt.decode(token, 'secret', algorithms=['HS256'])\n            user_id = payload['sub']\n        except jwt.ExpiredSignatureError:\n            raise HTTPException(status_code=401, detail='Token expired')\n        except jwt.InvalidTokenError:\n            raise HTTPException(status_code=401, detail='Invalid token')\n\n        current_time = time.time()\n        if user_id not in self.user_requests:\n            self.user_requests[user_id] = []\n        self.user_requests[user_id] = [t for t in self.user_requests[user_id] if t > current_time - 3600]\n\n        if len(self.user_requests[user_id]) >= 100:\n            raise HTTPException(status_code=429, detail='Rate limit exceeded')\n\n        self.user_requests[user_id].append(current_time)\n        response = await call_next(request)\n        return response\n\napp = FastAPI(middleware=[Middleware(AuthRateLimitMiddleware)])\n\n@app.get('/projects')\nasync def get_projects():\n    return {'projects': ['Project A', 'Project B']}",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.6666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.019801980198019802,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Implement a response caching decorator with TTL control",
    "code_form": "decorator function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide a Python code example that implements a response caching decorator with TTL control for a web application.",
      "role": "user"
    },
    "chosen_code": "from flask import Flask, jsonify\nimport requests\nimport time\nfrom typing import Callable, Any, Dict, Tuple, Optional\n\n# Global cache dictionary to store cached responses\ncache: Dict[str, Tuple[Any, float]] = {}\n\napp = Flask(__name__)\n\ndef cache_response(ttl: int) -> Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"\n    Decorator to cache the response of a function for a specified time-to-live (TTL).\n\n    Args:\n        ttl (int): Time-to-live in seconds for the cached response.\n\n    Returns:\n        Callable: A decorator that wraps the target function.\n    \"\"\"\n    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a unique cache key based on the function arguments\n            key = str(args) + str(kwargs)\n            if key in cache:\n                value, timestamp = cache[key]\n                # Check if the cached value is still valid based on TTL\n                if time.time() - timestamp < ttl:\n                    return value\n            # Call the original function and cache the result\n            response = func(*args, **kwargs)\n            cache[key] = (response, time.time())  # Store response and current timestamp\n            return response\n        return wrapper\n    return decorator\n\n@app.route('/weather/<city>')\n@cache_response(300)\ndef get_weather(city: str) -> Any:\n    \"\"\"\n    Fetches the current weather information for a given city from an external API.\n\n    Args:\n        city (str): The name of the city for which to fetch weather data.\n\n    Returns:\n        Any: JSON response containing weather information.\n    \"\"\"\n    # Make a request to the weather API\n    response = requests.get(f'http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}')\n    # Raise an exception for HTTP errors\n    response.raise_for_status()\n    return jsonify(response.json())\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "rejected_code": "from flask import Flask, jsonify\nimport requests\nimport time\ncache = {}\n\napp = Flask(__name__)\n\ndef cache_response(ttl):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            key = str(args) + str(kwargs)\n            if key in cache:\n                value, timestamp = cache[key]\n                if time.time() - timestamp < ttl:\n                    return value\n            response = func(*args, **kwargs)\n            cache[key] = (response, time.time())\n            return response\n        return wrapper\n    return decorator\n\n@app.route('/weather/<city>')\n@cache_response(300)\ndef get_weather(city):\n    response = requests.get(f'http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}')\n    return jsonify(response.json())\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.5,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.10714285714285714,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Implement a response caching decorator with TTL control",
    "code_form": "decorator function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a Python function that implements a response caching decorator with TTL control for a web application.",
      "role": "user"
    },
    "chosen_code": "from flask import Flask, jsonify\nimport requests\nimport time\nfrom typing import Callable, Any, Dict, Tuple, Optional\n\n# Global cache dictionary to store cached responses\ncache: Dict[str, Tuple[Any, float]] = {}\n\napp = Flask(__name__)\n\ndef cache_response(ttl: int) -> Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"\n    Decorator to cache the response of a function for a specified time-to-live (TTL).\n\n    Args:\n        ttl (int): Time-to-live in seconds for the cached response.\n\n    Returns:\n        Callable: A decorator that wraps the target function.\n    \"\"\"\n    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a unique cache key based on the function arguments\n            key = str(args) + str(kwargs)\n            if key in cache:\n                value, timestamp = cache[key]\n                # Check if the cached value is still valid based on TTL\n                if time.time() - timestamp < ttl:\n                    return value\n            # Call the original function and cache the result\n            response = func(*args, **kwargs)\n            cache[key] = (response, time.time())  # Store response and current timestamp\n            return response\n        return wrapper\n    return decorator\n\n@app.route('/weather/<city>')\n@cache_response(300)\ndef get_weather(city: str) -> Any:\n    \"\"\"\n    Fetches the current weather information for a given city from an external API.\n\n    Args:\n        city (str): The name of the city for which to fetch weather data.\n\n    Returns:\n        Any: JSON response containing weather information.\n    \"\"\"\n    # Make a request to the weather API\n    response = requests.get(f'http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}')\n    # Raise an exception for HTTP errors\n    response.raise_for_status()\n    return jsonify(response.json())\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "rejected_code": "from flask import Flask, jsonify\nimport requests\nimport time\ncache = {}\n\napp = Flask(__name__)\n\ndef cache_response(ttl):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            key = str(args) + str(kwargs)\n            if key in cache:\n                value, timestamp = cache[key]\n                if time.time() - timestamp < ttl:\n                    return value\n            response = func(*args, **kwargs)\n            cache[key] = (response, time.time())\n            return response\n        return wrapper\n    return decorator\n\n@app.route('/weather/<city>')\n@cache_response(300)\ndef get_weather(city):\n    response = requests.get(f'http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}')\n    return jsonify(response.json())\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.5,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.10714285714285714,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    }
  },
  {
    "domain": "web development",
    "task": "Implement a response caching decorator with TTL control",
    "code_form": "decorator function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python function that implements a response caching decorator with TTL control, specifying input as a function with any arguments and output as a cached response.",
      "role": "user"
    },
    "chosen_code": "from flask import Flask, jsonify\nimport requests\nimport time\nfrom typing import Callable, Any, Dict, Tuple, Optional\n\n# Global cache dictionary to store cached responses\ncache: Dict[str, Tuple[Any, float]] = {}\n\napp = Flask(__name__)\n\ndef cache_response(ttl: int) -> Callable[[Callable[..., Any]], Callable[..., Any]]:\n    \"\"\"\n    Decorator to cache the response of a function for a specified time-to-live (TTL).\n\n    Args:\n        ttl (int): Time-to-live in seconds for the cached response.\n\n    Returns:\n        Callable: A decorator that wraps the target function.\n    \"\"\"\n    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:\n        def wrapper(*args: Any, **kwargs: Any) -> Any:\n            # Create a unique cache key based on the function arguments\n            key = str(args) + str(kwargs)\n            if key in cache:\n                value, timestamp = cache[key]\n                # Check if the cached value is still valid based on TTL\n                if time.time() - timestamp < ttl:\n                    return value\n            # Call the original function and cache the result\n            response = func(*args, **kwargs)\n            cache[key] = (response, time.time())  # Store response and current timestamp\n            return response\n        return wrapper\n    return decorator\n\n@app.route('/weather/<city>')\n@cache_response(300)\ndef get_weather(city: str) -> Any:\n    \"\"\"\n    Fetches the current weather information for a given city from an external API.\n\n    Args:\n        city (str): The name of the city for which to fetch weather data.\n\n    Returns:\n        Any: JSON response containing weather information.\n    \"\"\"\n    # Make a request to the weather API\n    response = requests.get(f'http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}')\n    # Raise an exception for HTTP errors\n    response.raise_for_status()\n    return jsonify(response.json())\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "rejected_code": "from flask import Flask, jsonify\nimport requests\nimport time\ncache = {}\n\napp = Flask(__name__)\n\ndef cache_response(ttl):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            key = str(args) + str(kwargs)\n            if key in cache:\n                value, timestamp = cache[key]\n                if time.time() - timestamp < ttl:\n                    return value\n            response = func(*args, **kwargs)\n            cache[key] = (response, time.time())\n            return response\n        return wrapper\n    return decorator\n\n@app.route('/weather/<city>')\n@cache_response(300)\ndef get_weather(city):\n    response = requests.get(f'http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}')\n    return jsonify(response.json())\n\nif __name__ == '__main__':\n    app.run(debug=True)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.5,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.10714285714285714,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'flask'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Build a database connection pool manager with health checks",
    "code_form": "manager class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to build a database connection pool manager with health checks.",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker, Session as SqlAlchemySession\nfrom threading import Lock\nfrom sqlalchemy.engine import Engine\nfrom typing import Optional\n\nclass ConnectionPoolManager:\n    \"\"\"\n    A class that manages a pool of database connections using SQLAlchemy.\n    It provides methods to retrieve sessions, perform health checks on connections,\n    and dispose of the connection pool when no longer needed.\n    \"\"\"\n\n    def __init__(self, db_url: str, pool_size: int = 5) -> None:\n        \"\"\"\n        Initializes the ConnectionPoolManager with the given database URL and pool size.\n\n        :param db_url: The database URL for connecting to the PostgreSQL database.\n        :param pool_size: The number of connections to maintain in the pool (default is 5).\n        \"\"\"\n        self.engine: Engine = create_engine(db_url, pool_pre_ping=True, pool_size=pool_size)\n        self.Session: sessionmaker = sessionmaker(bind=self.engine)\n        self.lock: Lock = Lock()\n\n    def get_session(self) -> SqlAlchemySession:\n        \"\"\"\n        Retrieves a new session from the connection pool.\n\n        :return: A new SQLAlchemy session object.\n        \"\"\"\n        with self.lock:\n            return self.Session()\n\n    def health_check(self) -> bool:\n        \"\"\"\n        Performs a health check on the connection pool by executing a simple query.\n        This ensures that connections are active before use.\n\n        :return: True if the health check is successful, False otherwise.\n        \"\"\"\n        with self.lock:\n            try:\n                with self.engine.connect() as connection:\n                    connection.execute(text('SELECT 1'))\n                return True\n            except Exception as e:\n                # Log the exception (in a real-world scenario)\n                print(f\"Health check failed: {e}\")\n                return False\n\n    def close_all(self) -> None:\n        \"\"\"\n        Disposes of the connection pool and closes all connections.\n        This should be called when the application is shutting down.\n        \"\"\"\n        self.engine.dispose()\n\n# Example usage:\n# db_manager = ConnectionPoolManager('postgresql://user:password@localhost/dbname')\n# if db_manager.health_check():\n#     session = db_manager.get_session()\n#     # Use session for database operations\n# db_manager.close_all()",
    "rejected_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\nfrom threading import Lock\nimport time\n\nclass ConnectionPoolManager:\n    def __init__(self, db_url, pool_size=5):\n        self.engine = create_engine(db_url, pool_pre_ping=True, pool_size=pool_size)\n        self.Session = sessionmaker(bind=self.engine)\n        self.lock = Lock()\n\n    def get_session(self):\n        with self.lock:\n            return self.Session()\n\n    def health_check(self):\n        with self.lock:\n            try:\n                with self.engine.connect() as connection:\n                    connection.execute(text('SELECT 1'))\n                return True\n            except Exception:\n                return False\n\n    def close_all(self):\n        self.engine.dispose()\n\n# Example usage:\n# db_manager = ConnectionPoolManager('postgresql://user:password@localhost/dbname')\n# if db_manager.health_check():\n#     session = db_manager.get_session()\n#     # Use session for database operations\n# db_manager.close_all()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.1111111111111111,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.18181818181818182,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Build a database connection pool manager with health checks",
    "code_form": "manager class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a class in Python that implements a database connection pool manager with health checks?",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker, Session as SqlAlchemySession\nfrom threading import Lock\nfrom sqlalchemy.engine import Engine\nfrom typing import Optional\n\nclass ConnectionPoolManager:\n    \"\"\"\n    A class that manages a pool of database connections using SQLAlchemy.\n    It provides methods to retrieve sessions, perform health checks on connections,\n    and dispose of the connection pool when no longer needed.\n    \"\"\"\n\n    def __init__(self, db_url: str, pool_size: int = 5) -> None:\n        \"\"\"\n        Initializes the ConnectionPoolManager with the given database URL and pool size.\n\n        :param db_url: The database URL for connecting to the PostgreSQL database.\n        :param pool_size: The number of connections to maintain in the pool (default is 5).\n        \"\"\"\n        self.engine: Engine = create_engine(db_url, pool_pre_ping=True, pool_size=pool_size)\n        self.Session: sessionmaker = sessionmaker(bind=self.engine)\n        self.lock: Lock = Lock()\n\n    def get_session(self) -> SqlAlchemySession:\n        \"\"\"\n        Retrieves a new session from the connection pool.\n\n        :return: A new SQLAlchemy session object.\n        \"\"\"\n        with self.lock:\n            return self.Session()\n\n    def health_check(self) -> bool:\n        \"\"\"\n        Performs a health check on the connection pool by executing a simple query.\n        This ensures that connections are active before use.\n\n        :return: True if the health check is successful, False otherwise.\n        \"\"\"\n        with self.lock:\n            try:\n                with self.engine.connect() as connection:\n                    connection.execute(text('SELECT 1'))\n                return True\n            except Exception as e:\n                # Log the exception (in a real-world scenario)\n                print(f\"Health check failed: {e}\")\n                return False\n\n    def close_all(self) -> None:\n        \"\"\"\n        Disposes of the connection pool and closes all connections.\n        This should be called when the application is shutting down.\n        \"\"\"\n        self.engine.dispose()\n\n# Example usage:\n# db_manager = ConnectionPoolManager('postgresql://user:password@localhost/dbname')\n# if db_manager.health_check():\n#     session = db_manager.get_session()\n#     # Use session for database operations\n# db_manager.close_all()",
    "rejected_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\nfrom threading import Lock\nimport time\n\nclass ConnectionPoolManager:\n    def __init__(self, db_url, pool_size=5):\n        self.engine = create_engine(db_url, pool_pre_ping=True, pool_size=pool_size)\n        self.Session = sessionmaker(bind=self.engine)\n        self.lock = Lock()\n\n    def get_session(self):\n        with self.lock:\n            return self.Session()\n\n    def health_check(self):\n        with self.lock:\n            try:\n                with self.engine.connect() as connection:\n                    connection.execute(text('SELECT 1'))\n                return True\n            except Exception:\n                return False\n\n    def close_all(self):\n        self.engine.dispose()\n\n# Example usage:\n# db_manager = ConnectionPoolManager('postgresql://user:password@localhost/dbname')\n# if db_manager.health_check():\n#     session = db_manager.get_session()\n#     # Use session for database operations\n# db_manager.close_all()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.1111111111111111,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.18181818181818182,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Build a database connection pool manager with health checks",
    "code_form": "manager class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python class that implements a database connection pool manager with health checks. Specify that the class should accept a database URL and pool size as inputs, and return a session object and a health check status as outputs.",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker, Session as SqlAlchemySession\nfrom threading import Lock\nfrom sqlalchemy.engine import Engine\nfrom typing import Optional\n\nclass ConnectionPoolManager:\n    \"\"\"\n    A class that manages a pool of database connections using SQLAlchemy.\n    It provides methods to retrieve sessions, perform health checks on connections,\n    and dispose of the connection pool when no longer needed.\n    \"\"\"\n\n    def __init__(self, db_url: str, pool_size: int = 5) -> None:\n        \"\"\"\n        Initializes the ConnectionPoolManager with the given database URL and pool size.\n\n        :param db_url: The database URL for connecting to the PostgreSQL database.\n        :param pool_size: The number of connections to maintain in the pool (default is 5).\n        \"\"\"\n        self.engine: Engine = create_engine(db_url, pool_pre_ping=True, pool_size=pool_size)\n        self.Session: sessionmaker = sessionmaker(bind=self.engine)\n        self.lock: Lock = Lock()\n\n    def get_session(self) -> SqlAlchemySession:\n        \"\"\"\n        Retrieves a new session from the connection pool.\n\n        :return: A new SQLAlchemy session object.\n        \"\"\"\n        with self.lock:\n            return self.Session()\n\n    def health_check(self) -> bool:\n        \"\"\"\n        Performs a health check on the connection pool by executing a simple query.\n        This ensures that connections are active before use.\n\n        :return: True if the health check is successful, False otherwise.\n        \"\"\"\n        with self.lock:\n            try:\n                with self.engine.connect() as connection:\n                    connection.execute(text('SELECT 1'))\n                return True\n            except Exception as e:\n                # Log the exception (in a real-world scenario)\n                print(f\"Health check failed: {e}\")\n                return False\n\n    def close_all(self) -> None:\n        \"\"\"\n        Disposes of the connection pool and closes all connections.\n        This should be called when the application is shutting down.\n        \"\"\"\n        self.engine.dispose()\n\n# Example usage:\n# db_manager = ConnectionPoolManager('postgresql://user:password@localhost/dbname')\n# if db_manager.health_check():\n#     session = db_manager.get_session()\n#     # Use session for database operations\n# db_manager.close_all()",
    "rejected_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\nfrom threading import Lock\nimport time\n\nclass ConnectionPoolManager:\n    def __init__(self, db_url, pool_size=5):\n        self.engine = create_engine(db_url, pool_pre_ping=True, pool_size=pool_size)\n        self.Session = sessionmaker(bind=self.engine)\n        self.lock = Lock()\n\n    def get_session(self):\n        with self.lock:\n            return self.Session()\n\n    def health_check(self):\n        with self.lock:\n            try:\n                with self.engine.connect() as connection:\n                    connection.execute(text('SELECT 1'))\n                return True\n            except Exception:\n                return False\n\n    def close_all(self):\n        self.engine.dispose()\n\n# Example usage:\n# db_manager = ConnectionPoolManager('postgresql://user:password@localhost/dbname')\n# if db_manager.health_check():\n#     session = db_manager.get_session()\n#     # Use session for database operations\n# db_manager.close_all()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.1111111111111111,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.18181818181818182,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Implement a query builder with parameterized filters",
    "code_form": "builder class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to implement a query builder with parameterized filters for retrieving user records from a PostgreSQL database.",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, Column, Integer, String, Date, select\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session as SessionType\nfrom typing import List, Optional\n\n# Define the base class for SQLAlchemy models\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = 'users'\n    id: int = Column(Integer, primary_key=True)\n    name: str = Column(String)\n    age: Optional[int] = Column(Integer)\n    city: Optional[str] = Column(String)\n    registration_date: Optional[Date] = Column(Date)\n\nclass UserQueryBuilder:\n    def __init__(self) -> None:\n        \"\"\"Initialize a new UserQueryBuilder with empty filters and parameters.\"\"\"\n        self.filters: List[any] = []  # List to hold filter conditions\n        self.params: dict = {}  # Dictionary to hold parameter values\n\n    def filter_by_age(self, age: int) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user age.\"\"\"\n        self.filters.append(User.age == age)\n        self.params['age'] = age\n        return self\n\n    def filter_by_city(self, city: str) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user city.\"\"\"\n        self.filters.append(User.city == city)\n        self.params['city'] = city\n        return self\n\n    def filter_by_registration_date(self, registration_date: Date) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user registration date.\"\"\"\n        self.filters.append(User.registration_date == registration_date)\n        self.params['registration_date'] = registration_date\n        return self\n\n    def build_query(self) -> select:\n        \"\"\"Build and return the SQLAlchemy query based on the filters set.\"\"\"\n        return select(User).where(*self.filters) if self.filters else select(User)\n\n# Setup the database engine and session\nengine = create_engine('postgresql://user:password@localhost/dbname')\nSessionLocal = sessionmaker(bind=engine)\n\ndef get_users_with_filters(age: Optional[int] = None, city: Optional[str] = None, registration_date: Optional[Date] = None) -> List[User]:\n    \"\"\"Retrieve users from the database with optional filters.\"\"\"\n    session: SessionType = SessionLocal()\n    query_builder = UserQueryBuilder()\n    if age:\n        query_builder.filter_by_age(age)\n    if city:\n        query_builder.filter_by_city(city)\n    if registration_date:\n        query_builder.filter_by_registration_date(registration_date)\n    query = query_builder.build_query()\n    result = session.execute(query).scalars().all()\n    session.close()\n    return result\n\n# Example usage of the get_users_with_filters function\nif __name__ == '__main__':\n    users = get_users_with_filters(age=30, city='New York')\n    print(users)",
    "rejected_code": "from sqlalchemy import create_engine, Column, Integer, String, Date, and select\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = 'users'\n    id = Column(Integer, primary_key=True)\n    name = Column(String)\n    age = Column(Integer)\n    city = Column(String)\n    registration_date = Column(Date)\n\nclass UserQueryBuilder:\n    def __init__(self):\n        self.filters = []\n        self.params = {}\n\n    def filter_by_age(self, age):\n        self.filters.append(User.age == age)\n        self.params['age'] = age\n        return self\n\n    def filter_by_city(self, city):\n        self.filters.append(User.city == city)\n        self.params['city'] = city\n        return self\n\n    def filter_by_registration_date(self, registration_date):\n        self.filters.append(User.registration_date == registration_date)\n        self.params['registration_date'] = registration_date\n        return self\n\n    def build_query(self):\n        return select(User).where(*self.filters) if self.filters else select(User)\n\nengine = create_engine('postgresql://user:password@localhost/dbname')\nSession = sessionmaker(bind=engine)\n\nsession = Session()\nquery_builder = UserQueryBuilder()\nquery = query_builder.filter_by_age(30).filter_by_city('New York').build_query()\nresult = session.execute(query).scalars().all()\nprint(result)\nsession.close()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.625,
      "pep8_compliance": null,
      "comment_density": 0.04477611940298507,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.18181818181818182,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Implement a query builder with parameterized filters",
    "code_form": "builder class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a class in Python that implements a query builder with parameterized filters for retrieving user records from a PostgreSQL database?",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, Column, Integer, String, Date, select\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session as SessionType\nfrom typing import List, Optional\n\n# Define the base class for SQLAlchemy models\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = 'users'\n    id: int = Column(Integer, primary_key=True)\n    name: str = Column(String)\n    age: Optional[int] = Column(Integer)\n    city: Optional[str] = Column(String)\n    registration_date: Optional[Date] = Column(Date)\n\nclass UserQueryBuilder:\n    def __init__(self) -> None:\n        \"\"\"Initialize a new UserQueryBuilder with empty filters and parameters.\"\"\"\n        self.filters: List[any] = []  # List to hold filter conditions\n        self.params: dict = {}  # Dictionary to hold parameter values\n\n    def filter_by_age(self, age: int) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user age.\"\"\"\n        self.filters.append(User.age == age)\n        self.params['age'] = age\n        return self\n\n    def filter_by_city(self, city: str) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user city.\"\"\"\n        self.filters.append(User.city == city)\n        self.params['city'] = city\n        return self\n\n    def filter_by_registration_date(self, registration_date: Date) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user registration date.\"\"\"\n        self.filters.append(User.registration_date == registration_date)\n        self.params['registration_date'] = registration_date\n        return self\n\n    def build_query(self) -> select:\n        \"\"\"Build and return the SQLAlchemy query based on the filters set.\"\"\"\n        return select(User).where(*self.filters) if self.filters else select(User)\n\n# Setup the database engine and session\nengine = create_engine('postgresql://user:password@localhost/dbname')\nSessionLocal = sessionmaker(bind=engine)\n\ndef get_users_with_filters(age: Optional[int] = None, city: Optional[str] = None, registration_date: Optional[Date] = None) -> List[User]:\n    \"\"\"Retrieve users from the database with optional filters.\"\"\"\n    session: SessionType = SessionLocal()\n    query_builder = UserQueryBuilder()\n    if age:\n        query_builder.filter_by_age(age)\n    if city:\n        query_builder.filter_by_city(city)\n    if registration_date:\n        query_builder.filter_by_registration_date(registration_date)\n    query = query_builder.build_query()\n    result = session.execute(query).scalars().all()\n    session.close()\n    return result\n\n# Example usage of the get_users_with_filters function\nif __name__ == '__main__':\n    users = get_users_with_filters(age=30, city='New York')\n    print(users)",
    "rejected_code": "from sqlalchemy import create_engine, Column, Integer, String, Date, and select\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = 'users'\n    id = Column(Integer, primary_key=True)\n    name = Column(String)\n    age = Column(Integer)\n    city = Column(String)\n    registration_date = Column(Date)\n\nclass UserQueryBuilder:\n    def __init__(self):\n        self.filters = []\n        self.params = {}\n\n    def filter_by_age(self, age):\n        self.filters.append(User.age == age)\n        self.params['age'] = age\n        return self\n\n    def filter_by_city(self, city):\n        self.filters.append(User.city == city)\n        self.params['city'] = city\n        return self\n\n    def filter_by_registration_date(self, registration_date):\n        self.filters.append(User.registration_date == registration_date)\n        self.params['registration_date'] = registration_date\n        return self\n\n    def build_query(self):\n        return select(User).where(*self.filters) if self.filters else select(User)\n\nengine = create_engine('postgresql://user:password@localhost/dbname')\nSession = sessionmaker(bind=engine)\n\nsession = Session()\nquery_builder = UserQueryBuilder()\nquery = query_builder.filter_by_age(30).filter_by_city('New York').build_query()\nresult = session.execute(query).scalars().all()\nprint(result)\nsession.close()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.625,
      "pep8_compliance": null,
      "comment_density": 0.04477611940298507,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.18181818181818182,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Implement a query builder with parameterized filters",
    "code_form": "builder class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a Python class with type annotations that implements a query builder with parameterized filters for retrieving user records from a PostgreSQL database. The class should handle filters for age, city, and registration date.",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, Column, Integer, String, Date, select\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session as SessionType\nfrom typing import List, Optional\n\n# Define the base class for SQLAlchemy models\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = 'users'\n    id: int = Column(Integer, primary_key=True)\n    name: str = Column(String)\n    age: Optional[int] = Column(Integer)\n    city: Optional[str] = Column(String)\n    registration_date: Optional[Date] = Column(Date)\n\nclass UserQueryBuilder:\n    def __init__(self) -> None:\n        \"\"\"Initialize a new UserQueryBuilder with empty filters and parameters.\"\"\"\n        self.filters: List[any] = []  # List to hold filter conditions\n        self.params: dict = {}  # Dictionary to hold parameter values\n\n    def filter_by_age(self, age: int) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user age.\"\"\"\n        self.filters.append(User.age == age)\n        self.params['age'] = age\n        return self\n\n    def filter_by_city(self, city: str) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user city.\"\"\"\n        self.filters.append(User.city == city)\n        self.params['city'] = city\n        return self\n\n    def filter_by_registration_date(self, registration_date: Date) -> 'UserQueryBuilder':\n        \"\"\"Add a filter for user registration date.\"\"\"\n        self.filters.append(User.registration_date == registration_date)\n        self.params['registration_date'] = registration_date\n        return self\n\n    def build_query(self) -> select:\n        \"\"\"Build and return the SQLAlchemy query based on the filters set.\"\"\"\n        return select(User).where(*self.filters) if self.filters else select(User)\n\n# Setup the database engine and session\nengine = create_engine('postgresql://user:password@localhost/dbname')\nSessionLocal = sessionmaker(bind=engine)\n\ndef get_users_with_filters(age: Optional[int] = None, city: Optional[str] = None, registration_date: Optional[Date] = None) -> List[User]:\n    \"\"\"Retrieve users from the database with optional filters.\"\"\"\n    session: SessionType = SessionLocal()\n    query_builder = UserQueryBuilder()\n    if age:\n        query_builder.filter_by_age(age)\n    if city:\n        query_builder.filter_by_city(city)\n    if registration_date:\n        query_builder.filter_by_registration_date(registration_date)\n    query = query_builder.build_query()\n    result = session.execute(query).scalars().all()\n    session.close()\n    return result\n\n# Example usage of the get_users_with_filters function\nif __name__ == '__main__':\n    users = get_users_with_filters(age=30, city='New York')\n    print(users)",
    "rejected_code": "from sqlalchemy import create_engine, Column, Integer, String, Date, and select\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = 'users'\n    id = Column(Integer, primary_key=True)\n    name = Column(String)\n    age = Column(Integer)\n    city = Column(String)\n    registration_date = Column(Date)\n\nclass UserQueryBuilder:\n    def __init__(self):\n        self.filters = []\n        self.params = {}\n\n    def filter_by_age(self, age):\n        self.filters.append(User.age == age)\n        self.params['age'] = age\n        return self\n\n    def filter_by_city(self, city):\n        self.filters.append(User.city == city)\n        self.params['city'] = city\n        return self\n\n    def filter_by_registration_date(self, registration_date):\n        self.filters.append(User.registration_date == registration_date)\n        self.params['registration_date'] = registration_date\n        return self\n\n    def build_query(self):\n        return select(User).where(*self.filters) if self.filters else select(User)\n\nengine = create_engine('postgresql://user:password@localhost/dbname')\nSession = sessionmaker(bind=engine)\n\nsession = Session()\nquery_builder = UserQueryBuilder()\nquery = query_builder.filter_by_age(30).filter_by_city('New York').build_query()\nresult = session.execute(query).scalars().all()\nprint(result)\nsession.close()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.625,
      "pep8_compliance": null,
      "comment_density": 0.04477611940298507,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.18181818181818182,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Create a database migration function with schema versioning",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create a database migration function with schema versioning?",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.orm import sessionmaker\nfrom typing import Dict\n\n# Database connection parameters\nDATABASE_URL = 'postgresql://user:password@localhost/ecommerce'\n\n# Create a SQLAlchemy engine and session\nengine: Engine = create_engine(DATABASE_URL)\nSession = sessionmaker(bind=engine)\n\n# Current schema version\ncurrent_version: int = 1\n\n# Dictionary mapping version numbers to migration SQL commands\nmigrations: Dict[int, str] = {\n    1: \"CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(100), price DECIMAL);\",\n    2: \"ALTER TABLE products ADD COLUMN description TEXT;\"\n}\n\ndef migrate_database(target_version: int) -> None:\n    \"\"\"\n    Migrates the database schema to the specified target version.\n    \n    This function executes the necessary SQL commands to update the database schema\n    from the current version to the target version. If a migration for a specific version\n    is not found, a message is printed to inform the user.\n    \n    Args:\n        target_version (int): The version to migrate the database to.\n    \"\"\"\n    with engine.connect() as connection:\n        for version in range(current_version + 1, target_version + 1):\n            if version in migrations:\n                connection.execute(text(migrations[version]))\n                print(f'Migrated to version {version}')\n            else:\n                print(f'No migration found for version {version}')\n\n# Example usage: migrate the database to version 2\nif __name__ == '__main__':\n    migrate_database(2)",
    "rejected_code": "from sqlalchemy import create_engine, MetaData\nfrom sqlalchemy.orm import sessionmaker\n\nengine = create_engine('postgresql://user:password@localhost/ecommerce')\nSession = sessionmaker(bind=engine)\n\ncurrent_version = 1\n\nmigrations = {\n    1: \"CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(100), price DECIMAL);\",\n    2: \"ALTER TABLE products ADD COLUMN description TEXT;\"\n}\n\ndef migrate_database(target_version):\n    with engine.connect() as connection:\n        for version in range(current_version + 1, target_version + 1):\n            if version in migrations:\n                connection.execute(migrations[version])\n                print(f'Migrated to version {version}')\n            else:\n                print(f'No migration found for version {version}')\n\nmigrate_database(2)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.11627906976744186,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Create a database migration function with schema versioning",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a function in Python that implements a database migration system with schema versioning.",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.orm import sessionmaker\nfrom typing import Dict\n\n# Database connection parameters\nDATABASE_URL = 'postgresql://user:password@localhost/ecommerce'\n\n# Create a SQLAlchemy engine and session\nengine: Engine = create_engine(DATABASE_URL)\nSession = sessionmaker(bind=engine)\n\n# Current schema version\ncurrent_version: int = 1\n\n# Dictionary mapping version numbers to migration SQL commands\nmigrations: Dict[int, str] = {\n    1: \"CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(100), price DECIMAL);\",\n    2: \"ALTER TABLE products ADD COLUMN description TEXT;\"\n}\n\ndef migrate_database(target_version: int) -> None:\n    \"\"\"\n    Migrates the database schema to the specified target version.\n    \n    This function executes the necessary SQL commands to update the database schema\n    from the current version to the target version. If a migration for a specific version\n    is not found, a message is printed to inform the user.\n    \n    Args:\n        target_version (int): The version to migrate the database to.\n    \"\"\"\n    with engine.connect() as connection:\n        for version in range(current_version + 1, target_version + 1):\n            if version in migrations:\n                connection.execute(text(migrations[version]))\n                print(f'Migrated to version {version}')\n            else:\n                print(f'No migration found for version {version}')\n\n# Example usage: migrate the database to version 2\nif __name__ == '__main__':\n    migrate_database(2)",
    "rejected_code": "from sqlalchemy import create_engine, MetaData\nfrom sqlalchemy.orm import sessionmaker\n\nengine = create_engine('postgresql://user:password@localhost/ecommerce')\nSession = sessionmaker(bind=engine)\n\ncurrent_version = 1\n\nmigrations = {\n    1: \"CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(100), price DECIMAL);\",\n    2: \"ALTER TABLE products ADD COLUMN description TEXT;\"\n}\n\ndef migrate_database(target_version):\n    with engine.connect() as connection:\n        for version in range(current_version + 1, target_version + 1):\n            if version in migrations:\n                connection.execute(migrations[version])\n                print(f'Migrated to version {version}')\n            else:\n                print(f'No migration found for version {version}')\n\nmigrate_database(2)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.11627906976744186,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Create a database migration function with schema versioning",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you create a Python function that takes an integer as input for the target version and performs database migrations, specifying the input and output types?",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, text\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.orm import sessionmaker\nfrom typing import Dict\n\n# Database connection parameters\nDATABASE_URL = 'postgresql://user:password@localhost/ecommerce'\n\n# Create a SQLAlchemy engine and session\nengine: Engine = create_engine(DATABASE_URL)\nSession = sessionmaker(bind=engine)\n\n# Current schema version\ncurrent_version: int = 1\n\n# Dictionary mapping version numbers to migration SQL commands\nmigrations: Dict[int, str] = {\n    1: \"CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(100), price DECIMAL);\",\n    2: \"ALTER TABLE products ADD COLUMN description TEXT;\"\n}\n\ndef migrate_database(target_version: int) -> None:\n    \"\"\"\n    Migrates the database schema to the specified target version.\n    \n    This function executes the necessary SQL commands to update the database schema\n    from the current version to the target version. If a migration for a specific version\n    is not found, a message is printed to inform the user.\n    \n    Args:\n        target_version (int): The version to migrate the database to.\n    \"\"\"\n    with engine.connect() as connection:\n        for version in range(current_version + 1, target_version + 1):\n            if version in migrations:\n                connection.execute(text(migrations[version]))\n                print(f'Migrated to version {version}')\n            else:\n                print(f'No migration found for version {version}')\n\n# Example usage: migrate the database to version 2\nif __name__ == '__main__':\n    migrate_database(2)",
    "rejected_code": "from sqlalchemy import create_engine, MetaData\nfrom sqlalchemy.orm import sessionmaker\n\nengine = create_engine('postgresql://user:password@localhost/ecommerce')\nSession = sessionmaker(bind=engine)\n\ncurrent_version = 1\n\nmigrations = {\n    1: \"CREATE TABLE products (id SERIAL PRIMARY KEY, name VARCHAR(100), price DECIMAL);\",\n    2: \"ALTER TABLE products ADD COLUMN description TEXT;\"\n}\n\ndef migrate_database(target_version):\n    with engine.connect() as connection:\n        for version in range(current_version + 1, target_version + 1):\n            if version in migrations:\n                connection.execute(migrations[version])\n                print(f'Migrated to version {version}')\n            else:\n                print(f'No migration found for version {version}')\n\nmigrate_database(2)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.11627906976744186,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Create a numerical integration function with error estimation",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Provide Python code to calculate the integral of a Gaussian function with error estimation.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy.integrate import quad\nfrom typing import Callable, Tuple\n\n\ndef gaussian(x: float) -> float:\n    \"\"\"\n    Compute the Gaussian function value at x.\n\n    The Gaussian function is defined as:\n    f(x) = (1 / sqrt(2 * pi)) * exp(-0.5 * x^2)\n\n    Args:\n        x (float): The input value for which to compute the Gaussian function.\n\n    Returns:\n        float: The value of the Gaussian function at x.\n    \"\"\"\n    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x ** 2)\n\n\ndef integrate_with_error_estimation(func: Callable[[float], float], a: float, b: float) -> Tuple[float, float]:\n    \"\"\"\n    Perform numerical integration of a given function with error estimation.\n\n    Uses the adaptive quadrature method from SciPy to compute the integral\n    of the function from a to b and provides an estimate of the error.\n\n    Args:\n        func (Callable[[float], float]): The function to integrate.\n        a (float): The lower limit of integration.\n        b (float): The upper limit of integration.\n\n    Returns:\n        Tuple[float, float]: A tuple containing the computed integral and the estimated error.\n    \"\"\"\n    integral, error = quad(func, a, b)\n    return integral, error\n\n\nif __name__ == '__main__':\n    # Integrate the Gaussian function from negative to positive infinity\n    result, error_estimate = integrate_with_error_estimation(gaussian, -np.inf, np.inf)\n    print('Integral:', result)\n    print('Estimated Error:', error_estimate)",
    "rejected_code": "import numpy as np\nfrom scipy.integrate import quad\n\ndef gaussian(x):\n    return (1/np.sqrt(2*np.pi)) * np.exp(-0.5 * x**2)\n\ndef integrate_with_error_estimation(func, a, b):\n    integral, error = quad(func, a, b)\n    return integral, error\n\nresult, error_estimate = integrate_with_error_estimation(gaussian, -np.inf, np.inf)\nprint('Integral:', result)\nprint('Estimated Error:', error_estimate)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.022222222222222223,
      "execution_result": {
        "success": true,
        "output": "Integral: 0.9999999999999997\nEstimated Error: 1.017819145094224e-08",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Integral: 0.9999999999999997\nEstimated Error: 1.017819145094224e-08",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Create a numerical integration function with error estimation",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a Python function that calculates the integral of a Gaussian function with error estimation.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy.integrate import quad\nfrom typing import Callable, Tuple\n\n\ndef gaussian(x: float) -> float:\n    \"\"\"\n    Compute the Gaussian function value at x.\n\n    The Gaussian function is defined as:\n    f(x) = (1 / sqrt(2 * pi)) * exp(-0.5 * x^2)\n\n    Args:\n        x (float): The input value for which to compute the Gaussian function.\n\n    Returns:\n        float: The value of the Gaussian function at x.\n    \"\"\"\n    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x ** 2)\n\n\ndef integrate_with_error_estimation(func: Callable[[float], float], a: float, b: float) -> Tuple[float, float]:\n    \"\"\"\n    Perform numerical integration of a given function with error estimation.\n\n    Uses the adaptive quadrature method from SciPy to compute the integral\n    of the function from a to b and provides an estimate of the error.\n\n    Args:\n        func (Callable[[float], float]): The function to integrate.\n        a (float): The lower limit of integration.\n        b (float): The upper limit of integration.\n\n    Returns:\n        Tuple[float, float]: A tuple containing the computed integral and the estimated error.\n    \"\"\"\n    integral, error = quad(func, a, b)\n    return integral, error\n\n\nif __name__ == '__main__':\n    # Integrate the Gaussian function from negative to positive infinity\n    result, error_estimate = integrate_with_error_estimation(gaussian, -np.inf, np.inf)\n    print('Integral:', result)\n    print('Estimated Error:', error_estimate)",
    "rejected_code": "import numpy as np\nfrom scipy.integrate import quad\n\ndef gaussian(x):\n    return (1/np.sqrt(2*np.pi)) * np.exp(-0.5 * x**2)\n\ndef integrate_with_error_estimation(func, a, b):\n    integral, error = quad(func, a, b)\n    return integral, error\n\nresult, error_estimate = integrate_with_error_estimation(gaussian, -np.inf, np.inf)\nprint('Integral:', result)\nprint('Estimated Error:', error_estimate)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.022222222222222223,
      "execution_result": {
        "success": true,
        "output": "Integral: 0.9999999999999997\nEstimated Error: 1.017819145094224e-08",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Integral: 0.9999999999999997\nEstimated Error: 1.017819145094224e-08",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Create a numerical integration function with error estimation",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python function that takes a callable and two floats as input, returning a tuple of two floats for the integral and error estimation.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy.integrate import quad\nfrom typing import Callable, Tuple\n\n\ndef gaussian(x: float) -> float:\n    \"\"\"\n    Compute the Gaussian function value at x.\n\n    The Gaussian function is defined as:\n    f(x) = (1 / sqrt(2 * pi)) * exp(-0.5 * x^2)\n\n    Args:\n        x (float): The input value for which to compute the Gaussian function.\n\n    Returns:\n        float: The value of the Gaussian function at x.\n    \"\"\"\n    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x ** 2)\n\n\ndef integrate_with_error_estimation(func: Callable[[float], float], a: float, b: float) -> Tuple[float, float]:\n    \"\"\"\n    Perform numerical integration of a given function with error estimation.\n\n    Uses the adaptive quadrature method from SciPy to compute the integral\n    of the function from a to b and provides an estimate of the error.\n\n    Args:\n        func (Callable[[float], float]): The function to integrate.\n        a (float): The lower limit of integration.\n        b (float): The upper limit of integration.\n\n    Returns:\n        Tuple[float, float]: A tuple containing the computed integral and the estimated error.\n    \"\"\"\n    integral, error = quad(func, a, b)\n    return integral, error\n\n\nif __name__ == '__main__':\n    # Integrate the Gaussian function from negative to positive infinity\n    result, error_estimate = integrate_with_error_estimation(gaussian, -np.inf, np.inf)\n    print('Integral:', result)\n    print('Estimated Error:', error_estimate)",
    "rejected_code": "import numpy as np\nfrom scipy.integrate import quad\n\ndef gaussian(x):\n    return (1/np.sqrt(2*np.pi)) * np.exp(-0.5 * x**2)\n\ndef integrate_with_error_estimation(func, a, b):\n    integral, error = quad(func, a, b)\n    return integral, error\n\nresult, error_estimate = integrate_with_error_estimation(gaussian, -np.inf, np.inf)\nprint('Integral:', result)\nprint('Estimated Error:', error_estimate)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.022222222222222223,
      "execution_result": {
        "success": true,
        "output": "Integral: 0.9999999999999997\nEstimated Error: 1.017819145094224e-08",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Integral: 0.9999999999999997\nEstimated Error: 1.017819145094224e-08",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Implement a matrix operation class with optimized algorithms",
    "code_form": "computational class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to implement a matrix operation class with optimized algorithms.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom typing import List, Union\n\nclass MatrixOperations:\n    \"\"\"\n    A class to perform optimized matrix operations such as addition and multiplication.\n    This class uses NumPy for efficient computation, suitable for large-scale datasets.\n    \"\"\"\n\n    def __init__(self, matrix: List[List[Union[int, float]]]) -> None:\n        \"\"\"\n        Initializes the MatrixOperations instance with a given matrix.\n        \n        Args:\n            matrix (List[List[Union[int, float]]]): A 2D list representing the matrix.\n        \"\"\"\n        self.matrix = np.array(matrix)\n\n    def add(self, other: 'MatrixOperations') -> np.ndarray:\n        \"\"\"\n        Adds the current matrix with another matrix.\n        \n        Args:\n            other (MatrixOperations): Another instance of MatrixOperations to add.\n        \n        Returns:\n            np.ndarray: The resulting matrix after addition.\n        \"\"\"\n        return self.matrix + other.matrix\n\n    def multiply(self, other: 'MatrixOperations') -> np.ndarray:\n        \"\"\"\n        Multiplies the current matrix with another matrix.\n        \n        Args:\n            other (MatrixOperations): Another instance of MatrixOperations to multiply.\n        \n        Returns:\n            np.ndarray: The resulting matrix after multiplication.\n        \"\"\"\n        return np.dot(self.matrix, other.matrix)\n\n# Example usage:\nmatrix1 = MatrixOperations([[1, 2], [3, 4]])\nmatrix2 = MatrixOperations([[5, 6], [7, 8]])\nresult_add = matrix1.add(matrix2)\nresult_multiply = matrix1.multiply(matrix2)\nprint(\"Addition Result:\", result_add)\nprint(\"Multiplication Result:\", result_multiply)",
    "rejected_code": "import numpy as np\n\nclass MatrixOperations:\n    def __init__(self, matrix):\n        self.matrix = np.array(matrix)\n\n    def add(self, other):\n        return self.matrix + other.matrix\n\n    def multiply(self, other):\n        return np.dot(self.matrix, other.matrix)\n\n# Example usage:\nmatrix1 = MatrixOperations([[1, 2], [3, 4]])\nmatrix2 = MatrixOperations([[5, 6], [7, 8]])\nresult_add = matrix1.add(matrix2)\nresult_multiply = matrix1.multiply(matrix2)\nprint(result_add)\nprint(result_multiply)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.02040816326530612,
      "execution_result": {
        "success": true,
        "output": "Addition Result: [[ 6  8]\n [10 12]]\nMultiplication Result: [[19 22]\n [43 50]]",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.05263157894736842,
      "execution_result": {
        "success": true,
        "output": "[[ 6  8]\n [10 12]]\n[[19 22]\n [43 50]]",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Implement a matrix operation class with optimized algorithms",
    "code_form": "computational class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class to perform matrix operations with optimized algorithms.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom typing import List, Union\n\nclass MatrixOperations:\n    \"\"\"\n    A class to perform optimized matrix operations such as addition and multiplication.\n    This class uses NumPy for efficient computation, suitable for large-scale datasets.\n    \"\"\"\n\n    def __init__(self, matrix: List[List[Union[int, float]]]) -> None:\n        \"\"\"\n        Initializes the MatrixOperations instance with a given matrix.\n        \n        Args:\n            matrix (List[List[Union[int, float]]]): A 2D list representing the matrix.\n        \"\"\"\n        self.matrix = np.array(matrix)\n\n    def add(self, other: 'MatrixOperations') -> np.ndarray:\n        \"\"\"\n        Adds the current matrix with another matrix.\n        \n        Args:\n            other (MatrixOperations): Another instance of MatrixOperations to add.\n        \n        Returns:\n            np.ndarray: The resulting matrix after addition.\n        \"\"\"\n        return self.matrix + other.matrix\n\n    def multiply(self, other: 'MatrixOperations') -> np.ndarray:\n        \"\"\"\n        Multiplies the current matrix with another matrix.\n        \n        Args:\n            other (MatrixOperations): Another instance of MatrixOperations to multiply.\n        \n        Returns:\n            np.ndarray: The resulting matrix after multiplication.\n        \"\"\"\n        return np.dot(self.matrix, other.matrix)\n\n# Example usage:\nmatrix1 = MatrixOperations([[1, 2], [3, 4]])\nmatrix2 = MatrixOperations([[5, 6], [7, 8]])\nresult_add = matrix1.add(matrix2)\nresult_multiply = matrix1.multiply(matrix2)\nprint(\"Addition Result:\", result_add)\nprint(\"Multiplication Result:\", result_multiply)",
    "rejected_code": "import numpy as np\n\nclass MatrixOperations:\n    def __init__(self, matrix):\n        self.matrix = np.array(matrix)\n\n    def add(self, other):\n        return self.matrix + other.matrix\n\n    def multiply(self, other):\n        return np.dot(self.matrix, other.matrix)\n\n# Example usage:\nmatrix1 = MatrixOperations([[1, 2], [3, 4]])\nmatrix2 = MatrixOperations([[5, 6], [7, 8]])\nresult_add = matrix1.add(matrix2)\nresult_multiply = matrix1.multiply(matrix2)\nprint(result_add)\nprint(result_multiply)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.02040816326530612,
      "execution_result": {
        "success": true,
        "output": "Addition Result: [[ 6  8]\n [10 12]]\nMultiplication Result: [[19 22]\n [43 50]]",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.05263157894736842,
      "execution_result": {
        "success": true,
        "output": "[[ 6  8]\n [10 12]]\n[[19 22]\n [43 50]]",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Implement a matrix operation class with optimized algorithms",
    "code_form": "computational class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please create a class that performs matrix operations, specifying input as a list of lists and output as a NumPy array.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom typing import List, Union\n\nclass MatrixOperations:\n    \"\"\"\n    A class to perform optimized matrix operations such as addition and multiplication.\n    This class uses NumPy for efficient computation, suitable for large-scale datasets.\n    \"\"\"\n\n    def __init__(self, matrix: List[List[Union[int, float]]]) -> None:\n        \"\"\"\n        Initializes the MatrixOperations instance with a given matrix.\n        \n        Args:\n            matrix (List[List[Union[int, float]]]): A 2D list representing the matrix.\n        \"\"\"\n        self.matrix = np.array(matrix)\n\n    def add(self, other: 'MatrixOperations') -> np.ndarray:\n        \"\"\"\n        Adds the current matrix with another matrix.\n        \n        Args:\n            other (MatrixOperations): Another instance of MatrixOperations to add.\n        \n        Returns:\n            np.ndarray: The resulting matrix after addition.\n        \"\"\"\n        return self.matrix + other.matrix\n\n    def multiply(self, other: 'MatrixOperations') -> np.ndarray:\n        \"\"\"\n        Multiplies the current matrix with another matrix.\n        \n        Args:\n            other (MatrixOperations): Another instance of MatrixOperations to multiply.\n        \n        Returns:\n            np.ndarray: The resulting matrix after multiplication.\n        \"\"\"\n        return np.dot(self.matrix, other.matrix)\n\n# Example usage:\nmatrix1 = MatrixOperations([[1, 2], [3, 4]])\nmatrix2 = MatrixOperations([[5, 6], [7, 8]])\nresult_add = matrix1.add(matrix2)\nresult_multiply = matrix1.multiply(matrix2)\nprint(\"Addition Result:\", result_add)\nprint(\"Multiplication Result:\", result_multiply)",
    "rejected_code": "import numpy as np\n\nclass MatrixOperations:\n    def __init__(self, matrix):\n        self.matrix = np.array(matrix)\n\n    def add(self, other):\n        return self.matrix + other.matrix\n\n    def multiply(self, other):\n        return np.dot(self.matrix, other.matrix)\n\n# Example usage:\nmatrix1 = MatrixOperations([[1, 2], [3, 4]])\nmatrix2 = MatrixOperations([[5, 6], [7, 8]])\nresult_add = matrix1.add(matrix2)\nresult_multiply = matrix1.multiply(matrix2)\nprint(result_add)\nprint(result_multiply)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.02040816326530612,
      "execution_result": {
        "success": true,
        "output": "Addition Result: [[ 6  8]\n [10 12]]\nMultiplication Result: [[19 22]\n [43 50]]",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.05263157894736842,
      "execution_result": {
        "success": true,
        "output": "[[ 6  8]\n [10 12]]\n[[19 22]\n [43 50]]",
        "error": ""
      }
    }
  },
  {
    "domain": "database",
    "task": "Develop a data access object class with CRUD operations",
    "code_form": "dao class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to implement a data access object class with CRUD operations for a library system managing books?",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, Column, Integer, String, Sequence\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session as SQLAlchemySession\nfrom typing import Optional, Union\n\n# Create a base class for declarative models\nBase = declarative_base()\n\nclass Book(Base):\n    __tablename__ = 'books'\n    id = Column(Integer, Sequence('book_id_seq'), primary_key=True)\n    title = Column(String(100), nullable=False)\n    author = Column(String(100), nullable=False)\n    year = Column(Integer, nullable=False)\n\nclass BookDAO:\n    def __init__(self, db_url: str) -> None:\n        \"\"\"Initialize the Book Data Access Object with a database URL.\"\"\"\n        self.engine = create_engine(db_url)\n        Base.metadata.create_all(self.engine)\n        self.Session = sessionmaker(bind=self.engine)\n\n    def add_book(self, title: str, author: str, year: int) -> None:\n        \"\"\"Add a new book to the database.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        new_book = Book(title=title, author=author, year=year)\n        session.add(new_book)\n        session.commit()\n        session.close()\n\n    def get_book(self, book_id: int) -> Optional[Book]:\n        \"\"\"Retrieve a book by its ID. Returns None if not found.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        session.close()\n        return book\n\n    def update_book(self, book_id: int, title: str, author: str, year: int) -> None:\n        \"\"\"Update the details of an existing book.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            book.title = title\n            book.author = author\n            book.year = year\n            session.commit()\n        session.close()\n\n    def delete_book(self, book_id: int) -> None:\n        \"\"\"Delete a book from the database by its ID.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            session.delete(book)\n            session.commit()\n        session.close()\n\n# Example usage\n# dao = BookDAO('sqlite:///library.db')\n# dao.add_book('1984', 'George Orwell', 1949)\n# print(dao.get_book(1))\n# dao.update_book(1, '1984', 'George Orwell', 1950)\n# dao.delete_book(1)",
    "rejected_code": "from sqlalchemy import create_engine, Column, Integer, String, Sequence\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nBase = declarative_base()\n\nclass Book(Base):\n    __tablename__ = 'books'\n    id = Column(Integer, Sequence('book_id_seq'), primary_key=True)\n    title = Column(String(100))\n    author = Column(String(100))\n    year = Column(Integer)\n\nclass BookDAO:\n    def __init__(self, db_url):\n        self.engine = create_engine(db_url)\n        Base.metadata.create_all(self.engine)\n        self.Session = sessionmaker(bind=self.engine)\n\n    def add_book(self, title, author, year):\n        session = self.Session()\n        new_book = Book(title=title, author=author, year=year)\n        session.add(new_book)\n        session.commit()\n        session.close()\n\n    def get_book(self, book_id):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        session.close()\n        return book\n\n    def update_book(self, book_id, title, author, year):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            book.title = title\n            book.author = author\n            book.year = year\n            session.commit()\n        session.close()\n\n    def delete_book(self, book_id):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            session.delete(book)\n            session.commit()\n        session.close()\n\n# Example usage\n# dao = BookDAO('sqlite:///library.db')\n# dao.add_book('1984', 'George Orwell', 1949)\n# print(dao.get_book(1))\n# dao.update_book(1, '1984', 'George Orwell', 1950)\n# dao.delete_book(1)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.1111111111111111,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.10714285714285714,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Develop a data access object class with CRUD operations",
    "code_form": "dao class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python class that implements a data access object with CRUD operations for a library system managing books.",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, Column, Integer, String, Sequence\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session as SQLAlchemySession\nfrom typing import Optional, Union\n\n# Create a base class for declarative models\nBase = declarative_base()\n\nclass Book(Base):\n    __tablename__ = 'books'\n    id = Column(Integer, Sequence('book_id_seq'), primary_key=True)\n    title = Column(String(100), nullable=False)\n    author = Column(String(100), nullable=False)\n    year = Column(Integer, nullable=False)\n\nclass BookDAO:\n    def __init__(self, db_url: str) -> None:\n        \"\"\"Initialize the Book Data Access Object with a database URL.\"\"\"\n        self.engine = create_engine(db_url)\n        Base.metadata.create_all(self.engine)\n        self.Session = sessionmaker(bind=self.engine)\n\n    def add_book(self, title: str, author: str, year: int) -> None:\n        \"\"\"Add a new book to the database.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        new_book = Book(title=title, author=author, year=year)\n        session.add(new_book)\n        session.commit()\n        session.close()\n\n    def get_book(self, book_id: int) -> Optional[Book]:\n        \"\"\"Retrieve a book by its ID. Returns None if not found.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        session.close()\n        return book\n\n    def update_book(self, book_id: int, title: str, author: str, year: int) -> None:\n        \"\"\"Update the details of an existing book.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            book.title = title\n            book.author = author\n            book.year = year\n            session.commit()\n        session.close()\n\n    def delete_book(self, book_id: int) -> None:\n        \"\"\"Delete a book from the database by its ID.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            session.delete(book)\n            session.commit()\n        session.close()\n\n# Example usage\n# dao = BookDAO('sqlite:///library.db')\n# dao.add_book('1984', 'George Orwell', 1949)\n# print(dao.get_book(1))\n# dao.update_book(1, '1984', 'George Orwell', 1950)\n# dao.delete_book(1)",
    "rejected_code": "from sqlalchemy import create_engine, Column, Integer, String, Sequence\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nBase = declarative_base()\n\nclass Book(Base):\n    __tablename__ = 'books'\n    id = Column(Integer, Sequence('book_id_seq'), primary_key=True)\n    title = Column(String(100))\n    author = Column(String(100))\n    year = Column(Integer)\n\nclass BookDAO:\n    def __init__(self, db_url):\n        self.engine = create_engine(db_url)\n        Base.metadata.create_all(self.engine)\n        self.Session = sessionmaker(bind=self.engine)\n\n    def add_book(self, title, author, year):\n        session = self.Session()\n        new_book = Book(title=title, author=author, year=year)\n        session.add(new_book)\n        session.commit()\n        session.close()\n\n    def get_book(self, book_id):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        session.close()\n        return book\n\n    def update_book(self, book_id, title, author, year):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            book.title = title\n            book.author = author\n            book.year = year\n            session.commit()\n        session.close()\n\n    def delete_book(self, book_id):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            session.delete(book)\n            session.commit()\n        session.close()\n\n# Example usage\n# dao = BookDAO('sqlite:///library.db')\n# dao.add_book('1984', 'George Orwell', 1949)\n# print(dao.get_book(1))\n# dao.update_book(1, '1984', 'George Orwell', 1950)\n# dao.delete_book(1)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.1111111111111111,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.10714285714285714,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "database",
    "task": "Develop a data access object class with CRUD operations",
    "code_form": "dao class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you write a Python class that implements a data access object with CRUD operations for a library system managing books, specifying input and output types?",
      "role": "user"
    },
    "chosen_code": "from sqlalchemy import create_engine, Column, Integer, String, Sequence\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, Session as SQLAlchemySession\nfrom typing import Optional, Union\n\n# Create a base class for declarative models\nBase = declarative_base()\n\nclass Book(Base):\n    __tablename__ = 'books'\n    id = Column(Integer, Sequence('book_id_seq'), primary_key=True)\n    title = Column(String(100), nullable=False)\n    author = Column(String(100), nullable=False)\n    year = Column(Integer, nullable=False)\n\nclass BookDAO:\n    def __init__(self, db_url: str) -> None:\n        \"\"\"Initialize the Book Data Access Object with a database URL.\"\"\"\n        self.engine = create_engine(db_url)\n        Base.metadata.create_all(self.engine)\n        self.Session = sessionmaker(bind=self.engine)\n\n    def add_book(self, title: str, author: str, year: int) -> None:\n        \"\"\"Add a new book to the database.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        new_book = Book(title=title, author=author, year=year)\n        session.add(new_book)\n        session.commit()\n        session.close()\n\n    def get_book(self, book_id: int) -> Optional[Book]:\n        \"\"\"Retrieve a book by its ID. Returns None if not found.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        session.close()\n        return book\n\n    def update_book(self, book_id: int, title: str, author: str, year: int) -> None:\n        \"\"\"Update the details of an existing book.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            book.title = title\n            book.author = author\n            book.year = year\n            session.commit()\n        session.close()\n\n    def delete_book(self, book_id: int) -> None:\n        \"\"\"Delete a book from the database by its ID.\"\"\"\n        session: SQLAlchemySession = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            session.delete(book)\n            session.commit()\n        session.close()\n\n# Example usage\n# dao = BookDAO('sqlite:///library.db')\n# dao.add_book('1984', 'George Orwell', 1949)\n# print(dao.get_book(1))\n# dao.update_book(1, '1984', 'George Orwell', 1950)\n# dao.delete_book(1)",
    "rejected_code": "from sqlalchemy import create_engine, Column, Integer, String, Sequence\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nBase = declarative_base()\n\nclass Book(Base):\n    __tablename__ = 'books'\n    id = Column(Integer, Sequence('book_id_seq'), primary_key=True)\n    title = Column(String(100))\n    author = Column(String(100))\n    year = Column(Integer)\n\nclass BookDAO:\n    def __init__(self, db_url):\n        self.engine = create_engine(db_url)\n        Base.metadata.create_all(self.engine)\n        self.Session = sessionmaker(bind=self.engine)\n\n    def add_book(self, title, author, year):\n        session = self.Session()\n        new_book = Book(title=title, author=author, year=year)\n        session.add(new_book)\n        session.commit()\n        session.close()\n\n    def get_book(self, book_id):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        session.close()\n        return book\n\n    def update_book(self, book_id, title, author, year):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            book.title = title\n            book.author = author\n            book.year = year\n            session.commit()\n        session.close()\n\n    def delete_book(self, book_id):\n        session = self.Session()\n        book = session.query(Book).filter(Book.id == book_id).first()\n        if book:\n            session.delete(book)\n            session.commit()\n        session.close()\n\n# Example usage\n# dao = BookDAO('sqlite:///library.db')\n# dao.add_book('1984', 'George Orwell', 1949)\n# print(dao.get_book(1))\n# dao.update_book(1, '1984', 'George Orwell', 1950)\n# dao.delete_book(1)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.1111111111111111,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.10714285714285714,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'sqlalchemy'"
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Build a statistical hypothesis testing function with multiple methods",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to perform statistical hypothesis testing for a drug effect compared to a placebo using multiple methods.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy import stats\nfrom typing import Dict, Tuple, Any\n\n\ndef hypothesis_testing(drug_data: np.ndarray, placebo_data: np.ndarray) -> Dict[str, Tuple[float, float]]:\n    \"\"\"\n    Performs statistical hypothesis testing to compare the effects of a new drug against a placebo.\n    \n    Parameters:\n    drug_data (np.ndarray): Array of blood pressure readings from the drug group.\n    placebo_data (np.ndarray): Array of blood pressure readings from the placebo group.\n    \n    Returns:\n    Dict[str, Tuple[float, float]]: A dictionary containing the results of the statistical tests,\n    where each key is the name of the test and the value is a tuple containing the test statistic and p-value.\n    \"\"\"\n    results: Dict[str, Tuple[float, float]] = {}\n    \n    # Perform t-test\n    t_stat, t_p_value = stats.ttest_ind(drug_data, placebo_data)\n    results['t_test'] = (t_stat, t_p_value)\n    \n    # Perform Mann-Whitney U test\n    mw_stat, mw_p_value = stats.mannwhitneyu(drug_data, placebo_data)\n    results['mann_whitney'] = (mw_stat, mw_p_value)\n    \n    # Perform ANOVA test\n    f_stat, anova_p_value = stats.f_oneway(drug_data, placebo_data)\n    results['anova'] = (f_stat, anova_p_value)\n    \n    return results\n\n# Generate synthetic data for testing\nnp.random.seed(0)  # For reproducibility\n\ndrug_group = np.random.normal(loc=120, scale=10, size=30)\nplacebo_group = np.random.normal(loc=130, scale=10, size=30)\n\n# Execute hypothesis testing\nresults = hypothesis_testing(drug_group, placebo_group)\nprint(results)",
    "rejected_code": "import numpy as np\nfrom scipy import stats\n\ndef hypothesis_testing(drug_data, placebo_data):\n    results = {}\n    results['t_test'] = stats.ttest_ind(drug_data, placebo_data)\n    results['mann_whitney'] = stats.mannwhitneyu(drug_data, placebo_data)\n    f_stat, p_value = stats.f_oneway(drug_data, placebo_data)\n    results['anova'] = (f_stat, p_value)\n    return results\n\ndrug_group = np.random.normal(loc=120, scale=10, size=30)\nplacebo_group = np.random.normal(loc=130, scale=10, size=30)\n\nresults = hypothesis_testing(drug_group, placebo_group)\nprint(results)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.11904761904761904,
      "execution_result": {
        "success": true,
        "output": "{'t_test': (-1.024637558597005, 0.3097888645046585), 'mann_whitney': (401.0, 0.47334655725844954), 'anova': (1.0498821264876272, 0.30978886450466037)}",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'t_test': TtestResult(statistic=-5.5416111449795205, pvalue=7.659951921449201e-07, df=58.0), 'mann_whitney': MannwhitneyuResult(statistic=143.0, pvalue=5.858675152587995e-06), 'anova': (30.709454082161276, 7.659951921449094e-07)}",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Build a statistical hypothesis testing function with multiple methods",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a function to perform statistical hypothesis testing for a drug effect compared to a placebo using multiple methods.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy import stats\nfrom typing import Dict, Tuple, Any\n\n\ndef hypothesis_testing(drug_data: np.ndarray, placebo_data: np.ndarray) -> Dict[str, Tuple[float, float]]:\n    \"\"\"\n    Performs statistical hypothesis testing to compare the effects of a new drug against a placebo.\n    \n    Parameters:\n    drug_data (np.ndarray): Array of blood pressure readings from the drug group.\n    placebo_data (np.ndarray): Array of blood pressure readings from the placebo group.\n    \n    Returns:\n    Dict[str, Tuple[float, float]]: A dictionary containing the results of the statistical tests,\n    where each key is the name of the test and the value is a tuple containing the test statistic and p-value.\n    \"\"\"\n    results: Dict[str, Tuple[float, float]] = {}\n    \n    # Perform t-test\n    t_stat, t_p_value = stats.ttest_ind(drug_data, placebo_data)\n    results['t_test'] = (t_stat, t_p_value)\n    \n    # Perform Mann-Whitney U test\n    mw_stat, mw_p_value = stats.mannwhitneyu(drug_data, placebo_data)\n    results['mann_whitney'] = (mw_stat, mw_p_value)\n    \n    # Perform ANOVA test\n    f_stat, anova_p_value = stats.f_oneway(drug_data, placebo_data)\n    results['anova'] = (f_stat, anova_p_value)\n    \n    return results\n\n# Generate synthetic data for testing\nnp.random.seed(0)  # For reproducibility\n\ndrug_group = np.random.normal(loc=120, scale=10, size=30)\nplacebo_group = np.random.normal(loc=130, scale=10, size=30)\n\n# Execute hypothesis testing\nresults = hypothesis_testing(drug_group, placebo_group)\nprint(results)",
    "rejected_code": "import numpy as np\nfrom scipy import stats\n\ndef hypothesis_testing(drug_data, placebo_data):\n    results = {}\n    results['t_test'] = stats.ttest_ind(drug_data, placebo_data)\n    results['mann_whitney'] = stats.mannwhitneyu(drug_data, placebo_data)\n    f_stat, p_value = stats.f_oneway(drug_data, placebo_data)\n    results['anova'] = (f_stat, p_value)\n    return results\n\ndrug_group = np.random.normal(loc=120, scale=10, size=30)\nplacebo_group = np.random.normal(loc=130, scale=10, size=30)\n\nresults = hypothesis_testing(drug_group, placebo_group)\nprint(results)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.11904761904761904,
      "execution_result": {
        "success": true,
        "output": "{'t_test': (-1.024637558597005, 0.3097888645046585), 'mann_whitney': (401.0, 0.47334655725844954), 'anova': (1.0498821264876272, 0.30978886450466037)}",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'t_test': TtestResult(statistic=-3.9534983151583667, pvalue=0.0002118381542788876, df=58.0), 'mann_whitney': MannwhitneyuResult(statistic=213.0, pvalue=0.0004713751442131583), 'anova': (15.630148927960159, 0.00021183815427887733)}",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Build a statistical hypothesis testing function with multiple methods",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a function that takes in two numpy arrays (drug_data and placebo_data) and returns a dictionary with statistical test results for hypothesis testing.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy import stats\nfrom typing import Dict, Tuple, Any\n\n\ndef hypothesis_testing(drug_data: np.ndarray, placebo_data: np.ndarray) -> Dict[str, Tuple[float, float]]:\n    \"\"\"\n    Performs statistical hypothesis testing to compare the effects of a new drug against a placebo.\n    \n    Parameters:\n    drug_data (np.ndarray): Array of blood pressure readings from the drug group.\n    placebo_data (np.ndarray): Array of blood pressure readings from the placebo group.\n    \n    Returns:\n    Dict[str, Tuple[float, float]]: A dictionary containing the results of the statistical tests,\n    where each key is the name of the test and the value is a tuple containing the test statistic and p-value.\n    \"\"\"\n    results: Dict[str, Tuple[float, float]] = {}\n    \n    # Perform t-test\n    t_stat, t_p_value = stats.ttest_ind(drug_data, placebo_data)\n    results['t_test'] = (t_stat, t_p_value)\n    \n    # Perform Mann-Whitney U test\n    mw_stat, mw_p_value = stats.mannwhitneyu(drug_data, placebo_data)\n    results['mann_whitney'] = (mw_stat, mw_p_value)\n    \n    # Perform ANOVA test\n    f_stat, anova_p_value = stats.f_oneway(drug_data, placebo_data)\n    results['anova'] = (f_stat, anova_p_value)\n    \n    return results\n\n# Generate synthetic data for testing\nnp.random.seed(0)  # For reproducibility\n\ndrug_group = np.random.normal(loc=120, scale=10, size=30)\nplacebo_group = np.random.normal(loc=130, scale=10, size=30)\n\n# Execute hypothesis testing\nresults = hypothesis_testing(drug_group, placebo_group)\nprint(results)",
    "rejected_code": "import numpy as np\nfrom scipy import stats\n\ndef hypothesis_testing(drug_data, placebo_data):\n    results = {}\n    results['t_test'] = stats.ttest_ind(drug_data, placebo_data)\n    results['mann_whitney'] = stats.mannwhitneyu(drug_data, placebo_data)\n    f_stat, p_value = stats.f_oneway(drug_data, placebo_data)\n    results['anova'] = (f_stat, p_value)\n    return results\n\ndrug_group = np.random.normal(loc=120, scale=10, size=30)\nplacebo_group = np.random.normal(loc=130, scale=10, size=30)\n\nresults = hypothesis_testing(drug_group, placebo_group)\nprint(results)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.11904761904761904,
      "execution_result": {
        "success": true,
        "output": "{'t_test': (-1.024637558597005, 0.3097888645046585), 'mann_whitney': (401.0, 0.47334655725844954), 'anova': (1.0498821264876272, 0.30978886450466037)}",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'t_test': TtestResult(statistic=-3.450308465332131, pvalue=0.001050447443340477, df=58.0), 'mann_whitney': MannwhitneyuResult(statistic=222.0, pvalue=0.0007697288698323855), 'anova': (11.904628505942588, 0.0010504474433404712)}",
        "error": ""
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Build an image transformation pipeline with multiple filters",
    "code_form": "processor class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide code to build an image transformation pipeline with multiple filters?",
      "role": "user"
    },
    "chosen_code": "from PIL import Image, ImageFilter, ImageEnhance\nfrom typing import Tuple, Union\n\nclass ImageProcessor:\n    \"\"\"\n    A class to process images with various transformations such as resizing,\n    blurring, and enhancing colors for better presentation on social media.\n    \"\"\"\n\n    def __init__(self, image_path: str) -> None:\n        \"\"\"\n        Initialize the ImageProcessor with an image from the specified path.\n        \n        :param image_path: Path to the image file.\n        \"\"\"\n        self.image: Image.Image = Image.open(image_path)\n\n    def resize(self, size: Tuple[int, int]) -> None:\n        \"\"\"\n        Resize the image to the given dimensions.\n        \n        :param size: A tuple containing the new width and height.\n        \"\"\"\n        self.image = self.image.resize(size)\n\n    def blur(self, radius: float) -> None:\n        \"\"\"\n        Apply a Gaussian blur filter to the image.\n        \n        :param radius: The radius of the blur effect.\n        \"\"\"\n        self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\n\n    def enhance_colors(self, factor: float) -> None:\n        \"\"\"\n        Enhance the color of the image by a specified factor.\n        \n        :param factor: A factor to enhance the colors (1.0 means no change).\n        \"\"\"\n        enhancer = ImageEnhance.Color(self.image)\n        self.image = enhancer.enhance(factor)\n\n    def save(self, output_path: str) -> None:\n        \"\"\"\n        Save the processed image to the specified path.\n        \n        :param output_path: Path where the processed image will be saved.\n        \"\"\"\n        self.image.save(output_path)\n\n\n# Example usage of the ImageProcessor class\nif __name__ == '__main__':\n    pipeline = ImageProcessor('portrait.jpg')\n    pipeline.resize((800, 800))  # Resize to 800x800 pixels\n    pipeline.blur(5)              # Apply a blur with a radius of 5\n    pipeline.enhance_colors(1.5)  # Enhance colors by a factor of 1.5\n    pipeline.save('enhanced_portrait.jpg')  # Save the enhanced image",
    "rejected_code": "from PIL import Image, ImageFilter, ImageEnhance\n\nclass ImageProcessor:\n    def __init__(self, image_path):\n        self.image = Image.open(image_path)\n\n    def resize(self, size):\n        self.image = self.image.resize(size)\n\n    def blur(self, radius):\n        self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\n\n    def enhance_colors(self, factor):\n        enhancer = ImageEnhance.Color(self.image)\n        self.image = enhancer.enhance(factor)\n\n    def save(self, output_path):\n        self.image.save(output_path)\n\npipeline = ImageProcessor('portrait.jpg')\npipeline.resize((800, 800))\npipeline.blur(5)\npipeline.enhance_colors(1.5)\npipeline.save('enhanced_portrait.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.017241379310344827,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 54, in <module>\n  File \"<string>\", line 16, in __init__\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'portrait.jpg'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 5, in __init__\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'portrait.jpg'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Build an image transformation pipeline with multiple filters",
    "code_form": "processor class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you provide a class-based implementation of an image transformation pipeline with multiple filters?",
      "role": "user"
    },
    "chosen_code": "from PIL import Image, ImageFilter, ImageEnhance\nfrom typing import Tuple, Union\n\nclass ImageProcessor:\n    \"\"\"\n    A class to process images with various transformations such as resizing,\n    blurring, and enhancing colors for better presentation on social media.\n    \"\"\"\n\n    def __init__(self, image_path: str) -> None:\n        \"\"\"\n        Initialize the ImageProcessor with an image from the specified path.\n        \n        :param image_path: Path to the image file.\n        \"\"\"\n        self.image: Image.Image = Image.open(image_path)\n\n    def resize(self, size: Tuple[int, int]) -> None:\n        \"\"\"\n        Resize the image to the given dimensions.\n        \n        :param size: A tuple containing the new width and height.\n        \"\"\"\n        self.image = self.image.resize(size)\n\n    def blur(self, radius: float) -> None:\n        \"\"\"\n        Apply a Gaussian blur filter to the image.\n        \n        :param radius: The radius of the blur effect.\n        \"\"\"\n        self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\n\n    def enhance_colors(self, factor: float) -> None:\n        \"\"\"\n        Enhance the color of the image by a specified factor.\n        \n        :param factor: A factor to enhance the colors (1.0 means no change).\n        \"\"\"\n        enhancer = ImageEnhance.Color(self.image)\n        self.image = enhancer.enhance(factor)\n\n    def save(self, output_path: str) -> None:\n        \"\"\"\n        Save the processed image to the specified path.\n        \n        :param output_path: Path where the processed image will be saved.\n        \"\"\"\n        self.image.save(output_path)\n\n\n# Example usage of the ImageProcessor class\nif __name__ == '__main__':\n    pipeline = ImageProcessor('portrait.jpg')\n    pipeline.resize((800, 800))  # Resize to 800x800 pixels\n    pipeline.blur(5)              # Apply a blur with a radius of 5\n    pipeline.enhance_colors(1.5)  # Enhance colors by a factor of 1.5\n    pipeline.save('enhanced_portrait.jpg')  # Save the enhanced image",
    "rejected_code": "from PIL import Image, ImageFilter, ImageEnhance\n\nclass ImageProcessor:\n    def __init__(self, image_path):\n        self.image = Image.open(image_path)\n\n    def resize(self, size):\n        self.image = self.image.resize(size)\n\n    def blur(self, radius):\n        self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\n\n    def enhance_colors(self, factor):\n        enhancer = ImageEnhance.Color(self.image)\n        self.image = enhancer.enhance(factor)\n\n    def save(self, output_path):\n        self.image.save(output_path)\n\npipeline = ImageProcessor('portrait.jpg')\npipeline.resize((800, 800))\npipeline.blur(5)\npipeline.enhance_colors(1.5)\npipeline.save('enhanced_portrait.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.017241379310344827,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 54, in <module>\n  File \"<string>\", line 16, in __init__\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'portrait.jpg'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 5, in __init__\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'portrait.jpg'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Build an image transformation pipeline with multiple filters",
    "code_form": "processor class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you provide a class-based implementation of an image transformation pipeline that takes input as a string for the image path and outputs a processed image file?",
      "role": "user"
    },
    "chosen_code": "from PIL import Image, ImageFilter, ImageEnhance\nfrom typing import Tuple, Union\n\nclass ImageProcessor:\n    \"\"\"\n    A class to process images with various transformations such as resizing,\n    blurring, and enhancing colors for better presentation on social media.\n    \"\"\"\n\n    def __init__(self, image_path: str) -> None:\n        \"\"\"\n        Initialize the ImageProcessor with an image from the specified path.\n        \n        :param image_path: Path to the image file.\n        \"\"\"\n        self.image: Image.Image = Image.open(image_path)\n\n    def resize(self, size: Tuple[int, int]) -> None:\n        \"\"\"\n        Resize the image to the given dimensions.\n        \n        :param size: A tuple containing the new width and height.\n        \"\"\"\n        self.image = self.image.resize(size)\n\n    def blur(self, radius: float) -> None:\n        \"\"\"\n        Apply a Gaussian blur filter to the image.\n        \n        :param radius: The radius of the blur effect.\n        \"\"\"\n        self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\n\n    def enhance_colors(self, factor: float) -> None:\n        \"\"\"\n        Enhance the color of the image by a specified factor.\n        \n        :param factor: A factor to enhance the colors (1.0 means no change).\n        \"\"\"\n        enhancer = ImageEnhance.Color(self.image)\n        self.image = enhancer.enhance(factor)\n\n    def save(self, output_path: str) -> None:\n        \"\"\"\n        Save the processed image to the specified path.\n        \n        :param output_path: Path where the processed image will be saved.\n        \"\"\"\n        self.image.save(output_path)\n\n\n# Example usage of the ImageProcessor class\nif __name__ == '__main__':\n    pipeline = ImageProcessor('portrait.jpg')\n    pipeline.resize((800, 800))  # Resize to 800x800 pixels\n    pipeline.blur(5)              # Apply a blur with a radius of 5\n    pipeline.enhance_colors(1.5)  # Enhance colors by a factor of 1.5\n    pipeline.save('enhanced_portrait.jpg')  # Save the enhanced image",
    "rejected_code": "from PIL import Image, ImageFilter, ImageEnhance\n\nclass ImageProcessor:\n    def __init__(self, image_path):\n        self.image = Image.open(image_path)\n\n    def resize(self, size):\n        self.image = self.image.resize(size)\n\n    def blur(self, radius):\n        self.image = self.image.filter(ImageFilter.GaussianBlur(radius))\n\n    def enhance_colors(self, factor):\n        enhancer = ImageEnhance.Color(self.image)\n        self.image = enhancer.enhance(factor)\n\n    def save(self, output_path):\n        self.image.save(output_path)\n\npipeline = ImageProcessor('portrait.jpg')\npipeline.resize((800, 800))\npipeline.blur(5)\npipeline.enhance_colors(1.5)\npipeline.save('enhanced_portrait.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.017241379310344827,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 54, in <module>\n  File \"<string>\", line 16, in __init__\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'portrait.jpg'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 5, in __init__\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'portrait.jpg'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Implement a feature extraction function for image classification",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to implement a feature extraction function for image classification in the context of clothing items.",
      "role": "user"
    },
    "chosen_code": "from PIL import Image\nimport numpy as np\nfrom skimage import feature\nfrom typing import Any, Union\n\n\ndef extract_features(image_path: str) -> np.ndarray:\n    \"\"\"\n    Extracts numerical features from an image for classification purposes.\n\n    This function computes color histograms and texture patterns from the given image,\n    which can be used as features for machine learning models.\n\n    Args:\n        image_path (str): The file path to the image from which to extract features.\n\n    Returns:\n        np.ndarray: A concatenated array of color histogram and texture features.\n    \"\"\"\n    # Open the image and resize it to a fixed size\n    image: Image.Image = Image.open(image_path)\n    image = image.resize((128, 128))\n\n    # Convert the image to a numpy array for processing\n    image_array: np.ndarray = np.array(image)\n\n    # Calculate the color histogram with 32 bins\n    color_hist, _ = np.histogram(image_array[:, :, :3], bins=32, range=(0, 256))\n    # Normalize the histogram\n    color_hist = color_hist / np.sum(color_hist) if np.sum(color_hist) > 0 else color_hist\n\n    # Convert the image to grayscale using luminosity method\n    gray_image: np.ndarray = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n\n    # Extract texture features using Local Binary Pattern\n    texture_features: np.ndarray = feature.local_binary_pattern(gray_image, P=8, R=1, method='uniform')\n    texture_hist, _ = np.histogram(texture_features, bins=np.arange(0, 11), density=True)\n\n    # Return concatenated features\n    return np.concatenate((color_hist, texture_hist))\n\n# Example usage:\n# features: np.ndarray = extract_features('path/to/clothing/image.jpg')",
    "rejected_code": "from PIL import Image\nimport numpy as np\nfrom skimage import feature\n\ndef extract_features(image_path):\n    image = Image.open(image_path)\n    image = image.resize((128, 128))\n    image_array = np.array(image)\n    color_hist = np.histogram(image_array[:, :, :3], bins=32, range=(0, 256))[0]\n    color_hist = color_hist / np.sum(color_hist)\n    gray_image = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n    texture_features = feature.local_binary_pattern(gray_image, P=8, R=1, method='uniform')\n    texture_hist, _ = np.histogram(texture_features, bins=np.arange(0, 11), density=True)\n    return np.concatenate((color_hist, texture_hist))\n\n# Example usage:\n# features = extract_features('path/to/clothing/image.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.20930232558139536,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'skimage'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.11764705882352941,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'skimage'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Implement a feature extraction function for image classification",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a function in Python that extracts features from clothing images for classification purposes?",
      "role": "user"
    },
    "chosen_code": "from PIL import Image\nimport numpy as np\nfrom skimage import feature\nfrom typing import Any, Union\n\n\ndef extract_features(image_path: str) -> np.ndarray:\n    \"\"\"\n    Extracts numerical features from an image for classification purposes.\n\n    This function computes color histograms and texture patterns from the given image,\n    which can be used as features for machine learning models.\n\n    Args:\n        image_path (str): The file path to the image from which to extract features.\n\n    Returns:\n        np.ndarray: A concatenated array of color histogram and texture features.\n    \"\"\"\n    # Open the image and resize it to a fixed size\n    image: Image.Image = Image.open(image_path)\n    image = image.resize((128, 128))\n\n    # Convert the image to a numpy array for processing\n    image_array: np.ndarray = np.array(image)\n\n    # Calculate the color histogram with 32 bins\n    color_hist, _ = np.histogram(image_array[:, :, :3], bins=32, range=(0, 256))\n    # Normalize the histogram\n    color_hist = color_hist / np.sum(color_hist) if np.sum(color_hist) > 0 else color_hist\n\n    # Convert the image to grayscale using luminosity method\n    gray_image: np.ndarray = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n\n    # Extract texture features using Local Binary Pattern\n    texture_features: np.ndarray = feature.local_binary_pattern(gray_image, P=8, R=1, method='uniform')\n    texture_hist, _ = np.histogram(texture_features, bins=np.arange(0, 11), density=True)\n\n    # Return concatenated features\n    return np.concatenate((color_hist, texture_hist))\n\n# Example usage:\n# features: np.ndarray = extract_features('path/to/clothing/image.jpg')",
    "rejected_code": "from PIL import Image\nimport numpy as np\nfrom skimage import feature\n\ndef extract_features(image_path):\n    image = Image.open(image_path)\n    image = image.resize((128, 128))\n    image_array = np.array(image)\n    color_hist = np.histogram(image_array[:, :, :3], bins=32, range=(0, 256))[0]\n    color_hist = color_hist / np.sum(color_hist)\n    gray_image = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n    texture_features = feature.local_binary_pattern(gray_image, P=8, R=1, method='uniform')\n    texture_hist, _ = np.histogram(texture_features, bins=np.arange(0, 11), density=True)\n    return np.concatenate((color_hist, texture_hist))\n\n# Example usage:\n# features = extract_features('path/to/clothing/image.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.20930232558139536,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'skimage'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.11764705882352941,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'skimage'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Implement a feature extraction function for image classification",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a function in Python that takes a string as input (image path) and returns a numpy array of extracted features for clothing image classification.",
      "role": "user"
    },
    "chosen_code": "from PIL import Image\nimport numpy as np\nfrom skimage import feature\nfrom typing import Any, Union\n\n\ndef extract_features(image_path: str) -> np.ndarray:\n    \"\"\"\n    Extracts numerical features from an image for classification purposes.\n\n    This function computes color histograms and texture patterns from the given image,\n    which can be used as features for machine learning models.\n\n    Args:\n        image_path (str): The file path to the image from which to extract features.\n\n    Returns:\n        np.ndarray: A concatenated array of color histogram and texture features.\n    \"\"\"\n    # Open the image and resize it to a fixed size\n    image: Image.Image = Image.open(image_path)\n    image = image.resize((128, 128))\n\n    # Convert the image to a numpy array for processing\n    image_array: np.ndarray = np.array(image)\n\n    # Calculate the color histogram with 32 bins\n    color_hist, _ = np.histogram(image_array[:, :, :3], bins=32, range=(0, 256))\n    # Normalize the histogram\n    color_hist = color_hist / np.sum(color_hist) if np.sum(color_hist) > 0 else color_hist\n\n    # Convert the image to grayscale using luminosity method\n    gray_image: np.ndarray = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n\n    # Extract texture features using Local Binary Pattern\n    texture_features: np.ndarray = feature.local_binary_pattern(gray_image, P=8, R=1, method='uniform')\n    texture_hist, _ = np.histogram(texture_features, bins=np.arange(0, 11), density=True)\n\n    # Return concatenated features\n    return np.concatenate((color_hist, texture_hist))\n\n# Example usage:\n# features: np.ndarray = extract_features('path/to/clothing/image.jpg')",
    "rejected_code": "from PIL import Image\nimport numpy as np\nfrom skimage import feature\n\ndef extract_features(image_path):\n    image = Image.open(image_path)\n    image = image.resize((128, 128))\n    image_array = np.array(image)\n    color_hist = np.histogram(image_array[:, :, :3], bins=32, range=(0, 256))[0]\n    color_hist = color_hist / np.sum(color_hist)\n    gray_image = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])\n    texture_features = feature.local_binary_pattern(gray_image, P=8, R=1, method='uniform')\n    texture_hist, _ = np.histogram(texture_features, bins=np.arange(0, 11), density=True)\n    return np.concatenate((color_hist, texture_hist))\n\n# Example usage:\n# features = extract_features('path/to/clothing/image.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.20930232558139536,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'skimage'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.11764705882352941,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'skimage'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Create an image segmentation class with different algorithms",
    "code_form": "segmenter class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create an image segmentation class with different algorithms?",
      "role": "user"
    },
    "chosen_code": "import cv2\nimport numpy as np\nfrom typing import Literal, Union\n\nclass Segmenter:\n    \"\"\"\n    A class to perform image segmentation using various algorithms.\n    This class supports thresholding and edge detection methods to segment\n    images of products from their backgrounds.\n    \"\"\"\n\n    def __init__(self, image_path: str) -> None:\n        \"\"\"\n        Initializes the Segmenter with an image loaded from the given path.\n        \n        Parameters:\n        image_path (str): The path to the image file to be segmented.\n        \"\"\"\n        self.image: np.ndarray = cv2.imread(image_path)\n        if self.image is None:\n            raise ValueError(f\"Image not found at path: {image_path}\")\n\n    def threshold_segmentation(self) -> np.ndarray:\n        \"\"\"\n        Applies threshold segmentation to the loaded image.\n        Converts the image to grayscale and applies binary thresholding.\n        \n        Returns:\n        np.ndarray: The binary segmented image.\n        \"\"\"\n        gray: np.ndarray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n        return thresh\n\n    def edge_detection(self) -> np.ndarray:\n        \"\"\"\n        Applies edge detection to the loaded image using the Canny algorithm.\n        Converts the image to grayscale and detects edges.\n        \n        Returns:\n        np.ndarray: The image with detected edges.\n        \"\"\"\n        gray: np.ndarray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        edges: np.ndarray = cv2.Canny(gray, 100, 200)\n        return edges\n\n    def apply_segmentation(self, method: Literal['threshold', 'edges'] = 'threshold') -> np.ndarray:\n        \"\"\"\n        Applies the specified segmentation method to the image.\n        \n        Parameters:\n        method (Literal['threshold', 'edges']): The segmentation method to apply.\n        \n        Returns:\n        np.ndarray: The segmented image.\n        \n        Raises:\n        ValueError: If the method is not supported.\n        \"\"\"\n        if method == 'threshold':\n            return self.threshold_segmentation()\n        elif method == 'edges':\n            return self.edge_detection()\n        else:\n            raise ValueError('Unsupported segmentation method')\n\n# Example usage:\nseg = Segmenter('product_image.jpg')\nsegmented_image = seg.apply_segmentation('threshold')\ncv2.imwrite('segmented_image.jpg', segmented_image)",
    "rejected_code": "import cv2\nimport numpy as np\n\nclass Segmenter:\n    def __init__(self, image_path):\n        self.image = cv2.imread(image_path)\n\n    def threshold_segmentation(self):\n        gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n        return thresh\n\n    def edge_detection(self):\n        gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        edges = cv2.Canny(gray, 100, 200)\n        return edges\n\n    def apply_segmentation(self, method='threshold'):\n        if method == 'threshold':\n            return self.threshold_segmentation()\n        elif method == 'edges':\n            return self.edge_detection()\n        else:\n            raise ValueError('Unsupported segmentation method')\n\nseg = Segmenter('product_image.jpg')\nsegmented_image = seg.apply_segmentation('threshold')\ncv2.imwrite('segmented_image.jpg', segmented_image)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.014285714285714285,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cv2'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cv2'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Create an image segmentation class with different algorithms",
    "code_form": "segmenter class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python class to implement an image segmentation solution with various algorithms.",
      "role": "user"
    },
    "chosen_code": "import cv2\nimport numpy as np\nfrom typing import Literal, Union\n\nclass Segmenter:\n    \"\"\"\n    A class to perform image segmentation using various algorithms.\n    This class supports thresholding and edge detection methods to segment\n    images of products from their backgrounds.\n    \"\"\"\n\n    def __init__(self, image_path: str) -> None:\n        \"\"\"\n        Initializes the Segmenter with an image loaded from the given path.\n        \n        Parameters:\n        image_path (str): The path to the image file to be segmented.\n        \"\"\"\n        self.image: np.ndarray = cv2.imread(image_path)\n        if self.image is None:\n            raise ValueError(f\"Image not found at path: {image_path}\")\n\n    def threshold_segmentation(self) -> np.ndarray:\n        \"\"\"\n        Applies threshold segmentation to the loaded image.\n        Converts the image to grayscale and applies binary thresholding.\n        \n        Returns:\n        np.ndarray: The binary segmented image.\n        \"\"\"\n        gray: np.ndarray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n        return thresh\n\n    def edge_detection(self) -> np.ndarray:\n        \"\"\"\n        Applies edge detection to the loaded image using the Canny algorithm.\n        Converts the image to grayscale and detects edges.\n        \n        Returns:\n        np.ndarray: The image with detected edges.\n        \"\"\"\n        gray: np.ndarray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        edges: np.ndarray = cv2.Canny(gray, 100, 200)\n        return edges\n\n    def apply_segmentation(self, method: Literal['threshold', 'edges'] = 'threshold') -> np.ndarray:\n        \"\"\"\n        Applies the specified segmentation method to the image.\n        \n        Parameters:\n        method (Literal['threshold', 'edges']): The segmentation method to apply.\n        \n        Returns:\n        np.ndarray: The segmented image.\n        \n        Raises:\n        ValueError: If the method is not supported.\n        \"\"\"\n        if method == 'threshold':\n            return self.threshold_segmentation()\n        elif method == 'edges':\n            return self.edge_detection()\n        else:\n            raise ValueError('Unsupported segmentation method')\n\n# Example usage:\nseg = Segmenter('product_image.jpg')\nsegmented_image = seg.apply_segmentation('threshold')\ncv2.imwrite('segmented_image.jpg', segmented_image)",
    "rejected_code": "import cv2\nimport numpy as np\n\nclass Segmenter:\n    def __init__(self, image_path):\n        self.image = cv2.imread(image_path)\n\n    def threshold_segmentation(self):\n        gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n        return thresh\n\n    def edge_detection(self):\n        gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        edges = cv2.Canny(gray, 100, 200)\n        return edges\n\n    def apply_segmentation(self, method='threshold'):\n        if method == 'threshold':\n            return self.threshold_segmentation()\n        elif method == 'edges':\n            return self.edge_detection()\n        else:\n            raise ValueError('Unsupported segmentation method')\n\nseg = Segmenter('product_image.jpg')\nsegmented_image = seg.apply_segmentation('threshold')\ncv2.imwrite('segmented_image.jpg', segmented_image)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.014285714285714285,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cv2'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cv2'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Create an image segmentation class with different algorithms",
    "code_form": "segmenter class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Generate a Python class for image segmentation that accepts a string for the image path and returns a numpy array for the segmented image.",
      "role": "user"
    },
    "chosen_code": "import cv2\nimport numpy as np\nfrom typing import Literal, Union\n\nclass Segmenter:\n    \"\"\"\n    A class to perform image segmentation using various algorithms.\n    This class supports thresholding and edge detection methods to segment\n    images of products from their backgrounds.\n    \"\"\"\n\n    def __init__(self, image_path: str) -> None:\n        \"\"\"\n        Initializes the Segmenter with an image loaded from the given path.\n        \n        Parameters:\n        image_path (str): The path to the image file to be segmented.\n        \"\"\"\n        self.image: np.ndarray = cv2.imread(image_path)\n        if self.image is None:\n            raise ValueError(f\"Image not found at path: {image_path}\")\n\n    def threshold_segmentation(self) -> np.ndarray:\n        \"\"\"\n        Applies threshold segmentation to the loaded image.\n        Converts the image to grayscale and applies binary thresholding.\n        \n        Returns:\n        np.ndarray: The binary segmented image.\n        \"\"\"\n        gray: np.ndarray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n        return thresh\n\n    def edge_detection(self) -> np.ndarray:\n        \"\"\"\n        Applies edge detection to the loaded image using the Canny algorithm.\n        Converts the image to grayscale and detects edges.\n        \n        Returns:\n        np.ndarray: The image with detected edges.\n        \"\"\"\n        gray: np.ndarray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        edges: np.ndarray = cv2.Canny(gray, 100, 200)\n        return edges\n\n    def apply_segmentation(self, method: Literal['threshold', 'edges'] = 'threshold') -> np.ndarray:\n        \"\"\"\n        Applies the specified segmentation method to the image.\n        \n        Parameters:\n        method (Literal['threshold', 'edges']): The segmentation method to apply.\n        \n        Returns:\n        np.ndarray: The segmented image.\n        \n        Raises:\n        ValueError: If the method is not supported.\n        \"\"\"\n        if method == 'threshold':\n            return self.threshold_segmentation()\n        elif method == 'edges':\n            return self.edge_detection()\n        else:\n            raise ValueError('Unsupported segmentation method')\n\n# Example usage:\nseg = Segmenter('product_image.jpg')\nsegmented_image = seg.apply_segmentation('threshold')\ncv2.imwrite('segmented_image.jpg', segmented_image)",
    "rejected_code": "import cv2\nimport numpy as np\n\nclass Segmenter:\n    def __init__(self, image_path):\n        self.image = cv2.imread(image_path)\n\n    def threshold_segmentation(self):\n        gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n        return thresh\n\n    def edge_detection(self):\n        gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n        edges = cv2.Canny(gray, 100, 200)\n        return edges\n\n    def apply_segmentation(self, method='threshold'):\n        if method == 'threshold':\n            return self.threshold_segmentation()\n        elif method == 'edges':\n            return self.edge_detection()\n        else:\n            raise ValueError('Unsupported segmentation method')\n\nseg = Segmenter('product_image.jpg')\nsegmented_image = seg.apply_segmentation('threshold')\ncv2.imwrite('segmented_image.jpg', segmented_image)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.014285714285714285,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cv2'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cv2'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Develop a color correction function with various balancing methods",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide a Python function to perform color correction on underwater photos using different balancing methods?",
      "role": "user"
    },
    "chosen_code": "from PIL import Image\nimport numpy as np\nfrom typing import Literal, Union\n\n\ndef color_correction(image_path: str, method: Literal['white_balance', 'contrast_stretch'] = 'white_balance') -> Image:\n    \"\"\"\n    Perform color correction on an image using specified balancing methods.\n\n    Args:\n        image_path (str): The file path to the input image.\n        method (Literal['white_balance', 'contrast_stretch']): The color correction method to apply.\n            'white_balance' adjusts colors based on average RGB values.\n            'contrast_stretch' enhances contrast by stretching pixel intensity values.\n\n    Returns:\n        Image: A PIL Image object of the color-corrected image.\n    \"\"\"\n    # Load the image using PIL\n    img = Image.open(image_path)\n    # Convert the image to a NumPy array for manipulation\n    img_array = np.array(img)\n\n    # Apply the selected color correction method\n    if method == 'white_balance':\n        # Calculate the average RGB values\n        avg_colors = img_array.mean(axis=(0, 1))\n        # Adjust the image based on average colors\n        img_array = (img_array / avg_colors) * 128\n    elif method == 'contrast_stretch':\n        # Calculate the 2nd and 98th percentiles for contrast stretching\n        p2, p98 = np.percentile(img_array, (2, 98))\n        # Stretch the pixel values to enhance contrast\n        img_array = (img_array - p2) / (p98 - p2) * 255\n\n    # Clip the values to ensure they remain within valid range and convert to uint8\n    img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n    # Create a new Image object from the corrected array\n    corrected_img = Image.fromarray(img_array)\n    return corrected_img\n\n# Example usage of the color_correction function\ncorrected_image = color_correction('underwater_photo.jpg', method='white_balance')\n# Save the corrected image to a new file\ncorrected_image.save('corrected_underwater_photo.jpg')",
    "rejected_code": "from PIL import Image\nimport numpy as np\n\ndef color_correction(image_path, method='white_balance'):\n    img = Image.open(image_path)\n    img_array = np.array(img)\n    if method == 'white_balance':\n        avg_colors = img_array.mean(axis=(0, 1))\n        img_array = (img_array / avg_colors) * 128\n    elif method == 'contrast_stretch':\n        p2, p98 = np.percentile(img_array, (2, 98))\n        img_array = (img_array - p2) / (p98 - p2) * 255\n    img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n    corrected_img = Image.fromarray(img_array)\n    return corrected_img\n\ncorrected_image = color_correction('underwater_photo.jpg', method='white_balance')\ncorrected_image.save('corrected_underwater_photo.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.24444444444444444,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 43, in <module>\n  File \"<string>\", line 20, in color_correction\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'underwater_photo.jpg'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 17, in <module>\n  File \"<string>\", line 5, in color_correction\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'underwater_photo.jpg'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Develop a color correction function with various balancing methods",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class in Python that implements color correction for underwater photos using various balancing methods.",
      "role": "user"
    },
    "chosen_code": "from PIL import Image\nimport numpy as np\nfrom typing import Literal, Union\n\n\ndef color_correction(image_path: str, method: Literal['white_balance', 'contrast_stretch'] = 'white_balance') -> Image:\n    \"\"\"\n    Perform color correction on an image using specified balancing methods.\n\n    Args:\n        image_path (str): The file path to the input image.\n        method (Literal['white_balance', 'contrast_stretch']): The color correction method to apply.\n            'white_balance' adjusts colors based on average RGB values.\n            'contrast_stretch' enhances contrast by stretching pixel intensity values.\n\n    Returns:\n        Image: A PIL Image object of the color-corrected image.\n    \"\"\"\n    # Load the image using PIL\n    img = Image.open(image_path)\n    # Convert the image to a NumPy array for manipulation\n    img_array = np.array(img)\n\n    # Apply the selected color correction method\n    if method == 'white_balance':\n        # Calculate the average RGB values\n        avg_colors = img_array.mean(axis=(0, 1))\n        # Adjust the image based on average colors\n        img_array = (img_array / avg_colors) * 128\n    elif method == 'contrast_stretch':\n        # Calculate the 2nd and 98th percentiles for contrast stretching\n        p2, p98 = np.percentile(img_array, (2, 98))\n        # Stretch the pixel values to enhance contrast\n        img_array = (img_array - p2) / (p98 - p2) * 255\n\n    # Clip the values to ensure they remain within valid range and convert to uint8\n    img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n    # Create a new Image object from the corrected array\n    corrected_img = Image.fromarray(img_array)\n    return corrected_img\n\n# Example usage of the color_correction function\ncorrected_image = color_correction('underwater_photo.jpg', method='white_balance')\n# Save the corrected image to a new file\ncorrected_image.save('corrected_underwater_photo.jpg')",
    "rejected_code": "from PIL import Image\nimport numpy as np\n\ndef color_correction(image_path, method='white_balance'):\n    img = Image.open(image_path)\n    img_array = np.array(img)\n    if method == 'white_balance':\n        avg_colors = img_array.mean(axis=(0, 1))\n        img_array = (img_array / avg_colors) * 128\n    elif method == 'contrast_stretch':\n        p2, p98 = np.percentile(img_array, (2, 98))\n        img_array = (img_array - p2) / (p98 - p2) * 255\n    img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n    corrected_img = Image.fromarray(img_array)\n    return corrected_img\n\ncorrected_image = color_correction('underwater_photo.jpg', method='white_balance')\ncorrected_image.save('corrected_underwater_photo.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.24444444444444444,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 43, in <module>\n  File \"<string>\", line 20, in color_correction\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'underwater_photo.jpg'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 17, in <module>\n  File \"<string>\", line 5, in color_correction\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'underwater_photo.jpg'"
      }
    }
  },
  {
    "domain": "image processing",
    "task": "Develop a color correction function with various balancing methods",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python function that takes a string as input for the image path and a specific method type, returning a PIL Image object after performing color correction.",
      "role": "user"
    },
    "chosen_code": "from PIL import Image\nimport numpy as np\nfrom typing import Literal, Union\n\n\ndef color_correction(image_path: str, method: Literal['white_balance', 'contrast_stretch'] = 'white_balance') -> Image:\n    \"\"\"\n    Perform color correction on an image using specified balancing methods.\n\n    Args:\n        image_path (str): The file path to the input image.\n        method (Literal['white_balance', 'contrast_stretch']): The color correction method to apply.\n            'white_balance' adjusts colors based on average RGB values.\n            'contrast_stretch' enhances contrast by stretching pixel intensity values.\n\n    Returns:\n        Image: A PIL Image object of the color-corrected image.\n    \"\"\"\n    # Load the image using PIL\n    img = Image.open(image_path)\n    # Convert the image to a NumPy array for manipulation\n    img_array = np.array(img)\n\n    # Apply the selected color correction method\n    if method == 'white_balance':\n        # Calculate the average RGB values\n        avg_colors = img_array.mean(axis=(0, 1))\n        # Adjust the image based on average colors\n        img_array = (img_array / avg_colors) * 128\n    elif method == 'contrast_stretch':\n        # Calculate the 2nd and 98th percentiles for contrast stretching\n        p2, p98 = np.percentile(img_array, (2, 98))\n        # Stretch the pixel values to enhance contrast\n        img_array = (img_array - p2) / (p98 - p2) * 255\n\n    # Clip the values to ensure they remain within valid range and convert to uint8\n    img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n    # Create a new Image object from the corrected array\n    corrected_img = Image.fromarray(img_array)\n    return corrected_img\n\n# Example usage of the color_correction function\ncorrected_image = color_correction('underwater_photo.jpg', method='white_balance')\n# Save the corrected image to a new file\ncorrected_image.save('corrected_underwater_photo.jpg')",
    "rejected_code": "from PIL import Image\nimport numpy as np\n\ndef color_correction(image_path, method='white_balance'):\n    img = Image.open(image_path)\n    img_array = np.array(img)\n    if method == 'white_balance':\n        avg_colors = img_array.mean(axis=(0, 1))\n        img_array = (img_array / avg_colors) * 128\n    elif method == 'contrast_stretch':\n        p2, p98 = np.percentile(img_array, (2, 98))\n        img_array = (img_array - p2) / (p98 - p2) * 255\n    img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n    corrected_img = Image.fromarray(img_array)\n    return corrected_img\n\ncorrected_image = color_correction('underwater_photo.jpg', method='white_balance')\ncorrected_image.save('corrected_underwater_photo.jpg')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.24444444444444444,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 43, in <module>\n  File \"<string>\", line 20, in color_correction\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'underwater_photo.jpg'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 17, in <module>\n  File \"<string>\", line 5, in color_correction\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'underwater_photo.jpg'"
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Develop a differential equation solver class with various algorithms",
    "code_form": "solver class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to solve a differential equation for modeling population growth using the logistic growth model?",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\nfrom typing import Callable, List, Tuple, Any\n\nclass DifferentialEquationSolver:\n    \"\"\"\n    A class to solve differential equations using various numerical methods.\n    \"\"\"\n\n    def __init__(self, equation: Callable[[float, List[float]], List[float]], t_span: Tuple[float, float], y0: List[float]) -> None:\n        \"\"\"\n        Initializes the differential equation solver.\n\n        Parameters:\n            equation (Callable): The differential equation to be solved.\n            t_span (Tuple[float, float]): The time span for the solution (start, end).\n            y0 (List[float]): Initial conditions for the differential equation.\n        \"\"\"\n        self.equation = equation\n        self.t_span = t_span\n        self.y0 = y0\n\n    def solve(self, method: str = 'RK45') -> Any:\n        \"\"\"\n        Solves the differential equation using the specified method.\n\n        Parameters:\n            method (str): The integration method to use (default is 'RK45').\n\n        Returns:\n            Any: The result of the integration, including time points and solution values.\n        \"\"\"\n        sol = solve_ivp(self.equation, self.t_span, self.y0, method=method, dense_output=True)\n        return sol\n\n    def plot_solution(self, sol: Any) -> None:\n        \"\"\"\n        Plots the solution of the differential equation.\n\n        Parameters:\n            sol (Any): The result of the integration to plot.\n        \"\"\"\n        t = np.linspace(self.t_span[0], self.t_span[1], 100)\n        y = sol.sol(t)\n        plt.plot(t, y[0], label='Population over Time')\n        plt.xlabel('Time')\n        plt.ylabel('Population Size')\n        plt.title('Logistic Growth Model')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n\ndef logistic_growth(t: float, y: List[float]) -> List[float]:\n    \"\"\"\n    Defines the logistic growth differential equation.\n\n    Parameters:\n        t (float): The current time (not used in this model).\n        y (List[float]): The current population size.\n\n    Returns:\n        List[float]: The rate of change of the population.\n    \"\"\"\n    r = 0.1  # Growth rate\n    K = 1000  # Carrying capacity\n    dydt = r * y[0] * (1 - y[0] / K)\n    return [dydt]\n\n\nif __name__ == '__main__':\n    # Instantiate the solver with the logistic growth model parameters\n    solver = DifferentialEquationSolver(logistic_growth, (0, 100), [10])\n    # Solve the differential equation\n    solution = solver.solve()\n    # Plot the solution\n    solver.plot_solution(solution)",
    "rejected_code": "import numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\n\nclass DifferentialEquationSolver:\n    def __init__(self, equation, t_span, y0):\n        self.equation = equation\n        self.t_span = t_span\n        self.y0 = y0\n\n    def solve(self, method='RK45'):\n        sol = solve_ivp(self.equation, self.t_span, self.y0, method=method, dense_output=True)\n        return sol\n\n    def plot_solution(self, sol):\n        t = np.linspace(self.t_span[0], self.t_span[1], 100)\n        y = sol.sol(t)\n        plt.plot(t, y[0], label='Population over Time')\n        plt.xlabel('Time')\n        plt.ylabel('Population Size')\n        plt.title('Logistic Growth Model')\n        plt.legend()\n        plt.show()\n\ndef logistic_growth(t, y):\n    r = 0.1\n    K = 1000\n    dydt = r * y[0] * (1 - y[0] / K)\n    return [dydt]\n\nsolver = DifferentialEquationSolver(logistic_growth, (0, 100), [10])\nsolution = solver.solve()\nsolver.plot_solution(solution)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.2,
      "pep8_compliance": null,
      "comment_density": 0.038461538461538464,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"import numpy as np\\nfrom scipy.integrate import solve_ivp\\nimport matplotlib.pyplot as plt\\n\\nclass DifferentialEquationSolver:\\n    def __init__(self, equation, t_span, y0):\\n        self.equation = equation\\n        self.t_span = t_span\\n        self.y0 = y0\\n\\n    def solve(self, method='RK45'):\\n        sol = solve_ivp(self.equation, self.t_span, self.y0, method=method, dense_output=True)\\n        return sol\\n\\n    def plot_solution(self, sol):\\n        t = np.linspace(self.t_span[0], self.t_span[1], 100)\\n        y = sol.sol(t)\\n        plt.plot(t, y[0], label='Population over Time')\\n        plt.xlabel('Time')\\n        plt.ylabel('Population Size')\\n        plt.title('Logistic Growth Model')\\n        plt.legend()\\n        plt.show()\\n\\ndef logistic_growth(t, y):\\n    r = 0.1\\n    K = 1000\\n    dydt = r * y[0] * (1 - y[0] / K)\\n    return [dydt]\\n\\nsolver = DifferentialEquationSolver(logistic_growth, (0, 100), [10])\\nsolution = solver.solve()\\nsolver.plot_solution(solution)\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Develop a differential equation solver class with various algorithms",
    "code_form": "solver class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class in Python that solves a differential equation for modeling population growth using the logistic growth model.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\nfrom typing import Callable, List, Tuple, Any\n\nclass DifferentialEquationSolver:\n    \"\"\"\n    A class to solve differential equations using various numerical methods.\n    \"\"\"\n\n    def __init__(self, equation: Callable[[float, List[float]], List[float]], t_span: Tuple[float, float], y0: List[float]) -> None:\n        \"\"\"\n        Initializes the differential equation solver.\n\n        Parameters:\n            equation (Callable): The differential equation to be solved.\n            t_span (Tuple[float, float]): The time span for the solution (start, end).\n            y0 (List[float]): Initial conditions for the differential equation.\n        \"\"\"\n        self.equation = equation\n        self.t_span = t_span\n        self.y0 = y0\n\n    def solve(self, method: str = 'RK45') -> Any:\n        \"\"\"\n        Solves the differential equation using the specified method.\n\n        Parameters:\n            method (str): The integration method to use (default is 'RK45').\n\n        Returns:\n            Any: The result of the integration, including time points and solution values.\n        \"\"\"\n        sol = solve_ivp(self.equation, self.t_span, self.y0, method=method, dense_output=True)\n        return sol\n\n    def plot_solution(self, sol: Any) -> None:\n        \"\"\"\n        Plots the solution of the differential equation.\n\n        Parameters:\n            sol (Any): The result of the integration to plot.\n        \"\"\"\n        t = np.linspace(self.t_span[0], self.t_span[1], 100)\n        y = sol.sol(t)\n        plt.plot(t, y[0], label='Population over Time')\n        plt.xlabel('Time')\n        plt.ylabel('Population Size')\n        plt.title('Logistic Growth Model')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n\ndef logistic_growth(t: float, y: List[float]) -> List[float]:\n    \"\"\"\n    Defines the logistic growth differential equation.\n\n    Parameters:\n        t (float): The current time (not used in this model).\n        y (List[float]): The current population size.\n\n    Returns:\n        List[float]: The rate of change of the population.\n    \"\"\"\n    r = 0.1  # Growth rate\n    K = 1000  # Carrying capacity\n    dydt = r * y[0] * (1 - y[0] / K)\n    return [dydt]\n\n\nif __name__ == '__main__':\n    # Instantiate the solver with the logistic growth model parameters\n    solver = DifferentialEquationSolver(logistic_growth, (0, 100), [10])\n    # Solve the differential equation\n    solution = solver.solve()\n    # Plot the solution\n    solver.plot_solution(solution)",
    "rejected_code": "import numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\n\nclass DifferentialEquationSolver:\n    def __init__(self, equation, t_span, y0):\n        self.equation = equation\n        self.t_span = t_span\n        self.y0 = y0\n\n    def solve(self, method='RK45'):\n        sol = solve_ivp(self.equation, self.t_span, self.y0, method=method, dense_output=True)\n        return sol\n\n    def plot_solution(self, sol):\n        t = np.linspace(self.t_span[0], self.t_span[1], 100)\n        y = sol.sol(t)\n        plt.plot(t, y[0], label='Population over Time')\n        plt.xlabel('Time')\n        plt.ylabel('Population Size')\n        plt.title('Logistic Growth Model')\n        plt.legend()\n        plt.show()\n\ndef logistic_growth(t, y):\n    r = 0.1\n    K = 1000\n    dydt = r * y[0] * (1 - y[0] / K)\n    return [dydt]\n\nsolver = DifferentialEquationSolver(logistic_growth, (0, 100), [10])\nsolution = solver.solve()\nsolver.plot_solution(solution)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.2,
      "pep8_compliance": null,
      "comment_density": 0.038461538461538464,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "mathematics and scientific computing",
    "task": "Develop a differential equation solver class with various algorithms",
    "code_form": "solver class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you create a Python class that takes a logistic growth model as input and returns a solution, specifying the input and output types?",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\nfrom typing import Callable, List, Tuple, Any\n\nclass DifferentialEquationSolver:\n    \"\"\"\n    A class to solve differential equations using various numerical methods.\n    \"\"\"\n\n    def __init__(self, equation: Callable[[float, List[float]], List[float]], t_span: Tuple[float, float], y0: List[float]) -> None:\n        \"\"\"\n        Initializes the differential equation solver.\n\n        Parameters:\n            equation (Callable): The differential equation to be solved.\n            t_span (Tuple[float, float]): The time span for the solution (start, end).\n            y0 (List[float]): Initial conditions for the differential equation.\n        \"\"\"\n        self.equation = equation\n        self.t_span = t_span\n        self.y0 = y0\n\n    def solve(self, method: str = 'RK45') -> Any:\n        \"\"\"\n        Solves the differential equation using the specified method.\n\n        Parameters:\n            method (str): The integration method to use (default is 'RK45').\n\n        Returns:\n            Any: The result of the integration, including time points and solution values.\n        \"\"\"\n        sol = solve_ivp(self.equation, self.t_span, self.y0, method=method, dense_output=True)\n        return sol\n\n    def plot_solution(self, sol: Any) -> None:\n        \"\"\"\n        Plots the solution of the differential equation.\n\n        Parameters:\n            sol (Any): The result of the integration to plot.\n        \"\"\"\n        t = np.linspace(self.t_span[0], self.t_span[1], 100)\n        y = sol.sol(t)\n        plt.plot(t, y[0], label='Population over Time')\n        plt.xlabel('Time')\n        plt.ylabel('Population Size')\n        plt.title('Logistic Growth Model')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n\ndef logistic_growth(t: float, y: List[float]) -> List[float]:\n    \"\"\"\n    Defines the logistic growth differential equation.\n\n    Parameters:\n        t (float): The current time (not used in this model).\n        y (List[float]): The current population size.\n\n    Returns:\n        List[float]: The rate of change of the population.\n    \"\"\"\n    r = 0.1  # Growth rate\n    K = 1000  # Carrying capacity\n    dydt = r * y[0] * (1 - y[0] / K)\n    return [dydt]\n\n\nif __name__ == '__main__':\n    # Instantiate the solver with the logistic growth model parameters\n    solver = DifferentialEquationSolver(logistic_growth, (0, 100), [10])\n    # Solve the differential equation\n    solution = solver.solve()\n    # Plot the solution\n    solver.plot_solution(solution)",
    "rejected_code": "import numpy as np\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\n\nclass DifferentialEquationSolver:\n    def __init__(self, equation, t_span, y0):\n        self.equation = equation\n        self.t_span = t_span\n        self.y0 = y0\n\n    def solve(self, method='RK45'):\n        sol = solve_ivp(self.equation, self.t_span, self.y0, method=method, dense_output=True)\n        return sol\n\n    def plot_solution(self, sol):\n        t = np.linspace(self.t_span[0], self.t_span[1], 100)\n        y = sol.sol(t)\n        plt.plot(t, y[0], label='Population over Time')\n        plt.xlabel('Time')\n        plt.ylabel('Population Size')\n        plt.title('Logistic Growth Model')\n        plt.legend()\n        plt.show()\n\ndef logistic_growth(t, y):\n    r = 0.1\n    K = 1000\n    dydt = r * y[0] * (1 - y[0] / K)\n    return [dydt]\n\nsolver = DifferentialEquationSolver(logistic_growth, (0, 100), [10])\nsolution = solver.solve()\nsolver.plot_solution(solution)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.2,
      "pep8_compliance": null,
      "comment_density": 0.038461538461538464,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.2,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Implement a graph traversal algorithm with custom visitor pattern",
    "code_form": "algorithm function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to implement a graph traversal algorithm with a custom visitor pattern?",
      "role": "user"
    },
    "chosen_code": "from collections import deque\nfrom typing import Callable, Dict, List, Set, Any\n\nclass Graph:\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes an empty graph.\n        \"\"\"\n        self.graph: Dict[Any, List[Any]] = {}\n    \n    def add_edge(self, u: Any, v: Any) -> None:\n        \"\"\"\n        Adds a directed edge from user u to user v.\n\n        Parameters:\n        u (Any): The starting user of the edge.\n        v (Any): The ending user of the edge.\n        \"\"\"\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def bfs(self, start: Any, visitor: Callable[[Any], None]) -> None:\n        \"\"\"\n        Performs a breadth-first search starting from the given user.\n        Applies the visitor function to each visited user.\n\n        Parameters:\n        start (Any): The starting user for the traversal.\n        visitor (Callable[[Any], None]): A function that takes a user as input and performs an action.\n        \"\"\"\n        visited: Set[Any] = set()\n        queue: deque = deque([start])\n        while queue:\n            vertex = queue.popleft()\n            if vertex not in visited:\n                visitor(vertex)  # Apply the visitor function\n                visited.add(vertex)\n                queue.extend(self.graph.get(vertex, []))\n\ndef send_message(user: Any) -> None:\n    \"\"\"\n    Sends a message to the specified user.\n\n    Parameters:\n    user (Any): The user to whom the message is sent.\n    \"\"\"\n    print(f'Sending message to {user}')\n\n# Example usage of the Graph class to represent a social network\nsocial_graph = Graph()\n# Adding edges to represent friendships\nsocial_graph.add_edge('Alice', 'Bob')\nsocial_graph.add_edge('Alice', 'Charlie')\nsocial_graph.add_edge('Bob', 'David')\nsocial_graph.add_edge('Charlie', 'Eve')\n# Starting BFS traversal from 'Alice' and sending messages\nsocial_graph.bfs('Alice', send_message)",
    "rejected_code": "from collections import deque\n\nclass Graph:\n    def __init__(self):\n        self.graph = {}\n    \n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def bfs(self, start, visitor):\n        visited = set()\n        queue = deque([start])\n        while queue:\n            vertex = queue.popleft()\n            if vertex not in visited:\n                visitor(vertex)\n                visited.add(vertex)\n                queue.extend(self.graph.get(vertex, []))\n\ndef send_message(user):\n    print(f'Sending message to {user}')\n\nsocial_graph = Graph()\nsocial_graph.add_edge('Alice', 'Bob')\nsocial_graph.add_edge('Alice', 'Charlie')\nsocial_graph.add_edge('Bob', 'David')\nsocial_graph.add_edge('Charlie', 'Eve')\nsocial_graph.bfs('Alice', send_message)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.05172413793103448,
      "execution_result": {
        "success": true,
        "output": "Sending message to Alice\nSending message to Bob\nSending message to Charlie\nSending message to David\nSending message to Eve",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Sending message to Alice\nSending message to Bob\nSending message to Charlie\nSending message to David\nSending message to Eve",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Implement a graph traversal algorithm with custom visitor pattern",
    "code_form": "algorithm function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Could you write a class-based Python implementation for a graph traversal algorithm with a custom visitor pattern?",
      "role": "user"
    },
    "chosen_code": "from collections import deque\nfrom typing import Callable, Dict, List, Set, Any\n\nclass Graph:\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes an empty graph.\n        \"\"\"\n        self.graph: Dict[Any, List[Any]] = {}\n    \n    def add_edge(self, u: Any, v: Any) -> None:\n        \"\"\"\n        Adds a directed edge from user u to user v.\n\n        Parameters:\n        u (Any): The starting user of the edge.\n        v (Any): The ending user of the edge.\n        \"\"\"\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def bfs(self, start: Any, visitor: Callable[[Any], None]) -> None:\n        \"\"\"\n        Performs a breadth-first search starting from the given user.\n        Applies the visitor function to each visited user.\n\n        Parameters:\n        start (Any): The starting user for the traversal.\n        visitor (Callable[[Any], None]): A function that takes a user as input and performs an action.\n        \"\"\"\n        visited: Set[Any] = set()\n        queue: deque = deque([start])\n        while queue:\n            vertex = queue.popleft()\n            if vertex not in visited:\n                visitor(vertex)  # Apply the visitor function\n                visited.add(vertex)\n                queue.extend(self.graph.get(vertex, []))\n\ndef send_message(user: Any) -> None:\n    \"\"\"\n    Sends a message to the specified user.\n\n    Parameters:\n    user (Any): The user to whom the message is sent.\n    \"\"\"\n    print(f'Sending message to {user}')\n\n# Example usage of the Graph class to represent a social network\nsocial_graph = Graph()\n# Adding edges to represent friendships\nsocial_graph.add_edge('Alice', 'Bob')\nsocial_graph.add_edge('Alice', 'Charlie')\nsocial_graph.add_edge('Bob', 'David')\nsocial_graph.add_edge('Charlie', 'Eve')\n# Starting BFS traversal from 'Alice' and sending messages\nsocial_graph.bfs('Alice', send_message)",
    "rejected_code": "from collections import deque\n\nclass Graph:\n    def __init__(self):\n        self.graph = {}\n    \n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def bfs(self, start, visitor):\n        visited = set()\n        queue = deque([start])\n        while queue:\n            vertex = queue.popleft()\n            if vertex not in visited:\n                visitor(vertex)\n                visited.add(vertex)\n                queue.extend(self.graph.get(vertex, []))\n\ndef send_message(user):\n    print(f'Sending message to {user}')\n\nsocial_graph = Graph()\nsocial_graph.add_edge('Alice', 'Bob')\nsocial_graph.add_edge('Alice', 'Charlie')\nsocial_graph.add_edge('Bob', 'David')\nsocial_graph.add_edge('Charlie', 'Eve')\nsocial_graph.bfs('Alice', send_message)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.05172413793103448,
      "execution_result": {
        "success": true,
        "output": "Sending message to Alice\nSending message to Bob\nSending message to Charlie\nSending message to David\nSending message to Eve",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Sending message to Alice\nSending message to Bob\nSending message to Charlie\nSending message to David\nSending message to Eve",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Implement a graph traversal algorithm with custom visitor pattern",
    "code_form": "algorithm function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please create a Python class that implements a graph traversal algorithm with a custom visitor pattern, specifying the input and output types.",
      "role": "user"
    },
    "chosen_code": "from collections import deque\nfrom typing import Callable, Dict, List, Set, Any\n\nclass Graph:\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes an empty graph.\n        \"\"\"\n        self.graph: Dict[Any, List[Any]] = {}\n    \n    def add_edge(self, u: Any, v: Any) -> None:\n        \"\"\"\n        Adds a directed edge from user u to user v.\n\n        Parameters:\n        u (Any): The starting user of the edge.\n        v (Any): The ending user of the edge.\n        \"\"\"\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def bfs(self, start: Any, visitor: Callable[[Any], None]) -> None:\n        \"\"\"\n        Performs a breadth-first search starting from the given user.\n        Applies the visitor function to each visited user.\n\n        Parameters:\n        start (Any): The starting user for the traversal.\n        visitor (Callable[[Any], None]): A function that takes a user as input and performs an action.\n        \"\"\"\n        visited: Set[Any] = set()\n        queue: deque = deque([start])\n        while queue:\n            vertex = queue.popleft()\n            if vertex not in visited:\n                visitor(vertex)  # Apply the visitor function\n                visited.add(vertex)\n                queue.extend(self.graph.get(vertex, []))\n\ndef send_message(user: Any) -> None:\n    \"\"\"\n    Sends a message to the specified user.\n\n    Parameters:\n    user (Any): The user to whom the message is sent.\n    \"\"\"\n    print(f'Sending message to {user}')\n\n# Example usage of the Graph class to represent a social network\nsocial_graph = Graph()\n# Adding edges to represent friendships\nsocial_graph.add_edge('Alice', 'Bob')\nsocial_graph.add_edge('Alice', 'Charlie')\nsocial_graph.add_edge('Bob', 'David')\nsocial_graph.add_edge('Charlie', 'Eve')\n# Starting BFS traversal from 'Alice' and sending messages\nsocial_graph.bfs('Alice', send_message)",
    "rejected_code": "from collections import deque\n\nclass Graph:\n    def __init__(self):\n        self.graph = {}\n    \n    def add_edge(self, u, v):\n        if u not in self.graph:\n            self.graph[u] = []\n        self.graph[u].append(v)\n\n    def bfs(self, start, visitor):\n        visited = set()\n        queue = deque([start])\n        while queue:\n            vertex = queue.popleft()\n            if vertex not in visited:\n                visitor(vertex)\n                visited.add(vertex)\n                queue.extend(self.graph.get(vertex, []))\n\ndef send_message(user):\n    print(f'Sending message to {user}')\n\nsocial_graph = Graph()\nsocial_graph.add_edge('Alice', 'Bob')\nsocial_graph.add_edge('Alice', 'Charlie')\nsocial_graph.add_edge('Bob', 'David')\nsocial_graph.add_edge('Charlie', 'Eve')\nsocial_graph.bfs('Alice', send_message)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.05172413793103448,
      "execution_result": {
        "success": true,
        "output": "Sending message to Alice\nSending message to Bob\nSending message to Charlie\nSending message to David\nSending message to Eve",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Sending message to Alice\nSending message to Bob\nSending message to Charlie\nSending message to David\nSending message to Eve",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Create a priority queue implementation with customizable priority functions",
    "code_form": "data structure class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide a Python implementation of a priority queue that allows for customizable priority functions?",
      "role": "user"
    },
    "chosen_code": "import heapq\nfrom typing import Callable, List, Tuple, Any\n\nclass PriorityQueue:\n    \"\"\"\n    A priority queue implementation that allows for customizable priority functions.\n    This queue uses a min-heap to manage elements based on their priority.\n    \"\"\"\n\n    def __init__(self, priority_function: Callable[[Any], int]) -> None:\n        \"\"\"\n        Initializes the priority queue with a given priority function.\n        \n        :param priority_function: A function that takes an item and returns its priority (lower values indicate higher priority).\n        \"\"\"\n        self.elements: List[Tuple[int, Any]] = []  # List to hold the heap elements\n        self.priority_function: Callable[[Any], int] = priority_function  # The function to determine priority\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Checks if the priority queue is empty.\n        \n        :return: True if the queue is empty, False otherwise.\n        \"\"\"\n        return not self.elements\n\n    def put(self, item: Any) -> None:\n        \"\"\"\n        Adds an item to the priority queue.\n        \n        :param item: The item to be added to the queue.\n        \"\"\"\n        heapq.heappush(self.elements, (self.priority_function(item), item))\n\n    def get(self) -> Any:\n        \"\"\"\n        Removes and returns the highest priority item from the queue.\n        \n        :return: The item with the highest priority.\n        \"\"\"\n        return heapq.heappop(self.elements)[1]  # Return the item, not the priority\n\nclass Patient:\n    \"\"\"\n    Represents a patient with a name and severity level.\n    \"\"\"\n\n    def __init__(self, name: str, severity: int) -> None:\n        \"\"\"\n        Initializes a patient with a name and severity level.\n        \n        :param name: The name of the patient.\n        :param severity: The severity level of the patient's condition (higher is worse).\n        \"\"\"\n        self.name: str = name\n        self.severity: int = severity\n\ndef severity_priority(patient: Patient) -> int:\n    \"\"\"\n    A priority function that returns the negative severity of a patient.\n    This means that patients with higher severity (lower priority number) will be treated first.\n    \n    :param patient: The patient whose priority is to be determined.\n    :return: The negative severity of the patient.\n    \"\"\"\n    return -patient.severity\n\n# Example usage of the PriorityQueue with Patient objects\npq = PriorityQueue(severity_priority)\n\n# Adding patients to the priority queue\npq.put(Patient('Alice', 5))\npq.put(Patient('Bob', 2))\npq.put(Patient('Charlie', 4))\n\n# Treating patients based on priority\nwhile not pq.is_empty():\n    patient = pq.get()\n    print(f'Treating patient: {patient.name} with severity {patient.severity}')",
    "rejected_code": "import heapq\n\nclass PriorityQueue:\n    def __init__(self, priority_function):\n        self.elements = []\n        self.priority_function = priority_function\n\n    def is_empty(self):\n        return not self.elements\n\n    def put(self, item):\n        heapq.heappush(self.elements, (self.priority_function(item), item))\n\n    def get(self):\n        return heapq.heappop(self.elements)[1]\n\nclass Patient:\n    def __init__(self, name, severity):\n        self.name = name\n        self.severity = severity\n\ndef severity_priority(patient):\n    return -patient.severity\n\npq = PriorityQueue(severity_priority)\n\npq.put(Patient('Alice', 5))\npq.put(Patient('Bob', 2))\npq.put(Patient('Charlie', 4))\n\nwhile not pq.is_empty():\n    patient = pq.get()\n    print(f'Treating patient: {patient.name} with severity {patient.severity}')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.0379746835443038,
      "execution_result": {
        "success": true,
        "output": "Treating patient: Alice with severity 5\nTreating patient: Charlie with severity 4\nTreating patient: Bob with severity 2",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Treating patient: Alice with severity 5\nTreating patient: Charlie with severity 4\nTreating patient: Bob with severity 2",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Create a priority queue implementation with customizable priority functions",
    "code_form": "data structure class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class-based implementation of a priority queue with customizable priority functions in Python.",
      "role": "user"
    },
    "chosen_code": "import heapq\nfrom typing import Callable, List, Tuple, Any\n\nclass PriorityQueue:\n    \"\"\"\n    A priority queue implementation that allows for customizable priority functions.\n    This queue uses a min-heap to manage elements based on their priority.\n    \"\"\"\n\n    def __init__(self, priority_function: Callable[[Any], int]) -> None:\n        \"\"\"\n        Initializes the priority queue with a given priority function.\n        \n        :param priority_function: A function that takes an item and returns its priority (lower values indicate higher priority).\n        \"\"\"\n        self.elements: List[Tuple[int, Any]] = []  # List to hold the heap elements\n        self.priority_function: Callable[[Any], int] = priority_function  # The function to determine priority\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Checks if the priority queue is empty.\n        \n        :return: True if the queue is empty, False otherwise.\n        \"\"\"\n        return not self.elements\n\n    def put(self, item: Any) -> None:\n        \"\"\"\n        Adds an item to the priority queue.\n        \n        :param item: The item to be added to the queue.\n        \"\"\"\n        heapq.heappush(self.elements, (self.priority_function(item), item))\n\n    def get(self) -> Any:\n        \"\"\"\n        Removes and returns the highest priority item from the queue.\n        \n        :return: The item with the highest priority.\n        \"\"\"\n        return heapq.heappop(self.elements)[1]  # Return the item, not the priority\n\nclass Patient:\n    \"\"\"\n    Represents a patient with a name and severity level.\n    \"\"\"\n\n    def __init__(self, name: str, severity: int) -> None:\n        \"\"\"\n        Initializes a patient with a name and severity level.\n        \n        :param name: The name of the patient.\n        :param severity: The severity level of the patient's condition (higher is worse).\n        \"\"\"\n        self.name: str = name\n        self.severity: int = severity\n\ndef severity_priority(patient: Patient) -> int:\n    \"\"\"\n    A priority function that returns the negative severity of a patient.\n    This means that patients with higher severity (lower priority number) will be treated first.\n    \n    :param patient: The patient whose priority is to be determined.\n    :return: The negative severity of the patient.\n    \"\"\"\n    return -patient.severity\n\n# Example usage of the PriorityQueue with Patient objects\npq = PriorityQueue(severity_priority)\n\n# Adding patients to the priority queue\npq.put(Patient('Alice', 5))\npq.put(Patient('Bob', 2))\npq.put(Patient('Charlie', 4))\n\n# Treating patients based on priority\nwhile not pq.is_empty():\n    patient = pq.get()\n    print(f'Treating patient: {patient.name} with severity {patient.severity}')",
    "rejected_code": "import heapq\n\nclass PriorityQueue:\n    def __init__(self, priority_function):\n        self.elements = []\n        self.priority_function = priority_function\n\n    def is_empty(self):\n        return not self.elements\n\n    def put(self, item):\n        heapq.heappush(self.elements, (self.priority_function(item), item))\n\n    def get(self):\n        return heapq.heappop(self.elements)[1]\n\nclass Patient:\n    def __init__(self, name, severity):\n        self.name = name\n        self.severity = severity\n\ndef severity_priority(patient):\n    return -patient.severity\n\npq = PriorityQueue(severity_priority)\n\npq.put(Patient('Alice', 5))\npq.put(Patient('Bob', 2))\npq.put(Patient('Charlie', 4))\n\nwhile not pq.is_empty():\n    patient = pq.get()\n    print(f'Treating patient: {patient.name} with severity {patient.severity}')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.0379746835443038,
      "execution_result": {
        "success": true,
        "output": "Treating patient: Alice with severity 5\nTreating patient: Charlie with severity 4\nTreating patient: Bob with severity 2",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Treating patient: Alice with severity 5\nTreating patient: Charlie with severity 4\nTreating patient: Bob with severity 2",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Create a priority queue implementation with customizable priority functions",
    "code_form": "data structure class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a class in Python for a priority queue that accepts customizable priority functions, ensuring to include type annotations for inputs and outputs.",
      "role": "user"
    },
    "chosen_code": "import heapq\nfrom typing import Callable, List, Tuple, Any\n\nclass PriorityQueue:\n    \"\"\"\n    A priority queue implementation that allows for customizable priority functions.\n    This queue uses a min-heap to manage elements based on their priority.\n    \"\"\"\n\n    def __init__(self, priority_function: Callable[[Any], int]) -> None:\n        \"\"\"\n        Initializes the priority queue with a given priority function.\n        \n        :param priority_function: A function that takes an item and returns its priority (lower values indicate higher priority).\n        \"\"\"\n        self.elements: List[Tuple[int, Any]] = []  # List to hold the heap elements\n        self.priority_function: Callable[[Any], int] = priority_function  # The function to determine priority\n\n    def is_empty(self) -> bool:\n        \"\"\"\n        Checks if the priority queue is empty.\n        \n        :return: True if the queue is empty, False otherwise.\n        \"\"\"\n        return not self.elements\n\n    def put(self, item: Any) -> None:\n        \"\"\"\n        Adds an item to the priority queue.\n        \n        :param item: The item to be added to the queue.\n        \"\"\"\n        heapq.heappush(self.elements, (self.priority_function(item), item))\n\n    def get(self) -> Any:\n        \"\"\"\n        Removes and returns the highest priority item from the queue.\n        \n        :return: The item with the highest priority.\n        \"\"\"\n        return heapq.heappop(self.elements)[1]  # Return the item, not the priority\n\nclass Patient:\n    \"\"\"\n    Represents a patient with a name and severity level.\n    \"\"\"\n\n    def __init__(self, name: str, severity: int) -> None:\n        \"\"\"\n        Initializes a patient with a name and severity level.\n        \n        :param name: The name of the patient.\n        :param severity: The severity level of the patient's condition (higher is worse).\n        \"\"\"\n        self.name: str = name\n        self.severity: int = severity\n\ndef severity_priority(patient: Patient) -> int:\n    \"\"\"\n    A priority function that returns the negative severity of a patient.\n    This means that patients with higher severity (lower priority number) will be treated first.\n    \n    :param patient: The patient whose priority is to be determined.\n    :return: The negative severity of the patient.\n    \"\"\"\n    return -patient.severity\n\n# Example usage of the PriorityQueue with Patient objects\npq = PriorityQueue(severity_priority)\n\n# Adding patients to the priority queue\npq.put(Patient('Alice', 5))\npq.put(Patient('Bob', 2))\npq.put(Patient('Charlie', 4))\n\n# Treating patients based on priority\nwhile not pq.is_empty():\n    patient = pq.get()\n    print(f'Treating patient: {patient.name} with severity {patient.severity}')",
    "rejected_code": "import heapq\n\nclass PriorityQueue:\n    def __init__(self, priority_function):\n        self.elements = []\n        self.priority_function = priority_function\n\n    def is_empty(self):\n        return not self.elements\n\n    def put(self, item):\n        heapq.heappush(self.elements, (self.priority_function(item), item))\n\n    def get(self):\n        return heapq.heappop(self.elements)[1]\n\nclass Patient:\n    def __init__(self, name, severity):\n        self.name = name\n        self.severity = severity\n\ndef severity_priority(patient):\n    return -patient.severity\n\npq = PriorityQueue(severity_priority)\n\npq.put(Patient('Alice', 5))\npq.put(Patient('Bob', 2))\npq.put(Patient('Charlie', 4))\n\nwhile not pq.is_empty():\n    patient = pq.get()\n    print(f'Treating patient: {patient.name} with severity {patient.severity}')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.0379746835443038,
      "execution_result": {
        "success": true,
        "output": "Treating patient: Alice with severity 5\nTreating patient: Charlie with severity 4\nTreating patient: Bob with severity 2",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Treating patient: Alice with severity 5\nTreating patient: Charlie with severity 4\nTreating patient: Bob with severity 2",
        "error": ""
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Implement a model evaluation function with cross-validation and various metrics",
    "code_form": "evaluation function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to implement a model evaluation function with cross-validation and various metrics for a logistic regression model?",
      "role": "user"
    },
    "chosen_code": "from typing import Dict, Any\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n\n\ndef evaluate_model(model: LogisticRegression, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, float]:\n    \"\"\"\n    Evaluates the given machine learning model using cross-validation and various metrics.\n\n    Args:\n        model (LogisticRegression): The machine learning model to evaluate.\n        X (np.ndarray): Feature data for the model.\n        y (np.ndarray): Target data for the model.\n        cv (int): The number of cross-validation folds.\n\n    Returns:\n        Dict[str, float]: A dictionary containing the mean scores for each evaluation metric.\n    \"\"\"\n    # Define scoring metrics\n    scoring: Dict[str, Any] = {\n        'accuracy': make_scorer(accuracy_score),\n        'precision': make_scorer(precision_score),\n        'recall': make_scorer(recall_score),\n        'f1': make_scorer(f1_score)\n    }\n\n    # Store results\n    results: Dict[str, float] = {}\n\n    # Evaluate the model for each metric\n    for metric, scorer in scoring.items():\n        scores = cross_val_score(model, X, y, cv=cv, scoring=scorer)\n        results[metric] = scores.mean()  # Store the mean score for the metric\n\n    return results\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to load data, create a model, and evaluate it.\n    \"\"\"\n    # Load dataset\n    data = load_breast_cancer()\n    X = data.data  # Feature data\n    y = data.target  # Target labels\n\n    # Create logistic regression model\n    model = LogisticRegression(max_iter=10000)\n\n    # Evaluate the model\n    results = evaluate_model(model, X, y)\n\n    # Print results\n    for metric, score in results.items():\n        print(f'{metric.capitalize()}: {score:.4f}')  # Print scores with formatting\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\nmodel = LogisticRegression(max_iter=10000)\n\nscoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'f1': make_scorer(f1_score)}\n\nscores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\nprint('Accuracy:', scores.mean())\nfor metric in scoring:\n    scores = cross_val_score(model, X, y, cv=5, scoring=scoring[metric])\n    print(f'{metric.capitalize()}:', scores.mean())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.11290322580645161,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', 'from typing import Dict, Any\\nimport numpy as np\\nfrom sklearn.datasets import load_breast_cancer\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\\n\\n\\ndef evaluate_model(model: LogisticRegression, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, float]:\\n    \"\"\"\\n    Evaluates the given machine learning model using cross-validation and various metrics.\\n\\n    Args:\\n        model (LogisticRegression): The machine learning model to evaluate.\\n        X (np.ndarray): Feature data for the model.\\n        y (np.ndarray): Target data for the model.\\n        cv (int): The number of cross-validation folds.\\n\\n    Returns:\\n        Dict[str, float]: A dictionary containing the mean scores for each evaluation metric.\\n    \"\"\"\\n    # Define scoring metrics\\n    scoring: Dict[str, Any] = {\\n        \\'accuracy\\': make_scorer(accuracy_score),\\n        \\'precision\\': make_scorer(precision_score),\\n        \\'recall\\': make_scorer(recall_score),\\n        \\'f1\\': make_scorer(f1_score)\\n    }\\n\\n    # Store results\\n    results: Dict[str, float] = {}\\n\\n    # Evaluate the model for each metric\\n    for metric, scorer in scoring.items():\\n        scores = cross_val_score(model, X, y, cv=cv, scoring=scorer)\\n        results[metric] = scores.mean()  # Store the mean score for the metric\\n\\n    return results\\n\\n\\ndef main() -> None:\\n    \"\"\"\\n    Main function to load data, create a model, and evaluate it.\\n    \"\"\"\\n    # Load dataset\\n    data = load_breast_cancer()\\n    X = data.data  # Feature data\\n    y = data.target  # Target labels\\n\\n    # Create logistic regression model\\n    model = LogisticRegression(max_iter=10000)\\n\\n    # Evaluate the model\\n    results = evaluate_model(model, X, y)\\n\\n    # Print results\\n    for metric, score in results.items():\\n        print(f\\'{metric.capitalize()}: {score:.4f}\\')  # Print scores with formatting\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n\\n']' timed out after 10 seconds"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"from sklearn.datasets import load_breast_cancer\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\\n\\ndata = load_breast_cancer()\\nX = data.data\\ny = data.target\\nmodel = LogisticRegression(max_iter=10000)\\n\\nscoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'f1': make_scorer(f1_score)}\\n\\nscores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\\nprint('Accuracy:', scores.mean())\\nfor metric in scoring:\\n    scores = cross_val_score(model, X, y, cv=5, scoring=scoring[metric])\\n    print(f'{metric.capitalize()}:', scores.mean())\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Implement a model evaluation function with cross-validation and various metrics",
    "code_form": "evaluation function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you provide a Python function that implements a model evaluation with cross-validation and various metrics for a logistic regression model?",
      "role": "user"
    },
    "chosen_code": "from typing import Dict, Any\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n\n\ndef evaluate_model(model: LogisticRegression, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, float]:\n    \"\"\"\n    Evaluates the given machine learning model using cross-validation and various metrics.\n\n    Args:\n        model (LogisticRegression): The machine learning model to evaluate.\n        X (np.ndarray): Feature data for the model.\n        y (np.ndarray): Target data for the model.\n        cv (int): The number of cross-validation folds.\n\n    Returns:\n        Dict[str, float]: A dictionary containing the mean scores for each evaluation metric.\n    \"\"\"\n    # Define scoring metrics\n    scoring: Dict[str, Any] = {\n        'accuracy': make_scorer(accuracy_score),\n        'precision': make_scorer(precision_score),\n        'recall': make_scorer(recall_score),\n        'f1': make_scorer(f1_score)\n    }\n\n    # Store results\n    results: Dict[str, float] = {}\n\n    # Evaluate the model for each metric\n    for metric, scorer in scoring.items():\n        scores = cross_val_score(model, X, y, cv=cv, scoring=scorer)\n        results[metric] = scores.mean()  # Store the mean score for the metric\n\n    return results\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to load data, create a model, and evaluate it.\n    \"\"\"\n    # Load dataset\n    data = load_breast_cancer()\n    X = data.data  # Feature data\n    y = data.target  # Target labels\n\n    # Create logistic regression model\n    model = LogisticRegression(max_iter=10000)\n\n    # Evaluate the model\n    results = evaluate_model(model, X, y)\n\n    # Print results\n    for metric, score in results.items():\n        print(f'{metric.capitalize()}: {score:.4f}')  # Print scores with formatting\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\nmodel = LogisticRegression(max_iter=10000)\n\nscoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'f1': make_scorer(f1_score)}\n\nscores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\nprint('Accuracy:', scores.mean())\nfor metric in scoring:\n    scores = cross_val_score(model, X, y, cv=5, scoring=scoring[metric])\n    print(f'{metric.capitalize()}:', scores.mean())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.11290322580645161,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', 'from typing import Dict, Any\\nimport numpy as np\\nfrom sklearn.datasets import load_breast_cancer\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\\n\\n\\ndef evaluate_model(model: LogisticRegression, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, float]:\\n    \"\"\"\\n    Evaluates the given machine learning model using cross-validation and various metrics.\\n\\n    Args:\\n        model (LogisticRegression): The machine learning model to evaluate.\\n        X (np.ndarray): Feature data for the model.\\n        y (np.ndarray): Target data for the model.\\n        cv (int): The number of cross-validation folds.\\n\\n    Returns:\\n        Dict[str, float]: A dictionary containing the mean scores for each evaluation metric.\\n    \"\"\"\\n    # Define scoring metrics\\n    scoring: Dict[str, Any] = {\\n        \\'accuracy\\': make_scorer(accuracy_score),\\n        \\'precision\\': make_scorer(precision_score),\\n        \\'recall\\': make_scorer(recall_score),\\n        \\'f1\\': make_scorer(f1_score)\\n    }\\n\\n    # Store results\\n    results: Dict[str, float] = {}\\n\\n    # Evaluate the model for each metric\\n    for metric, scorer in scoring.items():\\n        scores = cross_val_score(model, X, y, cv=cv, scoring=scorer)\\n        results[metric] = scores.mean()  # Store the mean score for the metric\\n\\n    return results\\n\\n\\ndef main() -> None:\\n    \"\"\"\\n    Main function to load data, create a model, and evaluate it.\\n    \"\"\"\\n    # Load dataset\\n    data = load_breast_cancer()\\n    X = data.data  # Feature data\\n    y = data.target  # Target labels\\n\\n    # Create logistic regression model\\n    model = LogisticRegression(max_iter=10000)\\n\\n    # Evaluate the model\\n    results = evaluate_model(model, X, y)\\n\\n    # Print results\\n    for metric, score in results.items():\\n        print(f\\'{metric.capitalize()}: {score:.4f}\\')  # Print scores with formatting\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n\\n']' timed out after 10 seconds"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"from sklearn.datasets import load_breast_cancer\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\\n\\ndata = load_breast_cancer()\\nX = data.data\\ny = data.target\\nmodel = LogisticRegression(max_iter=10000)\\n\\nscoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'f1': make_scorer(f1_score)}\\n\\nscores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\\nprint('Accuracy:', scores.mean())\\nfor metric in scoring:\\n    scores = cross_val_score(model, X, y, cv=5, scoring=scoring[metric])\\n    print(f'{metric.capitalize()}:', scores.mean())\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Implement a model evaluation function with cross-validation and various metrics",
    "code_form": "evaluation function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you provide a Python function that takes a LogisticRegression model, feature data (np.ndarray), and target data (np.ndarray) as input, and returns a dictionary of evaluation metrics?",
      "role": "user"
    },
    "chosen_code": "from typing import Dict, Any\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n\n\ndef evaluate_model(model: LogisticRegression, X: np.ndarray, y: np.ndarray, cv: int = 5) -> Dict[str, float]:\n    \"\"\"\n    Evaluates the given machine learning model using cross-validation and various metrics.\n\n    Args:\n        model (LogisticRegression): The machine learning model to evaluate.\n        X (np.ndarray): Feature data for the model.\n        y (np.ndarray): Target data for the model.\n        cv (int): The number of cross-validation folds.\n\n    Returns:\n        Dict[str, float]: A dictionary containing the mean scores for each evaluation metric.\n    \"\"\"\n    # Define scoring metrics\n    scoring: Dict[str, Any] = {\n        'accuracy': make_scorer(accuracy_score),\n        'precision': make_scorer(precision_score),\n        'recall': make_scorer(recall_score),\n        'f1': make_scorer(f1_score)\n    }\n\n    # Store results\n    results: Dict[str, float] = {}\n\n    # Evaluate the model for each metric\n    for metric, scorer in scoring.items():\n        scores = cross_val_score(model, X, y, cv=cv, scoring=scorer)\n        results[metric] = scores.mean()  # Store the mean score for the metric\n\n    return results\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to load data, create a model, and evaluate it.\n    \"\"\"\n    # Load dataset\n    data = load_breast_cancer()\n    X = data.data  # Feature data\n    y = data.target  # Target labels\n\n    # Create logistic regression model\n    model = LogisticRegression(max_iter=10000)\n\n    # Evaluate the model\n    results = evaluate_model(model, X, y)\n\n    # Print results\n    for metric, score in results.items():\n        print(f'{metric.capitalize()}: {score:.4f}')  # Print scores with formatting\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\nmodel = LogisticRegression(max_iter=10000)\n\nscoring = {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'f1': make_scorer(f1_score)}\n\nscores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\nprint('Accuracy:', scores.mean())\nfor metric in scoring:\n    scores = cross_val_score(model, X, y, cv=5, scoring=scoring[metric])\n    print(f'{metric.capitalize()}:', scores.mean())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.11290322580645161,
      "execution_result": {
        "success": true,
        "output": "Accuracy: 0.9508\nPrecision: 0.9543\nRecall: 0.9692\nF1: 0.9612",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Accuracy: 0.9507995652848935\nAccuracy: 0.9507995652848935\nPrecision: 0.9542623125822158\nRecall: 0.9692097026604068\nF1: 0.9611875600190988",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Build a dynamic programming solution function with memoization",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to solve the knapsack problem using dynamic programming and memoization?",
      "role": "user"
    },
    "chosen_code": "from typing import List, Dict, Callable\n\n\ndef knapsack(weights: List[int], values: List[int], capacity: int) -> int:\n    \"\"\"\n    Calculate the maximum value of items that can be carried in a knapsack with a given weight limit.\n\n    Parameters:\n    weights (List[int]): A list of weights for each item.\n    values (List[int]): A list of values for each item.\n    capacity (int): The maximum weight capacity of the knapsack.\n\n    Returns:\n    int: The maximum value that can be carried in the knapsack.\n    \"\"\"\n    # Memoization dictionary to store previously computed results\n    memo: Dict[Tuple[int, int], int] = {}\n\n    def utility_function(index: int, remaining_capacity: int) -> int:\n        \"\"\"\n        Utility function to recursively calculate the maximum value that can be achieved\n        with the remaining items and capacity.\n\n        Parameters:\n        index (int): The current index of the item being considered.\n        remaining_capacity (int): The remaining weight capacity of the knapsack.\n\n        Returns:\n        int: The maximum value achievable with the current index and capacity.\n        \"\"\"\n        # Base case: no items left or no capacity\n        if index >= len(weights) or remaining_capacity <= 0:\n            return 0\n\n        # Check if result is already computed\n        if (index, remaining_capacity) in memo:\n            return memo[(index, remaining_capacity)]\n\n        # If the current item's weight exceeds remaining capacity, skip it\n        if weights[index] > remaining_capacity:\n            result = utility_function(index + 1, remaining_capacity)\n        else:\n            # Calculate the maximum value by including or excluding the current item\n            result = max(\n                utility_function(index + 1, remaining_capacity),\n                values[index] + utility_function(index + 1, remaining_capacity - weights[index])\n            )\n\n        # Store the computed result in the memo dictionary\n        memo[(index, remaining_capacity)] = result\n        return result\n\n    # Start the utility function with the first item and the full capacity\n    return utility_function(0, capacity)\n\n\n# Example usage\nif __name__ == '__main__':\n    weights = [2, 3, 4, 5]\n    values = [3, 4, 5, 6]\n    capacity = 5\n    print(knapsack(weights, values, capacity))  # Output: 7",
    "rejected_code": "def knapsack(weights, values, capacity):\n    memo = {}\n    def utility_function(index, remaining_capacity):\n        if index >= len(weights) or remaining_capacity <= 0:\n            return 0\n        if (index, remaining_capacity) in memo:\n            return memo[(index, remaining_capacity)]\n        if weights[index] > remaining_capacity:\n            result = utility_function(index + 1, remaining_capacity)\n        else:\n            result = max(utility_function(index + 1, remaining_capacity),\n                         values[index] + utility_function(index + 1, remaining_capacity - weights[index]))\n        memo[(index, remaining_capacity)] = result\n        return result\n    return utility_function(0, capacity)\n\nweights = [2, 3, 4, 5]\nvalues = [3, 4, 5, 6]\ncapacity = 5\nprint(knapsack(weights, values, capacity))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.12903225806451613,
      "execution_result": {
        "success": true,
        "output": "7",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "7",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Build a dynamic programming solution function with memoization",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a function in Python that solves the knapsack problem using dynamic programming and memoization.",
      "role": "user"
    },
    "chosen_code": "from typing import List, Dict, Callable\n\n\ndef knapsack(weights: List[int], values: List[int], capacity: int) -> int:\n    \"\"\"\n    Calculate the maximum value of items that can be carried in a knapsack with a given weight limit.\n\n    Parameters:\n    weights (List[int]): A list of weights for each item.\n    values (List[int]): A list of values for each item.\n    capacity (int): The maximum weight capacity of the knapsack.\n\n    Returns:\n    int: The maximum value that can be carried in the knapsack.\n    \"\"\"\n    # Memoization dictionary to store previously computed results\n    memo: Dict[Tuple[int, int], int] = {}\n\n    def utility_function(index: int, remaining_capacity: int) -> int:\n        \"\"\"\n        Utility function to recursively calculate the maximum value that can be achieved\n        with the remaining items and capacity.\n\n        Parameters:\n        index (int): The current index of the item being considered.\n        remaining_capacity (int): The remaining weight capacity of the knapsack.\n\n        Returns:\n        int: The maximum value achievable with the current index and capacity.\n        \"\"\"\n        # Base case: no items left or no capacity\n        if index >= len(weights) or remaining_capacity <= 0:\n            return 0\n\n        # Check if result is already computed\n        if (index, remaining_capacity) in memo:\n            return memo[(index, remaining_capacity)]\n\n        # If the current item's weight exceeds remaining capacity, skip it\n        if weights[index] > remaining_capacity:\n            result = utility_function(index + 1, remaining_capacity)\n        else:\n            # Calculate the maximum value by including or excluding the current item\n            result = max(\n                utility_function(index + 1, remaining_capacity),\n                values[index] + utility_function(index + 1, remaining_capacity - weights[index])\n            )\n\n        # Store the computed result in the memo dictionary\n        memo[(index, remaining_capacity)] = result\n        return result\n\n    # Start the utility function with the first item and the full capacity\n    return utility_function(0, capacity)\n\n\n# Example usage\nif __name__ == '__main__':\n    weights = [2, 3, 4, 5]\n    values = [3, 4, 5, 6]\n    capacity = 5\n    print(knapsack(weights, values, capacity))  # Output: 7",
    "rejected_code": "def knapsack(weights, values, capacity):\n    memo = {}\n    def utility_function(index, remaining_capacity):\n        if index >= len(weights) or remaining_capacity <= 0:\n            return 0\n        if (index, remaining_capacity) in memo:\n            return memo[(index, remaining_capacity)]\n        if weights[index] > remaining_capacity:\n            result = utility_function(index + 1, remaining_capacity)\n        else:\n            result = max(utility_function(index + 1, remaining_capacity),\n                         values[index] + utility_function(index + 1, remaining_capacity - weights[index]))\n        memo[(index, remaining_capacity)] = result\n        return result\n    return utility_function(0, capacity)\n\nweights = [2, 3, 4, 5]\nvalues = [3, 4, 5, 6]\ncapacity = 5\nprint(knapsack(weights, values, capacity))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.12903225806451613,
      "execution_result": {
        "success": true,
        "output": "7",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "7",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Build a dynamic programming solution function with memoization",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you create a Python function that takes lists of weights and values, along with an integer capacity, and returns an integer representing the maximum value for the knapsack?",
      "role": "user"
    },
    "chosen_code": "from typing import List, Dict, Callable\n\n\ndef knapsack(weights: List[int], values: List[int], capacity: int) -> int:\n    \"\"\"\n    Calculate the maximum value of items that can be carried in a knapsack with a given weight limit.\n\n    Parameters:\n    weights (List[int]): A list of weights for each item.\n    values (List[int]): A list of values for each item.\n    capacity (int): The maximum weight capacity of the knapsack.\n\n    Returns:\n    int: The maximum value that can be carried in the knapsack.\n    \"\"\"\n    # Memoization dictionary to store previously computed results\n    memo: Dict[Tuple[int, int], int] = {}\n\n    def utility_function(index: int, remaining_capacity: int) -> int:\n        \"\"\"\n        Utility function to recursively calculate the maximum value that can be achieved\n        with the remaining items and capacity.\n\n        Parameters:\n        index (int): The current index of the item being considered.\n        remaining_capacity (int): The remaining weight capacity of the knapsack.\n\n        Returns:\n        int: The maximum value achievable with the current index and capacity.\n        \"\"\"\n        # Base case: no items left or no capacity\n        if index >= len(weights) or remaining_capacity <= 0:\n            return 0\n\n        # Check if result is already computed\n        if (index, remaining_capacity) in memo:\n            return memo[(index, remaining_capacity)]\n\n        # If the current item's weight exceeds remaining capacity, skip it\n        if weights[index] > remaining_capacity:\n            result = utility_function(index + 1, remaining_capacity)\n        else:\n            # Calculate the maximum value by including or excluding the current item\n            result = max(\n                utility_function(index + 1, remaining_capacity),\n                values[index] + utility_function(index + 1, remaining_capacity - weights[index])\n            )\n\n        # Store the computed result in the memo dictionary\n        memo[(index, remaining_capacity)] = result\n        return result\n\n    # Start the utility function with the first item and the full capacity\n    return utility_function(0, capacity)\n\n\n# Example usage\nif __name__ == '__main__':\n    weights = [2, 3, 4, 5]\n    values = [3, 4, 5, 6]\n    capacity = 5\n    print(knapsack(weights, values, capacity))  # Output: 7",
    "rejected_code": "def knapsack(weights, values, capacity):\n    memo = {}\n    def utility_function(index, remaining_capacity):\n        if index >= len(weights) or remaining_capacity <= 0:\n            return 0\n        if (index, remaining_capacity) in memo:\n            return memo[(index, remaining_capacity)]\n        if weights[index] > remaining_capacity:\n            result = utility_function(index + 1, remaining_capacity)\n        else:\n            result = max(utility_function(index + 1, remaining_capacity),\n                         values[index] + utility_function(index + 1, remaining_capacity - weights[index]))\n        memo[(index, remaining_capacity)] = result\n        return result\n    return utility_function(0, capacity)\n\nweights = [2, 3, 4, 5]\nvalues = [3, 4, 5, 6]\ncapacity = 5\nprint(knapsack(weights, values, capacity))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.12903225806451613,
      "execution_result": {
        "success": true,
        "output": "7",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "7",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Develop a trie data structure class for efficient string operations",
    "code_form": "data structure class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code for a trie data structure to efficiently manage string operations?",
      "role": "user"
    },
    "chosen_code": "from typing import List, Dict\n\nclass TrieNode:\n    \"\"\"\n    A node in the Trie data structure.\n\n    Attributes:\n        children (Dict[str, TrieNode]): A dictionary mapping characters to child TrieNodes.\n        is_end_of_word (bool): A flag indicating if the node represents the end of a valid word.\n    \"\"\"\n    def __init__(self) -> None:\n        self.children: Dict[str, TrieNode] = {}\n        self.is_end_of_word: bool = False\n\nclass Trie:\n    \"\"\"\n    A Trie data structure for efficient string operations, such as insertion and prefix searching.\n\n    Attributes:\n        root (TrieNode): The root node of the Trie.\n    \"\"\"\n    def __init__(self) -> None:\n        self.root: TrieNode = TrieNode()\n\n    def insert(self, word: str) -> None:\n        \"\"\"\n        Inserts a word into the Trie.\n\n        Args:\n            word (str): The word to be inserted into the Trie.\n        \"\"\"\n        node: TrieNode = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n\n    def starts_with(self, prefix: str) -> List[str]:\n        \"\"\"\n        Returns a list of words in the Trie that start with the given prefix.\n\n        Args:\n            prefix (str): The prefix to search for.\n\n        Returns:\n            List[str]: A list of words that start with the given prefix.\n        \"\"\"\n        node: TrieNode = self.root\n        for char in prefix:\n            if char not in node.children:\n                return []  # No words with the given prefix\n            node = node.children[char]\n        return self._find_words(node, prefix)\n\n    def _find_words(self, node: TrieNode, prefix: str) -> List[str]:\n        \"\"\"\n        A helper method to find all words in the Trie starting from the given node.\n\n        Args:\n            node (TrieNode): The starting node for the search.\n            prefix (str): The current prefix being built.\n\n        Returns:\n            List[str]: A list of words found in the Trie.\n        \"\"\"\n        words: List[str] = []\n        if node.is_end_of_word:\n            words.append(prefix)\n        for char, child in node.children.items():\n            words.extend(self._find_words(child, prefix + char))\n        return words\n\n# Example usage of the Trie class\ntrie = Trie()\ntrie.insert('The Great Gatsby')\ntrie.insert('The Catcher in the Rye')\ntrie.insert('To Kill a Mockingbird')\nresults = trie.starts_with('The')\n# results now contains all book titles starting with 'The'",
    "rejected_code": "class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.is_end_of_word = False\n\nclass Trie:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def insert(self, word):\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n\n    def starts_with(self, prefix):\n        node = self.root\n        for char in prefix:\n            if char not in node.children:\n                return []\n            node = node.children[char]\n        return self._find_words(node, prefix)\n\n    def _find_words(self, node, prefix):\n        words = []\n        if node.is_end_of_word:\n            words.append(prefix)\n        for char, child in node.children.items():\n            words.extend(self._find_words(child, prefix + char))\n        return words\n\ntrie = Trie()\ntrie.insert('The Great Gatsby')\ntrie.insert('The Catcher in the Rye')\ntrie.insert('To Kill a Mockingbird')\nresults = trie.starts_with('The')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.6,
      "code_complexity": 2.2857142857142856,
      "pep8_compliance": null,
      "comment_density": 0.025,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.2857142857142856,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Develop a trie data structure class for efficient string operations",
    "code_form": "data structure class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class in Python that implements a trie data structure for efficient string operations.",
      "role": "user"
    },
    "chosen_code": "from typing import List, Dict\n\nclass TrieNode:\n    \"\"\"\n    A node in the Trie data structure.\n\n    Attributes:\n        children (Dict[str, TrieNode]): A dictionary mapping characters to child TrieNodes.\n        is_end_of_word (bool): A flag indicating if the node represents the end of a valid word.\n    \"\"\"\n    def __init__(self) -> None:\n        self.children: Dict[str, TrieNode] = {}\n        self.is_end_of_word: bool = False\n\nclass Trie:\n    \"\"\"\n    A Trie data structure for efficient string operations, such as insertion and prefix searching.\n\n    Attributes:\n        root (TrieNode): The root node of the Trie.\n    \"\"\"\n    def __init__(self) -> None:\n        self.root: TrieNode = TrieNode()\n\n    def insert(self, word: str) -> None:\n        \"\"\"\n        Inserts a word into the Trie.\n\n        Args:\n            word (str): The word to be inserted into the Trie.\n        \"\"\"\n        node: TrieNode = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n\n    def starts_with(self, prefix: str) -> List[str]:\n        \"\"\"\n        Returns a list of words in the Trie that start with the given prefix.\n\n        Args:\n            prefix (str): The prefix to search for.\n\n        Returns:\n            List[str]: A list of words that start with the given prefix.\n        \"\"\"\n        node: TrieNode = self.root\n        for char in prefix:\n            if char not in node.children:\n                return []  # No words with the given prefix\n            node = node.children[char]\n        return self._find_words(node, prefix)\n\n    def _find_words(self, node: TrieNode, prefix: str) -> List[str]:\n        \"\"\"\n        A helper method to find all words in the Trie starting from the given node.\n\n        Args:\n            node (TrieNode): The starting node for the search.\n            prefix (str): The current prefix being built.\n\n        Returns:\n            List[str]: A list of words found in the Trie.\n        \"\"\"\n        words: List[str] = []\n        if node.is_end_of_word:\n            words.append(prefix)\n        for char, child in node.children.items():\n            words.extend(self._find_words(child, prefix + char))\n        return words\n\n# Example usage of the Trie class\ntrie = Trie()\ntrie.insert('The Great Gatsby')\ntrie.insert('The Catcher in the Rye')\ntrie.insert('To Kill a Mockingbird')\nresults = trie.starts_with('The')\n# results now contains all book titles starting with 'The'",
    "rejected_code": "class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.is_end_of_word = False\n\nclass Trie:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def insert(self, word):\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n\n    def starts_with(self, prefix):\n        node = self.root\n        for char in prefix:\n            if char not in node.children:\n                return []\n            node = node.children[char]\n        return self._find_words(node, prefix)\n\n    def _find_words(self, node, prefix):\n        words = []\n        if node.is_end_of_word:\n            words.append(prefix)\n        for char, child in node.children.items():\n            words.extend(self._find_words(child, prefix + char))\n        return words\n\ntrie = Trie()\ntrie.insert('The Great Gatsby')\ntrie.insert('The Catcher in the Rye')\ntrie.insert('To Kill a Mockingbird')\nresults = trie.starts_with('The')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.6,
      "code_complexity": 2.2857142857142856,
      "pep8_compliance": null,
      "comment_density": 0.025,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.2857142857142856,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "classic algorithms",
    "task": "Develop a trie data structure class for efficient string operations",
    "code_form": "data structure class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you write a class in Python for a trie data structure that includes type annotations? The class should support inserting strings and retrieving all strings that start with a given prefix.",
      "role": "user"
    },
    "chosen_code": "from typing import List, Dict\n\nclass TrieNode:\n    \"\"\"\n    A node in the Trie data structure.\n\n    Attributes:\n        children (Dict[str, TrieNode]): A dictionary mapping characters to child TrieNodes.\n        is_end_of_word (bool): A flag indicating if the node represents the end of a valid word.\n    \"\"\"\n    def __init__(self) -> None:\n        self.children: Dict[str, TrieNode] = {}\n        self.is_end_of_word: bool = False\n\nclass Trie:\n    \"\"\"\n    A Trie data structure for efficient string operations, such as insertion and prefix searching.\n\n    Attributes:\n        root (TrieNode): The root node of the Trie.\n    \"\"\"\n    def __init__(self) -> None:\n        self.root: TrieNode = TrieNode()\n\n    def insert(self, word: str) -> None:\n        \"\"\"\n        Inserts a word into the Trie.\n\n        Args:\n            word (str): The word to be inserted into the Trie.\n        \"\"\"\n        node: TrieNode = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n\n    def starts_with(self, prefix: str) -> List[str]:\n        \"\"\"\n        Returns a list of words in the Trie that start with the given prefix.\n\n        Args:\n            prefix (str): The prefix to search for.\n\n        Returns:\n            List[str]: A list of words that start with the given prefix.\n        \"\"\"\n        node: TrieNode = self.root\n        for char in prefix:\n            if char not in node.children:\n                return []  # No words with the given prefix\n            node = node.children[char]\n        return self._find_words(node, prefix)\n\n    def _find_words(self, node: TrieNode, prefix: str) -> List[str]:\n        \"\"\"\n        A helper method to find all words in the Trie starting from the given node.\n\n        Args:\n            node (TrieNode): The starting node for the search.\n            prefix (str): The current prefix being built.\n\n        Returns:\n            List[str]: A list of words found in the Trie.\n        \"\"\"\n        words: List[str] = []\n        if node.is_end_of_word:\n            words.append(prefix)\n        for char, child in node.children.items():\n            words.extend(self._find_words(child, prefix + char))\n        return words\n\n# Example usage of the Trie class\ntrie = Trie()\ntrie.insert('The Great Gatsby')\ntrie.insert('The Catcher in the Rye')\ntrie.insert('To Kill a Mockingbird')\nresults = trie.starts_with('The')\n# results now contains all book titles starting with 'The'",
    "rejected_code": "class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.is_end_of_word = False\n\nclass Trie:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def insert(self, word):\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n\n    def starts_with(self, prefix):\n        node = self.root\n        for char in prefix:\n            if char not in node.children:\n                return []\n            node = node.children[char]\n        return self._find_words(node, prefix)\n\n    def _find_words(self, node, prefix):\n        words = []\n        if node.is_end_of_word:\n            words.append(prefix)\n        for char, child in node.children.items():\n            words.extend(self._find_words(child, prefix + char))\n        return words\n\ntrie = Trie()\ntrie.insert('The Great Gatsby')\ntrie.insert('The Catcher in the Rye')\ntrie.insert('To Kill a Mockingbird')\nresults = trie.starts_with('The')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.6,
      "code_complexity": 2.2857142857142856,
      "pep8_compliance": null,
      "comment_density": 0.025,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.2857142857142856,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Build a feature selection class with multiple evaluation metrics",
    "code_form": "selector class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code for a feature selection class that evaluates features using accuracy, F1 score, and ROC AUC?",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom typing import List, Tuple, Any\n\nclass FeatureSelector:\n    \"\"\"\n    A class to perform feature selection based on multiple evaluation metrics.\n    This class evaluates features from a dataset using accuracy, F1 score,\n    and ROC AUC to determine which features contribute significantly to\n    the predictive power of a model.\n    \"\"\"\n\n    def __init__(self, X: pd.DataFrame, y: pd.Series) -> None:\n        \"\"\"\n        Initializes the FeatureSelector with feature data and target labels.\n\n        Parameters:\n        X (pd.DataFrame): The feature dataset.\n        y (pd.Series): The target variable.\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.selected_features: List[str] = []\n\n    def evaluate_feature(self, feature: str) -> Tuple[float, float, float]:\n        \"\"\"\n        Evaluates a single feature using a Random Forest classifier.\n\n        Parameters:\n        feature (str): The name of the feature to evaluate.\n\n        Returns:\n        Tuple[float, float, float]: A tuple containing accuracy, F1 score,\n        and ROC AUC score of the model using the specified feature.\n        \"\"\"\n        # Split the data into training and testing sets\n        X_train, X_test, y_train, y_test = train_test_split(\n            self.X[[feature]], self.y, test_size=0.2, random_state=42\n        )\n        model = RandomForestClassifier(random_state=42)\n        model.fit(X_train, y_train)\n\n        # Make predictions\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n\n        return accuracy, f1, roc_auc\n\n    def select_features(self) -> List[str]:\n        \"\"\"\n        Selects features based on predefined thresholds for accuracy,\n        F1 score, and ROC AUC score.\n\n        Returns:\n        List[str]: A list of selected feature names that meet the thresholds.\n        \"\"\"\n        for feature in self.X.columns:\n            accuracy, f1, roc_auc = self.evaluate_feature(feature)\n            # Check if the feature meets the criteria for selection\n            if accuracy > 0.7 and f1 > 0.6 and roc_auc > 0.7:\n                self.selected_features.append(feature)\n        return self.selected_features\n\n# Example usage:\n# df = pd.read_csv('patient_data.csv')\n# X = df.drop('readmission', axis=1)\n# y = df['readmission']\n# selector = FeatureSelector(X, y)\n# selected_features = selector.select_features()",
    "rejected_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\nclass FeatureSelector:\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n        self.selected_features = []\n\n    def evaluate_feature(self, feature):\n        X_train, X_test, y_train, y_test = train_test_split(self.X[[feature]], self.y, test_size=0.2, random_state=42)\n        model = RandomForestClassifier()\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n        return accuracy, f1, roc_auc\n\n    def select_features(self):\n        for feature in self.X.columns:\n            accuracy, f1, roc_auc = self.evaluate_feature(feature)\n            if accuracy > 0.7 and f1 > 0.6 and roc_auc > 0.7:\n                self.selected_features.append(feature)\n        return self.selected_features\n\n# Example usage:\n# df = pd.read_csv('patient_data.csv')\n# X = df.drop('readmission', axis=1)\n# y = df['readmission']\n# selector = FeatureSelector(X, y)\n# selected_features = selector.select_features()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.12162162162162163,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.17142857142857143,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Build a feature selection class with multiple evaluation metrics",
    "code_form": "selector class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python class that implements feature selection using multiple evaluation metrics such as accuracy, F1 score, and ROC AUC.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom typing import List, Tuple, Any\n\nclass FeatureSelector:\n    \"\"\"\n    A class to perform feature selection based on multiple evaluation metrics.\n    This class evaluates features from a dataset using accuracy, F1 score,\n    and ROC AUC to determine which features contribute significantly to\n    the predictive power of a model.\n    \"\"\"\n\n    def __init__(self, X: pd.DataFrame, y: pd.Series) -> None:\n        \"\"\"\n        Initializes the FeatureSelector with feature data and target labels.\n\n        Parameters:\n        X (pd.DataFrame): The feature dataset.\n        y (pd.Series): The target variable.\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.selected_features: List[str] = []\n\n    def evaluate_feature(self, feature: str) -> Tuple[float, float, float]:\n        \"\"\"\n        Evaluates a single feature using a Random Forest classifier.\n\n        Parameters:\n        feature (str): The name of the feature to evaluate.\n\n        Returns:\n        Tuple[float, float, float]: A tuple containing accuracy, F1 score,\n        and ROC AUC score of the model using the specified feature.\n        \"\"\"\n        # Split the data into training and testing sets\n        X_train, X_test, y_train, y_test = train_test_split(\n            self.X[[feature]], self.y, test_size=0.2, random_state=42\n        )\n        model = RandomForestClassifier(random_state=42)\n        model.fit(X_train, y_train)\n\n        # Make predictions\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n\n        return accuracy, f1, roc_auc\n\n    def select_features(self) -> List[str]:\n        \"\"\"\n        Selects features based on predefined thresholds for accuracy,\n        F1 score, and ROC AUC score.\n\n        Returns:\n        List[str]: A list of selected feature names that meet the thresholds.\n        \"\"\"\n        for feature in self.X.columns:\n            accuracy, f1, roc_auc = self.evaluate_feature(feature)\n            # Check if the feature meets the criteria for selection\n            if accuracy > 0.7 and f1 > 0.6 and roc_auc > 0.7:\n                self.selected_features.append(feature)\n        return self.selected_features\n\n# Example usage:\n# df = pd.read_csv('patient_data.csv')\n# X = df.drop('readmission', axis=1)\n# y = df['readmission']\n# selector = FeatureSelector(X, y)\n# selected_features = selector.select_features()",
    "rejected_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\nclass FeatureSelector:\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n        self.selected_features = []\n\n    def evaluate_feature(self, feature):\n        X_train, X_test, y_train, y_test = train_test_split(self.X[[feature]], self.y, test_size=0.2, random_state=42)\n        model = RandomForestClassifier()\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n        return accuracy, f1, roc_auc\n\n    def select_features(self):\n        for feature in self.X.columns:\n            accuracy, f1, roc_auc = self.evaluate_feature(feature)\n            if accuracy > 0.7 and f1 > 0.6 and roc_auc > 0.7:\n                self.selected_features.append(feature)\n        return self.selected_features\n\n# Example usage:\n# df = pd.read_csv('patient_data.csv')\n# X = df.drop('readmission', axis=1)\n# y = df['readmission']\n# selector = FeatureSelector(X, y)\n# selected_features = selector.select_features()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.12162162162162163,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.17142857142857143,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Build a feature selection class with multiple evaluation metrics",
    "code_form": "selector class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you create a Python class that performs feature selection, taking a DataFrame for features and a Series for the target variable, and returning a list of selected feature names?",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom typing import List, Tuple, Any\n\nclass FeatureSelector:\n    \"\"\"\n    A class to perform feature selection based on multiple evaluation metrics.\n    This class evaluates features from a dataset using accuracy, F1 score,\n    and ROC AUC to determine which features contribute significantly to\n    the predictive power of a model.\n    \"\"\"\n\n    def __init__(self, X: pd.DataFrame, y: pd.Series) -> None:\n        \"\"\"\n        Initializes the FeatureSelector with feature data and target labels.\n\n        Parameters:\n        X (pd.DataFrame): The feature dataset.\n        y (pd.Series): The target variable.\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.selected_features: List[str] = []\n\n    def evaluate_feature(self, feature: str) -> Tuple[float, float, float]:\n        \"\"\"\n        Evaluates a single feature using a Random Forest classifier.\n\n        Parameters:\n        feature (str): The name of the feature to evaluate.\n\n        Returns:\n        Tuple[float, float, float]: A tuple containing accuracy, F1 score,\n        and ROC AUC score of the model using the specified feature.\n        \"\"\"\n        # Split the data into training and testing sets\n        X_train, X_test, y_train, y_test = train_test_split(\n            self.X[[feature]], self.y, test_size=0.2, random_state=42\n        )\n        model = RandomForestClassifier(random_state=42)\n        model.fit(X_train, y_train)\n\n        # Make predictions\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n\n        return accuracy, f1, roc_auc\n\n    def select_features(self) -> List[str]:\n        \"\"\"\n        Selects features based on predefined thresholds for accuracy,\n        F1 score, and ROC AUC score.\n\n        Returns:\n        List[str]: A list of selected feature names that meet the thresholds.\n        \"\"\"\n        for feature in self.X.columns:\n            accuracy, f1, roc_auc = self.evaluate_feature(feature)\n            # Check if the feature meets the criteria for selection\n            if accuracy > 0.7 and f1 > 0.6 and roc_auc > 0.7:\n                self.selected_features.append(feature)\n        return self.selected_features\n\n# Example usage:\n# df = pd.read_csv('patient_data.csv')\n# X = df.drop('readmission', axis=1)\n# y = df['readmission']\n# selector = FeatureSelector(X, y)\n# selected_features = selector.select_features()",
    "rejected_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\nclass FeatureSelector:\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n        self.selected_features = []\n\n    def evaluate_feature(self, feature):\n        X_train, X_test, y_train, y_test = train_test_split(self.X[[feature]], self.y, test_size=0.2, random_state=42)\n        model = RandomForestClassifier()\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred)\n        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n        return accuracy, f1, roc_auc\n\n    def select_features(self):\n        for feature in self.X.columns:\n            accuracy, f1, roc_auc = self.evaluate_feature(feature)\n            if accuracy > 0.7 and f1 > 0.6 and roc_auc > 0.7:\n                self.selected_features.append(feature)\n        return self.selected_features\n\n# Example usage:\n# df = pd.read_csv('patient_data.csv')\n# X = df.drop('readmission', axis=1)\n# y = df['readmission']\n# selector = FeatureSelector(X, y)\n# selected_features = selector.select_features()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.12162162162162163,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.17142857142857143,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Create a hyperparameter optimization class with multiple search strategies",
    "code_form": "optimizer class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to create a hyperparameter optimization class with multiple search strategies for a Random Forest classifier.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skopt import BayesSearchCV\nfrom typing import Dict, Any, Tuple\n\nclass HyperparameterOptimizer:\n    \"\"\"\n    A class to perform hyperparameter optimization for a Random Forest classifier.\n    This class supports both Grid Search and Bayesian Optimization strategies.\n    \"\"\"\n\n    def __init__(self, X: pd.DataFrame, y: pd.Series) -> None:\n        \"\"\"\n        Initializes the HyperparameterOptimizer with features and target labels.\n        \n        Parameters:\n        X (pd.DataFrame): Feature dataset.\n        y (pd.Series): Target labels (binary classification).\n        \"\"\"\n        self.X = X\n        self.y = y\n\n    def grid_search(self) -> Dict[str, Any]:\n        \"\"\"\n        Performs grid search to find the best hyperparameters for the Random Forest classifier.\n        \n        Returns:\n        Dict[str, Any]: The best hyperparameters found by grid search.\n        \"\"\"\n        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n        model = RandomForestClassifier()\n        grid_search = GridSearchCV(model, param_grid, cv=5)\n        grid_search.fit(self.X, self.y)\n        return grid_search.best_params_\n\n    def bayesian_optimization(self) -> Dict[str, Any]:\n        \"\"\"\n        Performs Bayesian optimization to find the best hyperparameters for the Random Forest classifier.\n        \n        Returns:\n        Dict[str, Any]: The best hyperparameters found by Bayesian optimization.\n        \"\"\"\n        param_space = {'n_estimators': (50, 200), 'max_depth': (1, 20)}\n        model = RandomForestClassifier()\n        bayes_search = BayesSearchCV(model, param_space, n_iter=30, cv=5)\n        bayes_search.fit(self.X, self.y)\n        return bayes_search.best_params_\n\n# Usage example\n# Load your dataset\n# data = pd.read_csv('customer_data.csv')\n# X = data.drop('churn', axis=1)\n# y = data['churn']\n# optimizer = HyperparameterOptimizer(X, y)\n# best_grid_params = optimizer.grid_search()\n# best_bayes_params = optimizer.bayesian_optimization()",
    "rejected_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skopt import BayesSearchCV\n\nclass HyperparameterOptimizer:\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def grid_search(self):\n        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n        model = RandomForestClassifier()\n        grid_search = GridSearchCV(model, param_grid, cv=5)\n        grid_search.fit(self.X, self.y)\n        return grid_search.best_params_\n\n    def bayesian_optimization(self):\n        param_space = {'n_estimators': (50, 200), 'max_depth': (1, 20)}\n        model = RandomForestClassifier()\n        bayes_search = BayesSearchCV(model, param_space, n_iter=30, cv=5)\n        bayes_search.fit(self.X, self.y)\n        return bayes_search.best_params_\n\n# Usage example\n\n# Load your dataset\n# data = pd.read_csv('customer_data.csv')\n# X = data.drop('churn', axis=1)\n# y = data['churn']\n\n# optimizer = HyperparameterOptimizer(X, y)\n# best_grid_params = optimizer.grid_search()\n# best_bayes_params = optimizer.bayesian_optimization()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.13793103448275862,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 5, in <module>\nModuleNotFoundError: No module named 'skopt'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.22857142857142856,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 5, in <module>\nModuleNotFoundError: No module named 'skopt'"
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Create a hyperparameter optimization class with multiple search strategies",
    "code_form": "optimizer class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a class that implements hyperparameter optimization strategies for a Random Forest classifier?",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skopt import BayesSearchCV\nfrom typing import Dict, Any, Tuple\n\nclass HyperparameterOptimizer:\n    \"\"\"\n    A class to perform hyperparameter optimization for a Random Forest classifier.\n    This class supports both Grid Search and Bayesian Optimization strategies.\n    \"\"\"\n\n    def __init__(self, X: pd.DataFrame, y: pd.Series) -> None:\n        \"\"\"\n        Initializes the HyperparameterOptimizer with features and target labels.\n        \n        Parameters:\n        X (pd.DataFrame): Feature dataset.\n        y (pd.Series): Target labels (binary classification).\n        \"\"\"\n        self.X = X\n        self.y = y\n\n    def grid_search(self) -> Dict[str, Any]:\n        \"\"\"\n        Performs grid search to find the best hyperparameters for the Random Forest classifier.\n        \n        Returns:\n        Dict[str, Any]: The best hyperparameters found by grid search.\n        \"\"\"\n        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n        model = RandomForestClassifier()\n        grid_search = GridSearchCV(model, param_grid, cv=5)\n        grid_search.fit(self.X, self.y)\n        return grid_search.best_params_\n\n    def bayesian_optimization(self) -> Dict[str, Any]:\n        \"\"\"\n        Performs Bayesian optimization to find the best hyperparameters for the Random Forest classifier.\n        \n        Returns:\n        Dict[str, Any]: The best hyperparameters found by Bayesian optimization.\n        \"\"\"\n        param_space = {'n_estimators': (50, 200), 'max_depth': (1, 20)}\n        model = RandomForestClassifier()\n        bayes_search = BayesSearchCV(model, param_space, n_iter=30, cv=5)\n        bayes_search.fit(self.X, self.y)\n        return bayes_search.best_params_\n\n# Usage example\n# Load your dataset\n# data = pd.read_csv('customer_data.csv')\n# X = data.drop('churn', axis=1)\n# y = data['churn']\n# optimizer = HyperparameterOptimizer(X, y)\n# best_grid_params = optimizer.grid_search()\n# best_bayes_params = optimizer.bayesian_optimization()",
    "rejected_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skopt import BayesSearchCV\n\nclass HyperparameterOptimizer:\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def grid_search(self):\n        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n        model = RandomForestClassifier()\n        grid_search = GridSearchCV(model, param_grid, cv=5)\n        grid_search.fit(self.X, self.y)\n        return grid_search.best_params_\n\n    def bayesian_optimization(self):\n        param_space = {'n_estimators': (50, 200), 'max_depth': (1, 20)}\n        model = RandomForestClassifier()\n        bayes_search = BayesSearchCV(model, param_space, n_iter=30, cv=5)\n        bayes_search.fit(self.X, self.y)\n        return bayes_search.best_params_\n\n# Usage example\n\n# Load your dataset\n# data = pd.read_csv('customer_data.csv')\n# X = data.drop('churn', axis=1)\n# y = data['churn']\n\n# optimizer = HyperparameterOptimizer(X, y)\n# best_grid_params = optimizer.grid_search()\n# best_bayes_params = optimizer.bayesian_optimization()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.13793103448275862,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 5, in <module>\nModuleNotFoundError: No module named 'skopt'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.22857142857142856,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 5, in <module>\nModuleNotFoundError: No module named 'skopt'"
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Create a hyperparameter optimization class with multiple search strategies",
    "code_form": "optimizer class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you provide a class that performs hyperparameter optimization for a Random Forest classifier, with specified input types as DataFrame for features and Series for target, and output types as a dictionary of best parameters?",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skopt import BayesSearchCV\nfrom typing import Dict, Any, Tuple\n\nclass HyperparameterOptimizer:\n    \"\"\"\n    A class to perform hyperparameter optimization for a Random Forest classifier.\n    This class supports both Grid Search and Bayesian Optimization strategies.\n    \"\"\"\n\n    def __init__(self, X: pd.DataFrame, y: pd.Series) -> None:\n        \"\"\"\n        Initializes the HyperparameterOptimizer with features and target labels.\n        \n        Parameters:\n        X (pd.DataFrame): Feature dataset.\n        y (pd.Series): Target labels (binary classification).\n        \"\"\"\n        self.X = X\n        self.y = y\n\n    def grid_search(self) -> Dict[str, Any]:\n        \"\"\"\n        Performs grid search to find the best hyperparameters for the Random Forest classifier.\n        \n        Returns:\n        Dict[str, Any]: The best hyperparameters found by grid search.\n        \"\"\"\n        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n        model = RandomForestClassifier()\n        grid_search = GridSearchCV(model, param_grid, cv=5)\n        grid_search.fit(self.X, self.y)\n        return grid_search.best_params_\n\n    def bayesian_optimization(self) -> Dict[str, Any]:\n        \"\"\"\n        Performs Bayesian optimization to find the best hyperparameters for the Random Forest classifier.\n        \n        Returns:\n        Dict[str, Any]: The best hyperparameters found by Bayesian optimization.\n        \"\"\"\n        param_space = {'n_estimators': (50, 200), 'max_depth': (1, 20)}\n        model = RandomForestClassifier()\n        bayes_search = BayesSearchCV(model, param_space, n_iter=30, cv=5)\n        bayes_search.fit(self.X, self.y)\n        return bayes_search.best_params_\n\n# Usage example\n# Load your dataset\n# data = pd.read_csv('customer_data.csv')\n# X = data.drop('churn', axis=1)\n# y = data['churn']\n# optimizer = HyperparameterOptimizer(X, y)\n# best_grid_params = optimizer.grid_search()\n# best_bayes_params = optimizer.bayesian_optimization()",
    "rejected_code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skopt import BayesSearchCV\n\nclass HyperparameterOptimizer:\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def grid_search(self):\n        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n        model = RandomForestClassifier()\n        grid_search = GridSearchCV(model, param_grid, cv=5)\n        grid_search.fit(self.X, self.y)\n        return grid_search.best_params_\n\n    def bayesian_optimization(self):\n        param_space = {'n_estimators': (50, 200), 'max_depth': (1, 20)}\n        model = RandomForestClassifier()\n        bayes_search = BayesSearchCV(model, param_space, n_iter=30, cv=5)\n        bayes_search.fit(self.X, self.y)\n        return bayes_search.best_params_\n\n# Usage example\n\n# Load your dataset\n# data = pd.read_csv('customer_data.csv')\n# X = data.drop('churn', axis=1)\n# y = data['churn']\n\n# optimizer = HyperparameterOptimizer(X, y)\n# best_grid_params = optimizer.grid_search()\n# best_bayes_params = optimizer.bayesian_optimization()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.13793103448275862,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 5, in <module>\nModuleNotFoundError: No module named 'skopt'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.22857142857142856,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 5, in <module>\nModuleNotFoundError: No module named 'skopt'"
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Implement a resource usage tracker for system processes",
    "code_form": "tracker function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to implement a resource usage tracker for system processes?",
      "role": "user"
    },
    "chosen_code": "import psutil\nimport time\nimport logging\nfrom typing import Optional\n\n# Configure logging to write to a file with an appropriate log level\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\n\ndef track_resource_usage(process_name: str, cpu_threshold: float, memory_threshold: float) -> None:\n    \"\"\"\n    Monitors the CPU and memory usage of a specific system process.\n\n    This function checks the CPU and memory usage of the specified process every minute.\n    If the usage exceeds the defined thresholds, an alert is logged.\n\n    Args:\n        process_name (str): The name of the process to monitor.\n        cpu_threshold (float): The CPU usage threshold percentage.\n        memory_threshold (float): The memory usage threshold in MB.\n    \"\"\"\n    while True:\n        # Iterate over all running processes\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\n            # Check if the current process matches the specified name\n            if proc.info['name'] == process_name:\n                # Get CPU usage and convert memory usage to MB\n                cpu_usage: float = proc.info['cpu_percent']\n                memory_usage: float = proc.info['memory_info'].rss / (1024 * 1024)\n                # Log an alert if thresholds are exceeded\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage:.2f}MB memory.')\n        # Sleep for 60 seconds before the next check\n        time.sleep(60)\n\n\n# Example usage (uncomment to run):\n# track_resource_usage('your_process_name', 80.0, 150.0)",
    "rejected_code": "import psutil\nimport time\nimport logging\n\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO)\n\ndef track_resource_usage(process_name, cpu_threshold, memory_threshold):\n    while True:\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\n            if proc.info['name'] == process_name:\n                cpu_usage = proc.info['cpu_percent']\n                memory_usage = proc.info['memory_info'].rss / (1024 * 1024)\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage}MB memory.')\n        time.sleep(60)\n\ntrack_resource_usage('your_process_name', 80, 150)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.21052631578947367,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"import psutil\\nimport time\\nimport logging\\n\\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO)\\n\\ndef track_resource_usage(process_name, cpu_threshold, memory_threshold):\\n    while True:\\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\\n            if proc.info['name'] == process_name:\\n                cpu_usage = proc.info['cpu_percent']\\n                memory_usage = proc.info['memory_info'].rss / (1024 * 1024)\\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage}MB memory.')\\n        time.sleep(60)\\n\\ntrack_resource_usage('your_process_name', 80, 150)\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Implement a resource usage tracker for system processes",
    "code_form": "tracker function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python function to implement a resource usage tracker for system processes.",
      "role": "user"
    },
    "chosen_code": "import psutil\nimport time\nimport logging\nfrom typing import Optional\n\n# Configure logging to write to a file with an appropriate log level\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\n\ndef track_resource_usage(process_name: str, cpu_threshold: float, memory_threshold: float) -> None:\n    \"\"\"\n    Monitors the CPU and memory usage of a specific system process.\n\n    This function checks the CPU and memory usage of the specified process every minute.\n    If the usage exceeds the defined thresholds, an alert is logged.\n\n    Args:\n        process_name (str): The name of the process to monitor.\n        cpu_threshold (float): The CPU usage threshold percentage.\n        memory_threshold (float): The memory usage threshold in MB.\n    \"\"\"\n    while True:\n        # Iterate over all running processes\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\n            # Check if the current process matches the specified name\n            if proc.info['name'] == process_name:\n                # Get CPU usage and convert memory usage to MB\n                cpu_usage: float = proc.info['cpu_percent']\n                memory_usage: float = proc.info['memory_info'].rss / (1024 * 1024)\n                # Log an alert if thresholds are exceeded\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage:.2f}MB memory.')\n        # Sleep for 60 seconds before the next check\n        time.sleep(60)\n\n\n# Example usage (uncomment to run):\n# track_resource_usage('your_process_name', 80.0, 150.0)",
    "rejected_code": "import psutil\nimport time\nimport logging\n\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO)\n\ndef track_resource_usage(process_name, cpu_threshold, memory_threshold):\n    while True:\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\n            if proc.info['name'] == process_name:\n                cpu_usage = proc.info['cpu_percent']\n                memory_usage = proc.info['memory_info'].rss / (1024 * 1024)\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage}MB memory.')\n        time.sleep(60)\n\ntrack_resource_usage('your_process_name', 80, 150)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.21052631578947367,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"import psutil\\nimport time\\nimport logging\\n\\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO)\\n\\ndef track_resource_usage(process_name, cpu_threshold, memory_threshold):\\n    while True:\\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\\n            if proc.info['name'] == process_name:\\n                cpu_usage = proc.info['cpu_percent']\\n                memory_usage = proc.info['memory_info'].rss / (1024 * 1024)\\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage}MB memory.')\\n        time.sleep(60)\\n\\ntrack_resource_usage('your_process_name', 80, 150)\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Implement a resource usage tracker for system processes",
    "code_form": "tracker function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python function that implements a resource usage tracker for system processes, specifying input types as strings and floats, and the output type as None.",
      "role": "user"
    },
    "chosen_code": "import psutil\nimport time\nimport logging\nfrom typing import Optional\n\n# Configure logging to write to a file with an appropriate log level\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\n\ndef track_resource_usage(process_name: str, cpu_threshold: float, memory_threshold: float) -> None:\n    \"\"\"\n    Monitors the CPU and memory usage of a specific system process.\n\n    This function checks the CPU and memory usage of the specified process every minute.\n    If the usage exceeds the defined thresholds, an alert is logged.\n\n    Args:\n        process_name (str): The name of the process to monitor.\n        cpu_threshold (float): The CPU usage threshold percentage.\n        memory_threshold (float): The memory usage threshold in MB.\n    \"\"\"\n    while True:\n        # Iterate over all running processes\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\n            # Check if the current process matches the specified name\n            if proc.info['name'] == process_name:\n                # Get CPU usage and convert memory usage to MB\n                cpu_usage: float = proc.info['cpu_percent']\n                memory_usage: float = proc.info['memory_info'].rss / (1024 * 1024)\n                # Log an alert if thresholds are exceeded\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage:.2f}MB memory.')\n        # Sleep for 60 seconds before the next check\n        time.sleep(60)\n\n\n# Example usage (uncomment to run):\n# track_resource_usage('your_process_name', 80.0, 150.0)",
    "rejected_code": "import psutil\nimport time\nimport logging\n\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO)\n\ndef track_resource_usage(process_name, cpu_threshold, memory_threshold):\n    while True:\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\n            if proc.info['name'] == process_name:\n                cpu_usage = proc.info['cpu_percent']\n                memory_usage = proc.info['memory_info'].rss / (1024 * 1024)\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage}MB memory.')\n        time.sleep(60)\n\ntrack_resource_usage('your_process_name', 80, 150)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.21052631578947367,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"import psutil\\nimport time\\nimport logging\\n\\nlogging.basicConfig(filename='resource_usage.log', level=logging.INFO)\\n\\ndef track_resource_usage(process_name, cpu_threshold, memory_threshold):\\n    while True:\\n        for proc in psutil.process_iter(['name', 'cpu_percent', 'memory_info']):\\n            if proc.info['name'] == process_name:\\n                cpu_usage = proc.info['cpu_percent']\\n                memory_usage = proc.info['memory_info'].rss / (1024 * 1024)\\n                if cpu_usage > cpu_threshold or memory_usage > memory_threshold:\\n                    logging.info(f'Alert: {process_name} using {cpu_usage}% CPU and {memory_usage}MB memory.')\\n        time.sleep(60)\\n\\ntrack_resource_usage('your_process_name', 80, 150)\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Create a file monitoring system with custom event handlers",
    "code_form": "monitor class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create a log file monitoring system with custom event handlers?",
      "role": "user"
    },
    "chosen_code": "import time\nimport smtplib\nfrom pathlib import Path\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\nfrom typing import Optional\n\nclass LogEventHandler(FileSystemEventHandler):\n    \"\"\"\n    Custom event handler for monitoring log files. Triggers alerts when an error is logged.\n    \"\"\"\n\n    def on_modified(self, event: Path) -> None:\n        \"\"\"\n        Called when a file is modified. Checks for errors in the log file and sends alerts.\n        \n        Args:\n            event (Path): The file system event that occurred.\n        \"\"\"  \n        if event.is_directory:\n            return  # Ignore directory modifications\n        self.check_for_errors(event.src_path)\n\n    def check_for_errors(self, file_path: str) -> None:\n        \"\"\"\n        Reads the log file and checks for any lines containing 'ERROR'.\n        If found, triggers an alert.\n        \n        Args:\n            file_path (str): The path to the log file.\n        \"\"\"  \n        try:\n            with open(file_path, 'r') as file:\n                lines = file.readlines()\n                for line in lines:\n                    if 'ERROR' in line:\n                        self.send_alert(line.strip())  # Send alert for each error\n        except Exception as e:\n            print(f'Error reading file {file_path}: {e}')  # Log any errors while reading the file\n\n    def send_alert(self, error_message: str) -> None:\n        \"\"\"\n        Sends an email alert with the error message.\n        \n        Args:\n            error_message (str): The error message to include in the alert.\n        \"\"\"  \n        try:\n            server = smtplib.SMTP('smtp.example.com', 587)\n            server.starttls()\n            server.login('your_email@example.com', 'your_password')\n            message = f'Subject: Error Alert\\n\\nAn error was detected: {error_message}'\n            server.sendmail('your_email@example.com', 'alert_recipient@example.com', message)\n        except Exception as e:\n            print(f'Failed to send alert: {e}')  # Log any errors while sending the email\n        finally:\n            server.quit()\n\n\ndef main(log_directory: str) -> None:\n    \"\"\"\n    Main function to set up the log monitoring system.\n    \n    Args:\n        log_directory (str): The path to the directory containing log files to monitor.\n    \"\"\"  \n    path = Path(log_directory)\n    observer = Observer()\n    observer.schedule(LogEventHandler(), path, recursive=False)\n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\n\nif __name__ == '__main__':\n    main('/path/to/log/directory')",
    "rejected_code": "import time\nimport smtplib\nfrom pathlib import Path\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\n\nclass LogEventHandler(FileSystemEventHandler):\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        with open(event.src_path, 'r') as file:\n            lines = file.readlines()\n            for line in lines:\n                if 'ERROR' in line:\n                    self.send_alert(line)\n\n    def send_alert(self, error_message):\n        server = smtplib.SMTP('smtp.example.com', 587)\n        server.starttls()\n        server.login('your_email@example.com', 'your_password')\n        message = f'Subject: Error Alert\\n\\nAn error was detected: {error_message}'\n        server.sendmail('your_email@example.com', 'alert_recipient@example.com', message)\n        server.quit()\n\npath = Path('/path/to/log/directory')\nobserver = Observer()\nobserver.schedule(LogEventHandler(), path, recursive=False)\nobserver.start()\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    observer.stop()\nobserver.join()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 4, in <module>\nModuleNotFoundError: No module named 'watchdog'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 4, in <module>\nModuleNotFoundError: No module named 'watchdog'"
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Create a file monitoring system with custom event handlers",
    "code_form": "monitor class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Could you write a class in Python that implements a log file monitoring system with custom event handlers?",
      "role": "user"
    },
    "chosen_code": "import time\nimport smtplib\nfrom pathlib import Path\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\nfrom typing import Optional\n\nclass LogEventHandler(FileSystemEventHandler):\n    \"\"\"\n    Custom event handler for monitoring log files. Triggers alerts when an error is logged.\n    \"\"\"\n\n    def on_modified(self, event: Path) -> None:\n        \"\"\"\n        Called when a file is modified. Checks for errors in the log file and sends alerts.\n        \n        Args:\n            event (Path): The file system event that occurred.\n        \"\"\"  \n        if event.is_directory:\n            return  # Ignore directory modifications\n        self.check_for_errors(event.src_path)\n\n    def check_for_errors(self, file_path: str) -> None:\n        \"\"\"\n        Reads the log file and checks for any lines containing 'ERROR'.\n        If found, triggers an alert.\n        \n        Args:\n            file_path (str): The path to the log file.\n        \"\"\"  \n        try:\n            with open(file_path, 'r') as file:\n                lines = file.readlines()\n                for line in lines:\n                    if 'ERROR' in line:\n                        self.send_alert(line.strip())  # Send alert for each error\n        except Exception as e:\n            print(f'Error reading file {file_path}: {e}')  # Log any errors while reading the file\n\n    def send_alert(self, error_message: str) -> None:\n        \"\"\"\n        Sends an email alert with the error message.\n        \n        Args:\n            error_message (str): The error message to include in the alert.\n        \"\"\"  \n        try:\n            server = smtplib.SMTP('smtp.example.com', 587)\n            server.starttls()\n            server.login('your_email@example.com', 'your_password')\n            message = f'Subject: Error Alert\\n\\nAn error was detected: {error_message}'\n            server.sendmail('your_email@example.com', 'alert_recipient@example.com', message)\n        except Exception as e:\n            print(f'Failed to send alert: {e}')  # Log any errors while sending the email\n        finally:\n            server.quit()\n\n\ndef main(log_directory: str) -> None:\n    \"\"\"\n    Main function to set up the log monitoring system.\n    \n    Args:\n        log_directory (str): The path to the directory containing log files to monitor.\n    \"\"\"  \n    path = Path(log_directory)\n    observer = Observer()\n    observer.schedule(LogEventHandler(), path, recursive=False)\n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\n\nif __name__ == '__main__':\n    main('/path/to/log/directory')",
    "rejected_code": "import time\nimport smtplib\nfrom pathlib import Path\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\n\nclass LogEventHandler(FileSystemEventHandler):\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        with open(event.src_path, 'r') as file:\n            lines = file.readlines()\n            for line in lines:\n                if 'ERROR' in line:\n                    self.send_alert(line)\n\n    def send_alert(self, error_message):\n        server = smtplib.SMTP('smtp.example.com', 587)\n        server.starttls()\n        server.login('your_email@example.com', 'your_password')\n        message = f'Subject: Error Alert\\n\\nAn error was detected: {error_message}'\n        server.sendmail('your_email@example.com', 'alert_recipient@example.com', message)\n        server.quit()\n\npath = Path('/path/to/log/directory')\nobserver = Observer()\nobserver.schedule(LogEventHandler(), path, recursive=False)\nobserver.start()\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    observer.stop()\nobserver.join()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 4, in <module>\nModuleNotFoundError: No module named 'watchdog'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 4, in <module>\nModuleNotFoundError: No module named 'watchdog'"
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Create a file monitoring system with custom event handlers",
    "code_form": "monitor class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a Python class that implements a log file monitoring system with custom event handlers, specifying input and output types.",
      "role": "user"
    },
    "chosen_code": "import time\nimport smtplib\nfrom pathlib import Path\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\nfrom typing import Optional\n\nclass LogEventHandler(FileSystemEventHandler):\n    \"\"\"\n    Custom event handler for monitoring log files. Triggers alerts when an error is logged.\n    \"\"\"\n\n    def on_modified(self, event: Path) -> None:\n        \"\"\"\n        Called when a file is modified. Checks for errors in the log file and sends alerts.\n        \n        Args:\n            event (Path): The file system event that occurred.\n        \"\"\"  \n        if event.is_directory:\n            return  # Ignore directory modifications\n        self.check_for_errors(event.src_path)\n\n    def check_for_errors(self, file_path: str) -> None:\n        \"\"\"\n        Reads the log file and checks for any lines containing 'ERROR'.\n        If found, triggers an alert.\n        \n        Args:\n            file_path (str): The path to the log file.\n        \"\"\"  \n        try:\n            with open(file_path, 'r') as file:\n                lines = file.readlines()\n                for line in lines:\n                    if 'ERROR' in line:\n                        self.send_alert(line.strip())  # Send alert for each error\n        except Exception as e:\n            print(f'Error reading file {file_path}: {e}')  # Log any errors while reading the file\n\n    def send_alert(self, error_message: str) -> None:\n        \"\"\"\n        Sends an email alert with the error message.\n        \n        Args:\n            error_message (str): The error message to include in the alert.\n        \"\"\"  \n        try:\n            server = smtplib.SMTP('smtp.example.com', 587)\n            server.starttls()\n            server.login('your_email@example.com', 'your_password')\n            message = f'Subject: Error Alert\\n\\nAn error was detected: {error_message}'\n            server.sendmail('your_email@example.com', 'alert_recipient@example.com', message)\n        except Exception as e:\n            print(f'Failed to send alert: {e}')  # Log any errors while sending the email\n        finally:\n            server.quit()\n\n\ndef main(log_directory: str) -> None:\n    \"\"\"\n    Main function to set up the log monitoring system.\n    \n    Args:\n        log_directory (str): The path to the directory containing log files to monitor.\n    \"\"\"  \n    path = Path(log_directory)\n    observer = Observer()\n    observer.schedule(LogEventHandler(), path, recursive=False)\n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\n\nif __name__ == '__main__':\n    main('/path/to/log/directory')",
    "rejected_code": "import time\nimport smtplib\nfrom pathlib import Path\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\n\nclass LogEventHandler(FileSystemEventHandler):\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        with open(event.src_path, 'r') as file:\n            lines = file.readlines()\n            for line in lines:\n                if 'ERROR' in line:\n                    self.send_alert(line)\n\n    def send_alert(self, error_message):\n        server = smtplib.SMTP('smtp.example.com', 587)\n        server.starttls()\n        server.login('your_email@example.com', 'your_password')\n        message = f'Subject: Error Alert\\n\\nAn error was detected: {error_message}'\n        server.sendmail('your_email@example.com', 'alert_recipient@example.com', message)\n        server.quit()\n\npath = Path('/path/to/log/directory')\nobserver = Observer()\nobserver.schedule(LogEventHandler(), path, recursive=False)\nobserver.start()\ntry:\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    observer.stop()\nobserver.join()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 4, in <module>\nModuleNotFoundError: No module named 'watchdog'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 4, in <module>\nModuleNotFoundError: No module named 'watchdog'"
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Develop a data preprocessing pipeline function with scaling and encoding",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Write Python code to develop a data preprocessing pipeline function with scaling and encoding for a retail company's customer data.",
      "role": "user"
    },
    "chosen_code": "from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\nfrom pandas import DataFrame\nfrom typing import Any\n\n\ndef preprocess_data(df: DataFrame) -> Any:\n    \"\"\"\n    Preprocesses the input DataFrame by scaling numerical features and encoding categorical features.\n\n    Parameters:\n    df (DataFrame): The input DataFrame containing customer data with both numerical and categorical features.\n\n    Returns:\n    Any: The transformed data after applying scaling and encoding.\n    \"\"\"\n    # Define numerical and categorical features\n    numerical_features: list[str] = ['age', 'income', 'spending_score']\n    categorical_features: list[str] = ['gender', 'city']\n    \n    # Create transformers for numerical and categorical features\n    numerical_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n    \n    # Combine transformers into a ColumnTransformer\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features)\n        ]\n    )\n    \n    # Create a pipeline that includes the preprocessor\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n    \n    # Fit the pipeline to the data and transform it\n    return pipeline.fit_transform(df)\n\n# Example usage:\n# df = pd.DataFrame({'age': [25, 30, 22], 'income': [50000, 60000, 45000], 'spending_score': [60, 70, 50], 'gender': ['Male', 'Female', 'Female'], 'city': ['New York', 'Los Angeles', 'Chicago']})\n# processed_data = preprocess_data(df)",
    "rejected_code": "from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\n\ndef preprocess_data(df):\n    numerical_features = ['age', 'income', 'spending_score']\n    categorical_features = ['gender', 'city']\n    \n    numerical_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder()\n    \n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features)\n        ])\n    \n    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n    return pipeline.fit_transform(df)\n\n# Example usage:\n# df = pd.DataFrame({'age': [25, 30, 22], 'income': [50000, 60000, 45000], 'spending_score': [60, 70, 50], 'gender': ['Male', 'Female', 'Female'], 'city': ['New York', 'Los Angeles', 'Chicago']})\n# processed_data = preprocess_data(df)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.18604651162790697,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.125,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Develop a data preprocessing pipeline function with scaling and encoding",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Create a Python function that implements a data preprocessing pipeline with scaling and encoding for customer data.",
      "role": "user"
    },
    "chosen_code": "from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\nfrom pandas import DataFrame\nfrom typing import Any\n\n\ndef preprocess_data(df: DataFrame) -> Any:\n    \"\"\"\n    Preprocesses the input DataFrame by scaling numerical features and encoding categorical features.\n\n    Parameters:\n    df (DataFrame): The input DataFrame containing customer data with both numerical and categorical features.\n\n    Returns:\n    Any: The transformed data after applying scaling and encoding.\n    \"\"\"\n    # Define numerical and categorical features\n    numerical_features: list[str] = ['age', 'income', 'spending_score']\n    categorical_features: list[str] = ['gender', 'city']\n    \n    # Create transformers for numerical and categorical features\n    numerical_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n    \n    # Combine transformers into a ColumnTransformer\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features)\n        ]\n    )\n    \n    # Create a pipeline that includes the preprocessor\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n    \n    # Fit the pipeline to the data and transform it\n    return pipeline.fit_transform(df)\n\n# Example usage:\n# df = pd.DataFrame({'age': [25, 30, 22], 'income': [50000, 60000, 45000], 'spending_score': [60, 70, 50], 'gender': ['Male', 'Female', 'Female'], 'city': ['New York', 'Los Angeles', 'Chicago']})\n# processed_data = preprocess_data(df)",
    "rejected_code": "from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\n\ndef preprocess_data(df):\n    numerical_features = ['age', 'income', 'spending_score']\n    categorical_features = ['gender', 'city']\n    \n    numerical_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder()\n    \n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features)\n        ])\n    \n    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n    return pipeline.fit_transform(df)\n\n# Example usage:\n# df = pd.DataFrame({'age': [25, 30, 22], 'income': [50000, 60000, 45000], 'spending_score': [60, 70, 50], 'gender': ['Male', 'Female', 'Female'], 'city': ['New York', 'Los Angeles', 'Chicago']})\n# processed_data = preprocess_data(df)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.18604651162790697,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.125,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "machine learning",
    "task": "Develop a data preprocessing pipeline function with scaling and encoding",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Implement a Python function that takes a pandas DataFrame as input and returns the preprocessed data after scaling numerical features and encoding categorical features.",
      "role": "user"
    },
    "chosen_code": "from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\nfrom pandas import DataFrame\nfrom typing import Any\n\n\ndef preprocess_data(df: DataFrame) -> Any:\n    \"\"\"\n    Preprocesses the input DataFrame by scaling numerical features and encoding categorical features.\n\n    Parameters:\n    df (DataFrame): The input DataFrame containing customer data with both numerical and categorical features.\n\n    Returns:\n    Any: The transformed data after applying scaling and encoding.\n    \"\"\"\n    # Define numerical and categorical features\n    numerical_features: list[str] = ['age', 'income', 'spending_score']\n    categorical_features: list[str] = ['gender', 'city']\n    \n    # Create transformers for numerical and categorical features\n    numerical_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n    \n    # Combine transformers into a ColumnTransformer\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features)\n        ]\n    )\n    \n    # Create a pipeline that includes the preprocessor\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n    \n    # Fit the pipeline to the data and transform it\n    return pipeline.fit_transform(df)\n\n# Example usage:\n# df = pd.DataFrame({'age': [25, 30, 22], 'income': [50000, 60000, 45000], 'spending_score': [60, 70, 50], 'gender': ['Male', 'Female', 'Female'], 'city': ['New York', 'Los Angeles', 'Chicago']})\n# processed_data = preprocess_data(df)",
    "rejected_code": "from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\n\ndef preprocess_data(df):\n    numerical_features = ['age', 'income', 'spending_score']\n    categorical_features = ['gender', 'city']\n    \n    numerical_transformer = StandardScaler()\n    categorical_transformer = OneHotEncoder()\n    \n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features)\n        ])\n    \n    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n    return pipeline.fit_transform(df)\n\n# Example usage:\n# df = pd.DataFrame({'age': [25, 30, 22], 'income': [50000, 60000, 45000], 'spending_score': [60, 70, 50], 'gender': ['Male', 'Female', 'Female'], 'city': ['New York', 'Los Angeles', 'Chicago']})\n# processed_data = preprocess_data(df)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.18604651162790697,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.125,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Develop a command execution function with timeout and retry logic",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to implement a command execution function with timeout and retry logic.",
      "role": "user"
    },
    "chosen_code": "import subprocess\nimport time\nfrom typing import Optional\n\n\ndef execute_command_with_retries(command: str, max_retries: int, timeout: int) -> Optional[str]:\n    \"\"\"\n    Executes a shell command with retry and timeout logic.\n\n    Args:\n        command (str): The shell command to execute.\n        max_retries (int): The maximum number of retry attempts.\n        timeout (int): The timeout for each command execution in seconds.\n\n    Returns:\n        Optional[str]: The standard output of the command if successful, None otherwise.\n\n    Raises:\n        subprocess.CalledProcessError: If the command fails after maximum retries.\n        subprocess.TimeoutExpired: If the command times out after maximum retries.\n    \"\"\"\n    for attempt in range(max_retries):\n        try:\n            # Run the command with the specified timeout and check for errors\n            result = subprocess.run(command, shell=True, timeout=timeout, check=True, text=True, capture_output=True)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            print(f'Attempt {attempt + 1} failed: {e}')\n            # If it's the last attempt, raise the error\n            if attempt == max_retries - 1:\n                raise\n            # Wait before retrying\n            time.sleep(1)\n        except subprocess.TimeoutExpired:\n            print(f'Attempt {attempt + 1} timed out')\n            # If it's the last attempt, raise the timeout error\n            if attempt == max_retries - 1:\n                raise\n\n# Example command to backup a directory\ncommand = 'tar -czf backup.tar.gz /path/to/directory'\n# Execute the command with retries\nexecute_command_with_retries(command, 3, 5)",
    "rejected_code": "import subprocess\nimport time\n\ndef execute_command_with_retries(command, max_retries, timeout):\n    for attempt in range(max_retries):\n        try:\n            result = subprocess.run(command, shell=True, timeout=timeout, check=True)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            print(f'Attempt {attempt + 1} failed: {e}')\n            if attempt == max_retries - 1:\n                raise\n            time.sleep(1)\n        except subprocess.TimeoutExpired:\n            print(f'Attempt {attempt + 1} timed out')\n            if attempt == max_retries - 1:\n                raise\n\ncommand = 'tar -czf backup.tar.gz /path/to/directory'\nexecute_command_with_retries(command, 3, 5)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.13953488372093023,
      "execution_result": {
        "success": false,
        "output": "Attempt 1 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 2 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 3 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 43, in <module>\n  File \"<string>\", line 25, in execute_command_with_retries\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1."
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "Attempt 1 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 2 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 3 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.",
        "error": "tar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\ntar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\ntar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\nTraceback (most recent call last):\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 7, in execute_command_with_retries\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1."
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Develop a command execution function with timeout and retry logic",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a Python function that implements command execution with timeout and retry logic?",
      "role": "user"
    },
    "chosen_code": "import subprocess\nimport time\nfrom typing import Optional\n\n\ndef execute_command_with_retries(command: str, max_retries: int, timeout: int) -> Optional[str]:\n    \"\"\"\n    Executes a shell command with retry and timeout logic.\n\n    Args:\n        command (str): The shell command to execute.\n        max_retries (int): The maximum number of retry attempts.\n        timeout (int): The timeout for each command execution in seconds.\n\n    Returns:\n        Optional[str]: The standard output of the command if successful, None otherwise.\n\n    Raises:\n        subprocess.CalledProcessError: If the command fails after maximum retries.\n        subprocess.TimeoutExpired: If the command times out after maximum retries.\n    \"\"\"\n    for attempt in range(max_retries):\n        try:\n            # Run the command with the specified timeout and check for errors\n            result = subprocess.run(command, shell=True, timeout=timeout, check=True, text=True, capture_output=True)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            print(f'Attempt {attempt + 1} failed: {e}')\n            # If it's the last attempt, raise the error\n            if attempt == max_retries - 1:\n                raise\n            # Wait before retrying\n            time.sleep(1)\n        except subprocess.TimeoutExpired:\n            print(f'Attempt {attempt + 1} timed out')\n            # If it's the last attempt, raise the timeout error\n            if attempt == max_retries - 1:\n                raise\n\n# Example command to backup a directory\ncommand = 'tar -czf backup.tar.gz /path/to/directory'\n# Execute the command with retries\nexecute_command_with_retries(command, 3, 5)",
    "rejected_code": "import subprocess\nimport time\n\ndef execute_command_with_retries(command, max_retries, timeout):\n    for attempt in range(max_retries):\n        try:\n            result = subprocess.run(command, shell=True, timeout=timeout, check=True)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            print(f'Attempt {attempt + 1} failed: {e}')\n            if attempt == max_retries - 1:\n                raise\n            time.sleep(1)\n        except subprocess.TimeoutExpired:\n            print(f'Attempt {attempt + 1} timed out')\n            if attempt == max_retries - 1:\n                raise\n\ncommand = 'tar -czf backup.tar.gz /path/to/directory'\nexecute_command_with_retries(command, 3, 5)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.13953488372093023,
      "execution_result": {
        "success": false,
        "output": "Attempt 1 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 2 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 3 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 43, in <module>\n  File \"<string>\", line 25, in execute_command_with_retries\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1."
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "Attempt 1 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 2 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 3 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.",
        "error": "tar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\ntar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\ntar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\nTraceback (most recent call last):\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 7, in execute_command_with_retries\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1."
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Develop a command execution function with timeout and retry logic",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python function that takes a command string, maximum retries, and timeout duration, and returns the output or raises an error.",
      "role": "user"
    },
    "chosen_code": "import subprocess\nimport time\nfrom typing import Optional\n\n\ndef execute_command_with_retries(command: str, max_retries: int, timeout: int) -> Optional[str]:\n    \"\"\"\n    Executes a shell command with retry and timeout logic.\n\n    Args:\n        command (str): The shell command to execute.\n        max_retries (int): The maximum number of retry attempts.\n        timeout (int): The timeout for each command execution in seconds.\n\n    Returns:\n        Optional[str]: The standard output of the command if successful, None otherwise.\n\n    Raises:\n        subprocess.CalledProcessError: If the command fails after maximum retries.\n        subprocess.TimeoutExpired: If the command times out after maximum retries.\n    \"\"\"\n    for attempt in range(max_retries):\n        try:\n            # Run the command with the specified timeout and check for errors\n            result = subprocess.run(command, shell=True, timeout=timeout, check=True, text=True, capture_output=True)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            print(f'Attempt {attempt + 1} failed: {e}')\n            # If it's the last attempt, raise the error\n            if attempt == max_retries - 1:\n                raise\n            # Wait before retrying\n            time.sleep(1)\n        except subprocess.TimeoutExpired:\n            print(f'Attempt {attempt + 1} timed out')\n            # If it's the last attempt, raise the timeout error\n            if attempt == max_retries - 1:\n                raise\n\n# Example command to backup a directory\ncommand = 'tar -czf backup.tar.gz /path/to/directory'\n# Execute the command with retries\nexecute_command_with_retries(command, 3, 5)",
    "rejected_code": "import subprocess\nimport time\n\ndef execute_command_with_retries(command, max_retries, timeout):\n    for attempt in range(max_retries):\n        try:\n            result = subprocess.run(command, shell=True, timeout=timeout, check=True)\n            return result.stdout\n        except subprocess.CalledProcessError as e:\n            print(f'Attempt {attempt + 1} failed: {e}')\n            if attempt == max_retries - 1:\n                raise\n            time.sleep(1)\n        except subprocess.TimeoutExpired:\n            print(f'Attempt {attempt + 1} timed out')\n            if attempt == max_retries - 1:\n                raise\n\ncommand = 'tar -czf backup.tar.gz /path/to/directory'\nexecute_command_with_retries(command, 3, 5)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.13953488372093023,
      "execution_result": {
        "success": false,
        "output": "Attempt 1 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 2 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 3 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 43, in <module>\n  File \"<string>\", line 25, in execute_command_with_retries\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1."
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 6.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "Attempt 1 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 2 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.\nAttempt 3 failed: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1.",
        "error": "tar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\ntar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\ntar: /path/to/directory: Cannot stat: No such file or directory\ntar: Error exit delayed from previous errors.\nTraceback (most recent call last):\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 7, in execute_command_with_retries\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/subprocess.py\", line 571, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command 'tar -czf backup.tar.gz /path/to/directory' returned non-zero exit status 1."
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Build a task scheduling class with dependency resolution",
    "code_form": "scheduler class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide a Python code example for a task scheduling class with dependency resolution.",
      "role": "user"
    },
    "chosen_code": "import asyncio\nfrom typing import List, Set, Optional\n\nclass Task:\n    \"\"\"\n    Represents a task with a name and optional dependencies.\n    \"\"\"\n    def __init__(self, name: str, dependencies: Optional[List['Task']] = None) -> None:\n        self.name = name\n        self.dependencies = dependencies if dependencies else []\n\nclass Scheduler:\n    \"\"\"\n    Manages the scheduling of tasks while resolving dependencies.\n    \"\"\"\n    def __init__(self) -> None:\n        self.tasks: List[Task] = []\n\n    def add_task(self, task: Task) -> None:\n        \"\"\"\n        Adds a task to the scheduler.\n        \"\"\"\n        self.tasks.append(task)\n\n    def resolve_dependencies(self, task: Task, resolved: Set[Task], stack: Set[Task]) -> None:\n        \"\"\"\n        Recursively resolves task dependencies to detect circular dependencies.\n        Raises an exception if a circular dependency is detected.\n        \"\"\"\n        if task in stack:\n            raise Exception('Circular dependency detected')\n        if task not in resolved:\n            stack.add(task)\n            for dep in task.dependencies:\n                self.resolve_dependencies(dep, resolved, stack)\n            resolved.add(task)\n            stack.remove(task)\n\n    def schedule(self) -> List[Task]:\n        \"\"\"\n        Returns a list of tasks in the order they should be executed.\n        \"\"\"\n        resolved: Set[Task] = set()\n        for task in self.tasks:\n            self.resolve_dependencies(task, resolved, set())\n        return list(resolved)\n\n    async def run_task(self, task: Task) -> None:\n        \"\"\"\n        Simulates running a task by printing its name and waiting.\n        \"\"\"\n        print(f'Running task {task.name}')\n        await asyncio.sleep(1)\n\n    async def run(self) -> None:\n        \"\"\"\n        Executes the tasks in the resolved order.\n        \"\"\"\n        for task in self.schedule():\n            await self.run_task(task)\n\n# Example usage\nappA = Task('appA')\nappB = Task('appB', dependencies=[appA])\nappC = Task('appC', dependencies=[appB])\n\nscheduler = Scheduler()\nscheduler.add_task(appA)\nscheduler.add_task(appB)\nscheduler.add_task(appC)\n\nasyncio.run(scheduler.run())",
    "rejected_code": "import asyncio\n\nclass Task:\n    def __init__(self, name, dependencies=None):\n        self.name = name\n        self.dependencies = dependencies if dependencies else []\n\nclass Scheduler:\n    def __init__(self):\n        self.tasks = []\n\n    def add_task(self, task):\n        self.tasks.append(task)\n\n    def resolve_dependencies(self, task, resolved, stack):\n        if task in stack:\n            raise Exception('Circular dependency detected')\n        if task not in resolved:\n            stack.add(task)\n            for dep in task.dependencies:\n                self.resolve_dependencies(dep, resolved, stack)\n            resolved.add(task)\n            stack.remove(task)\n\n    def schedule(self):\n        resolved = set()\n        for task in self.tasks:\n            self.resolve_dependencies(task, resolved, set())\n        return list(resolved)\n\n    async def run_task(self, task):\n        print(f'Running task {task.name}')\n        await asyncio.sleep(1)\n\n    async def run(self):\n        for task in self.schedule():\n            await self.run_task(task)\n\nappA = Task('appA')\nappB = Task('appB', dependencies=[appA])\nappC = Task('appC', dependencies=[appB])\n\nscheduler = Scheduler()\nscheduler.add_task(appA)\nscheduler.add_task(appB)\nscheduler.add_task(appC)\n\nasyncio.run(scheduler.run())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.6,
      "code_complexity": 2.111111111111111,
      "pep8_compliance": null,
      "comment_density": 0.013888888888888888,
      "execution_result": {
        "success": true,
        "output": "Running task appA\nRunning task appB\nRunning task appC",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.111111111111111,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Running task appB\nRunning task appC\nRunning task appA",
        "error": ""
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Build a task scheduling class with dependency resolution",
    "code_form": "scheduler class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a Python class to implement a task scheduling system with dependency resolution?",
      "role": "user"
    },
    "chosen_code": "import asyncio\nfrom typing import List, Set, Optional\n\nclass Task:\n    \"\"\"\n    Represents a task with a name and optional dependencies.\n    \"\"\"\n    def __init__(self, name: str, dependencies: Optional[List['Task']] = None) -> None:\n        self.name = name\n        self.dependencies = dependencies if dependencies else []\n\nclass Scheduler:\n    \"\"\"\n    Manages the scheduling of tasks while resolving dependencies.\n    \"\"\"\n    def __init__(self) -> None:\n        self.tasks: List[Task] = []\n\n    def add_task(self, task: Task) -> None:\n        \"\"\"\n        Adds a task to the scheduler.\n        \"\"\"\n        self.tasks.append(task)\n\n    def resolve_dependencies(self, task: Task, resolved: Set[Task], stack: Set[Task]) -> None:\n        \"\"\"\n        Recursively resolves task dependencies to detect circular dependencies.\n        Raises an exception if a circular dependency is detected.\n        \"\"\"\n        if task in stack:\n            raise Exception('Circular dependency detected')\n        if task not in resolved:\n            stack.add(task)\n            for dep in task.dependencies:\n                self.resolve_dependencies(dep, resolved, stack)\n            resolved.add(task)\n            stack.remove(task)\n\n    def schedule(self) -> List[Task]:\n        \"\"\"\n        Returns a list of tasks in the order they should be executed.\n        \"\"\"\n        resolved: Set[Task] = set()\n        for task in self.tasks:\n            self.resolve_dependencies(task, resolved, set())\n        return list(resolved)\n\n    async def run_task(self, task: Task) -> None:\n        \"\"\"\n        Simulates running a task by printing its name and waiting.\n        \"\"\"\n        print(f'Running task {task.name}')\n        await asyncio.sleep(1)\n\n    async def run(self) -> None:\n        \"\"\"\n        Executes the tasks in the resolved order.\n        \"\"\"\n        for task in self.schedule():\n            await self.run_task(task)\n\n# Example usage\nappA = Task('appA')\nappB = Task('appB', dependencies=[appA])\nappC = Task('appC', dependencies=[appB])\n\nscheduler = Scheduler()\nscheduler.add_task(appA)\nscheduler.add_task(appB)\nscheduler.add_task(appC)\n\nasyncio.run(scheduler.run())",
    "rejected_code": "import asyncio\n\nclass Task:\n    def __init__(self, name, dependencies=None):\n        self.name = name\n        self.dependencies = dependencies if dependencies else []\n\nclass Scheduler:\n    def __init__(self):\n        self.tasks = []\n\n    def add_task(self, task):\n        self.tasks.append(task)\n\n    def resolve_dependencies(self, task, resolved, stack):\n        if task in stack:\n            raise Exception('Circular dependency detected')\n        if task not in resolved:\n            stack.add(task)\n            for dep in task.dependencies:\n                self.resolve_dependencies(dep, resolved, stack)\n            resolved.add(task)\n            stack.remove(task)\n\n    def schedule(self):\n        resolved = set()\n        for task in self.tasks:\n            self.resolve_dependencies(task, resolved, set())\n        return list(resolved)\n\n    async def run_task(self, task):\n        print(f'Running task {task.name}')\n        await asyncio.sleep(1)\n\n    async def run(self):\n        for task in self.schedule():\n            await self.run_task(task)\n\nappA = Task('appA')\nappB = Task('appB', dependencies=[appA])\nappC = Task('appC', dependencies=[appB])\n\nscheduler = Scheduler()\nscheduler.add_task(appA)\nscheduler.add_task(appB)\nscheduler.add_task(appC)\n\nasyncio.run(scheduler.run())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.6,
      "code_complexity": 2.111111111111111,
      "pep8_compliance": null,
      "comment_density": 0.013888888888888888,
      "execution_result": {
        "success": true,
        "output": "Running task appA\nRunning task appC\nRunning task appB",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.111111111111111,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Running task appB\nRunning task appC\nRunning task appA",
        "error": ""
      }
    }
  },
  {
    "domain": "automation and system",
    "task": "Build a task scheduling class with dependency resolution",
    "code_form": "scheduler class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python class that implements a task scheduling system with dependency resolution, ensuring to include type annotations for inputs and outputs.",
      "role": "user"
    },
    "chosen_code": "import asyncio\nfrom typing import List, Set, Optional\n\nclass Task:\n    \"\"\"\n    Represents a task with a name and optional dependencies.\n    \"\"\"\n    def __init__(self, name: str, dependencies: Optional[List['Task']] = None) -> None:\n        self.name = name\n        self.dependencies = dependencies if dependencies else []\n\nclass Scheduler:\n    \"\"\"\n    Manages the scheduling of tasks while resolving dependencies.\n    \"\"\"\n    def __init__(self) -> None:\n        self.tasks: List[Task] = []\n\n    def add_task(self, task: Task) -> None:\n        \"\"\"\n        Adds a task to the scheduler.\n        \"\"\"\n        self.tasks.append(task)\n\n    def resolve_dependencies(self, task: Task, resolved: Set[Task], stack: Set[Task]) -> None:\n        \"\"\"\n        Recursively resolves task dependencies to detect circular dependencies.\n        Raises an exception if a circular dependency is detected.\n        \"\"\"\n        if task in stack:\n            raise Exception('Circular dependency detected')\n        if task not in resolved:\n            stack.add(task)\n            for dep in task.dependencies:\n                self.resolve_dependencies(dep, resolved, stack)\n            resolved.add(task)\n            stack.remove(task)\n\n    def schedule(self) -> List[Task]:\n        \"\"\"\n        Returns a list of tasks in the order they should be executed.\n        \"\"\"\n        resolved: Set[Task] = set()\n        for task in self.tasks:\n            self.resolve_dependencies(task, resolved, set())\n        return list(resolved)\n\n    async def run_task(self, task: Task) -> None:\n        \"\"\"\n        Simulates running a task by printing its name and waiting.\n        \"\"\"\n        print(f'Running task {task.name}')\n        await asyncio.sleep(1)\n\n    async def run(self) -> None:\n        \"\"\"\n        Executes the tasks in the resolved order.\n        \"\"\"\n        for task in self.schedule():\n            await self.run_task(task)\n\n# Example usage\nappA = Task('appA')\nappB = Task('appB', dependencies=[appA])\nappC = Task('appC', dependencies=[appB])\n\nscheduler = Scheduler()\nscheduler.add_task(appA)\nscheduler.add_task(appB)\nscheduler.add_task(appC)\n\nasyncio.run(scheduler.run())",
    "rejected_code": "import asyncio\n\nclass Task:\n    def __init__(self, name, dependencies=None):\n        self.name = name\n        self.dependencies = dependencies if dependencies else []\n\nclass Scheduler:\n    def __init__(self):\n        self.tasks = []\n\n    def add_task(self, task):\n        self.tasks.append(task)\n\n    def resolve_dependencies(self, task, resolved, stack):\n        if task in stack:\n            raise Exception('Circular dependency detected')\n        if task not in resolved:\n            stack.add(task)\n            for dep in task.dependencies:\n                self.resolve_dependencies(dep, resolved, stack)\n            resolved.add(task)\n            stack.remove(task)\n\n    def schedule(self):\n        resolved = set()\n        for task in self.tasks:\n            self.resolve_dependencies(task, resolved, set())\n        return list(resolved)\n\n    async def run_task(self, task):\n        print(f'Running task {task.name}')\n        await asyncio.sleep(1)\n\n    async def run(self):\n        for task in self.schedule():\n            await self.run_task(task)\n\nappA = Task('appA')\nappB = Task('appB', dependencies=[appA])\nappC = Task('appC', dependencies=[appB])\n\nscheduler = Scheduler()\nscheduler.add_task(appA)\nscheduler.add_task(appB)\nscheduler.add_task(appC)\n\nasyncio.run(scheduler.run())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 0.6,
      "code_complexity": 2.111111111111111,
      "pep8_compliance": null,
      "comment_density": 0.013888888888888888,
      "execution_result": {
        "success": true,
        "output": "Running task appA\nRunning task appC\nRunning task appB",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.111111111111111,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "Running task appB\nRunning task appC\nRunning task appA",
        "error": ""
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Implement a configuration validation function with custom rules",
    "code_form": "validator function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide code to validate a Docker configuration for a CI/CD pipeline?",
      "role": "user"
    },
    "chosen_code": "from typing import Dict, Tuple\n\n\ndef validate_docker_config(config: Dict[str, Dict[str, str]]) -> Tuple[bool, str]:\n    \"\"\"\n    Validate a Docker configuration for a CI/CD pipeline.\n\n    This function checks whether all required environment variables are set\n    and whether the Docker image name follows a specific naming convention.\n\n    Args:\n        config (Dict[str, Dict[str, str]]): A dictionary containing the Docker configuration,\n            with 'environment' being another dictionary containing environment variables\n            and 'image' as the Docker image name.\n\n    Returns:\n        Tuple[bool, str]: A tuple where the first element indicates whether the\n            configuration is valid (True) or not (False), and the second element\n            is a message indicating the result of the validation.\n    \"\"\"\n    required_env_vars = ['DB_HOST', 'DB_USER', 'DB_PASSWORD']\n\n    # Check for missing required environment variables\n    for var in required_env_vars:\n        if var not in config.get('environment', {}):\n            return False, f'Missing environment variable: {var}'\n\n    # Validate the image name format\n    if not config.get('image', '').startswith('myorg/'):\n        return False, 'Image name must start with myorg/'\n\n    return True, 'Configuration is valid'\n\n\n# Example usage\nif __name__ == '__main__':\n    config = {\n        'environment': {\n            'DB_HOST': 'localhost',\n            'DB_USER': 'user',\n            'DB_PASSWORD': 'pass'\n        },\n        'image': 'myorg/myapp:latest'\n    }\n\n    is_valid, message = validate_docker_config(config)\n    print(message)",
    "rejected_code": "def validate_docker_config(config):\n    required_env_vars = ['DB_HOST', 'DB_USER', 'DB_PASSWORD']\n    for var in required_env_vars:\n        if var not in config['environment']:\n            return False, f'Missing environment variable: {var}'\n    if not config['image'].startswith('myorg/'): \n        return False, 'Image name must start with myorg/'\n    return True, 'Configuration is valid'\n\n# Example usage\nconfig = {\n    'environment': {\n        'DB_HOST': 'localhost',\n        'DB_USER': 'user',\n        'DB_PASSWORD': 'pass'\n    },\n    'image': 'myorg/myapp:latest'\n}\n\nis_valid, message = validate_docker_config(config)\nprint(message)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.06382978723404255,
      "execution_result": {
        "success": true,
        "output": "Configuration is valid",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.047619047619047616,
      "execution_result": {
        "success": true,
        "output": "Configuration is valid",
        "error": ""
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Implement a configuration validation function with custom rules",
    "code_form": "validator function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a function to validate a Docker configuration for a CI/CD pipeline.",
      "role": "user"
    },
    "chosen_code": "from typing import Dict, Tuple\n\n\ndef validate_docker_config(config: Dict[str, Dict[str, str]]) -> Tuple[bool, str]:\n    \"\"\"\n    Validate a Docker configuration for a CI/CD pipeline.\n\n    This function checks whether all required environment variables are set\n    and whether the Docker image name follows a specific naming convention.\n\n    Args:\n        config (Dict[str, Dict[str, str]]): A dictionary containing the Docker configuration,\n            with 'environment' being another dictionary containing environment variables\n            and 'image' as the Docker image name.\n\n    Returns:\n        Tuple[bool, str]: A tuple where the first element indicates whether the\n            configuration is valid (True) or not (False), and the second element\n            is a message indicating the result of the validation.\n    \"\"\"\n    required_env_vars = ['DB_HOST', 'DB_USER', 'DB_PASSWORD']\n\n    # Check for missing required environment variables\n    for var in required_env_vars:\n        if var not in config.get('environment', {}):\n            return False, f'Missing environment variable: {var}'\n\n    # Validate the image name format\n    if not config.get('image', '').startswith('myorg/'):\n        return False, 'Image name must start with myorg/'\n\n    return True, 'Configuration is valid'\n\n\n# Example usage\nif __name__ == '__main__':\n    config = {\n        'environment': {\n            'DB_HOST': 'localhost',\n            'DB_USER': 'user',\n            'DB_PASSWORD': 'pass'\n        },\n        'image': 'myorg/myapp:latest'\n    }\n\n    is_valid, message = validate_docker_config(config)\n    print(message)",
    "rejected_code": "def validate_docker_config(config):\n    required_env_vars = ['DB_HOST', 'DB_USER', 'DB_PASSWORD']\n    for var in required_env_vars:\n        if var not in config['environment']:\n            return False, f'Missing environment variable: {var}'\n    if not config['image'].startswith('myorg/'): \n        return False, 'Image name must start with myorg/'\n    return True, 'Configuration is valid'\n\n# Example usage\nconfig = {\n    'environment': {\n        'DB_HOST': 'localhost',\n        'DB_USER': 'user',\n        'DB_PASSWORD': 'pass'\n    },\n    'image': 'myorg/myapp:latest'\n}\n\nis_valid, message = validate_docker_config(config)\nprint(message)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.06382978723404255,
      "execution_result": {
        "success": true,
        "output": "Configuration is valid",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.047619047619047616,
      "execution_result": {
        "success": true,
        "output": "Configuration is valid",
        "error": ""
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Implement a configuration validation function with custom rules",
    "code_form": "validator function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a function that takes a dictionary as input and returns a tuple indicating whether a Docker configuration is valid, along with a message.",
      "role": "user"
    },
    "chosen_code": "from typing import Dict, Tuple\n\n\ndef validate_docker_config(config: Dict[str, Dict[str, str]]) -> Tuple[bool, str]:\n    \"\"\"\n    Validate a Docker configuration for a CI/CD pipeline.\n\n    This function checks whether all required environment variables are set\n    and whether the Docker image name follows a specific naming convention.\n\n    Args:\n        config (Dict[str, Dict[str, str]]): A dictionary containing the Docker configuration,\n            with 'environment' being another dictionary containing environment variables\n            and 'image' as the Docker image name.\n\n    Returns:\n        Tuple[bool, str]: A tuple where the first element indicates whether the\n            configuration is valid (True) or not (False), and the second element\n            is a message indicating the result of the validation.\n    \"\"\"\n    required_env_vars = ['DB_HOST', 'DB_USER', 'DB_PASSWORD']\n\n    # Check for missing required environment variables\n    for var in required_env_vars:\n        if var not in config.get('environment', {}):\n            return False, f'Missing environment variable: {var}'\n\n    # Validate the image name format\n    if not config.get('image', '').startswith('myorg/'):\n        return False, 'Image name must start with myorg/'\n\n    return True, 'Configuration is valid'\n\n\n# Example usage\nif __name__ == '__main__':\n    config = {\n        'environment': {\n            'DB_HOST': 'localhost',\n            'DB_USER': 'user',\n            'DB_PASSWORD': 'pass'\n        },\n        'image': 'myorg/myapp:latest'\n    }\n\n    is_valid, message = validate_docker_config(config)\n    print(message)",
    "rejected_code": "def validate_docker_config(config):\n    required_env_vars = ['DB_HOST', 'DB_USER', 'DB_PASSWORD']\n    for var in required_env_vars:\n        if var not in config['environment']:\n            return False, f'Missing environment variable: {var}'\n    if not config['image'].startswith('myorg/'): \n        return False, 'Image name must start with myorg/'\n    return True, 'Configuration is valid'\n\n# Example usage\nconfig = {\n    'environment': {\n        'DB_HOST': 'localhost',\n        'DB_USER': 'user',\n        'DB_PASSWORD': 'pass'\n    },\n    'image': 'myorg/myapp:latest'\n}\n\nis_valid, message = validate_docker_config(config)\nprint(message)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.06382978723404255,
      "execution_result": {
        "success": true,
        "output": "Configuration is valid",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 4.0,
      "pep8_compliance": null,
      "comment_density": 0.047619047619047616,
      "execution_result": {
        "success": true,
        "output": "Configuration is valid",
        "error": ""
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Develop an infrastructure-as-code testing function",
    "code_form": "tester function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to develop an infrastructure-as-code testing function.",
      "role": "user"
    },
    "chosen_code": "import docker\nimport pytest\nfrom docker.models.containers import Container\nfrom docker import DockerClient\n\n\ndef test_docker_container() -> None:\n    \"\"\"\n    Tests the deployment of a Docker container to ensure it is running\n    and healthy.\n\n    This function uses the Docker SDK for Python to run a container\n    based on the 'myapp:latest' image, checks its status and health,\n    and cleans up the container afterward.\n    \"\"\"\n    client: DockerClient = docker.from_env()\n    container: Container = client.containers.run('myapp:latest', detach=True)\n    try:\n        # Reload the container information to get the latest status\n        container.reload()\n        # Assert that the container is running\n        assert container.status == 'running', \"Container is not running\"\n        # Inspect the container's health status\n        response = client.api.inspect_container(container.id)\n        assert response['State']['Health']['Status'] == 'healthy', \"Container is not healthy\"\n    finally:\n        # Stop and remove the container to clean up resources\n        container.stop()\n        container.remove(force=True)\n",
    "rejected_code": "import docker\nimport pytest\n\ndef test_docker_container():\n    client = docker.from_env()\n    container = client.containers.run('myapp:latest', detach=True)\n    try:\n        container.reload()\n        assert container.status == 'running'\n        response = client.api.inspect_container(container.id)\n        assert response['State']['Health']['Status'] == 'healthy'\n    finally:\n        container.stop()\n        container.remove()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.13793103448275862,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'docker'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'docker'"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Develop an infrastructure-as-code testing function",
    "code_form": "tester function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a Python function to develop an infrastructure-as-code testing function?",
      "role": "user"
    },
    "chosen_code": "import docker\nimport pytest\nfrom docker.models.containers import Container\nfrom docker import DockerClient\n\n\ndef test_docker_container() -> None:\n    \"\"\"\n    Tests the deployment of a Docker container to ensure it is running\n    and healthy.\n\n    This function uses the Docker SDK for Python to run a container\n    based on the 'myapp:latest' image, checks its status and health,\n    and cleans up the container afterward.\n    \"\"\"\n    client: DockerClient = docker.from_env()\n    container: Container = client.containers.run('myapp:latest', detach=True)\n    try:\n        # Reload the container information to get the latest status\n        container.reload()\n        # Assert that the container is running\n        assert container.status == 'running', \"Container is not running\"\n        # Inspect the container's health status\n        response = client.api.inspect_container(container.id)\n        assert response['State']['Health']['Status'] == 'healthy', \"Container is not healthy\"\n    finally:\n        # Stop and remove the container to clean up resources\n        container.stop()\n        container.remove(force=True)\n",
    "rejected_code": "import docker\nimport pytest\n\ndef test_docker_container():\n    client = docker.from_env()\n    container = client.containers.run('myapp:latest', detach=True)\n    try:\n        container.reload()\n        assert container.status == 'running'\n        response = client.api.inspect_container(container.id)\n        assert response['State']['Health']['Status'] == 'healthy'\n    finally:\n        container.stop()\n        container.remove()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.13793103448275862,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'docker'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'docker'"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Develop an infrastructure-as-code testing function",
    "code_form": "tester function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please write a Python function that implements an infrastructure-as-code testing function, specifying input types and output types.",
      "role": "user"
    },
    "chosen_code": "import docker\nimport pytest\nfrom docker.models.containers import Container\nfrom docker import DockerClient\n\n\ndef test_docker_container() -> None:\n    \"\"\"\n    Tests the deployment of a Docker container to ensure it is running\n    and healthy.\n\n    This function uses the Docker SDK for Python to run a container\n    based on the 'myapp:latest' image, checks its status and health,\n    and cleans up the container afterward.\n    \"\"\"\n    client: DockerClient = docker.from_env()\n    container: Container = client.containers.run('myapp:latest', detach=True)\n    try:\n        # Reload the container information to get the latest status\n        container.reload()\n        # Assert that the container is running\n        assert container.status == 'running', \"Container is not running\"\n        # Inspect the container's health status\n        response = client.api.inspect_container(container.id)\n        assert response['State']['Health']['Status'] == 'healthy', \"Container is not healthy\"\n    finally:\n        # Stop and remove the container to clean up resources\n        container.stop()\n        container.remove(force=True)\n",
    "rejected_code": "import docker\nimport pytest\n\ndef test_docker_container():\n    client = docker.from_env()\n    container = client.containers.run('myapp:latest', detach=True)\n    try:\n        container.reload()\n        assert container.status == 'running'\n        response = client.api.inspect_container(container.id)\n        assert response['State']['Health']['Status'] == 'healthy'\n    finally:\n        container.stop()\n        container.remove()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.13793103448275862,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'docker'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'docker'"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Build a deployment verification system with health checks",
    "code_form": "verifier class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide code for a deployment verification system that checks the health of a web application?",
      "role": "user"
    },
    "chosen_code": "import requests\nimport time\nfrom typing import Optional\n\nclass DeploymentVerifier:\n    \"\"\"\n    A class to verify the deployment of a web application by performing health checks.\n\n    Attributes:\n        url (str): The URL of the health check endpoint.\n    \"\"\"\n\n    def __init__(self, url: str) -> None:\n        \"\"\"\n        Initializes the DeploymentVerifier with the specified health check URL.\n\n        Args:\n            url (str): The URL to check for application health.\n        \"\"\"\n        self.url = url\n\n    def health_check(self) -> bool:\n        \"\"\"\n        Performs a health check by sending a GET request to the URL.\n\n        Returns:\n            bool: True if the application is healthy (HTTP 200), False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(self.url)\n            return response.status_code == 200\n        except requests.exceptions.RequestException:\n            return False\n\n    def verify_deployment(self, retries: int = 5, delay: int = 2) -> None:\n        \"\"\"\n        Verifies the deployment by performing health checks up to a specified number of retries.\n\n        Args:\n            retries (int): Number of times to check the health of the application (default is 5).\n            delay (int): Delay in seconds between health checks (default is 2).\n        \"\"\"\n        for attempt in range(retries):\n            if self.health_check():\n                print('Deployment verified: Application is healthy.')\n                return\n            time.sleep(delay)\n        print('Deployment verification failed: Application is not healthy.')\n\nif __name__ == '__main__':\n    verifier = DeploymentVerifier('http://localhost:8080/health')\n    verifier.verify_deployment()",
    "rejected_code": "import requests\nimport time\n\nclass DeploymentVerifier:\n    def __init__(self, url):\n        self.url = url\n\n    def health_check(self):\n        try:\n            response = requests.get(self.url)\n            return response.status_code == 200\n        except requests.exceptions.RequestException:\n            return False\n\n    def verify_deployment(self):\n        for _ in range(5):\n            if self.health_check():\n                print('Deployment verified: Application is healthy.')\n                return\n            time.sleep(2)\n        print('Deployment verification failed: Application is not healthy.')\n\nverifier = DeploymentVerifier('http://localhost:8080/health')\nverifier.verify_deployment()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', 'import requests\\nimport time\\nfrom typing import Optional\\n\\nclass DeploymentVerifier:\\n    \"\"\"\\n    A class to verify the deployment of a web application by performing health checks.\\n\\n    Attributes:\\n        url (str): The URL of the health check endpoint.\\n    \"\"\"\\n\\n    def __init__(self, url: str) -> None:\\n        \"\"\"\\n        Initializes the DeploymentVerifier with the specified health check URL.\\n\\n        Args:\\n            url (str): The URL to check for application health.\\n        \"\"\"\\n        self.url = url\\n\\n    def health_check(self) -> bool:\\n        \"\"\"\\n        Performs a health check by sending a GET request to the URL.\\n\\n        Returns:\\n            bool: True if the application is healthy (HTTP 200), False otherwise.\\n        \"\"\"\\n        try:\\n            response = requests.get(self.url)\\n            return response.status_code == 200\\n        except requests.exceptions.RequestException:\\n            return False\\n\\n    def verify_deployment(self, retries: int = 5, delay: int = 2) -> None:\\n        \"\"\"\\n        Verifies the deployment by performing health checks up to a specified number of retries.\\n\\n        Args:\\n            retries (int): Number of times to check the health of the application (default is 5).\\n            delay (int): Delay in seconds between health checks (default is 2).\\n        \"\"\"\\n        for attempt in range(retries):\\n            if self.health_check():\\n                print(\\'Deployment verified: Application is healthy.\\')\\n                return\\n            time.sleep(delay)\\n        print(\\'Deployment verification failed: Application is not healthy.\\')\\n\\nif __name__ == \\'__main__\\':\\n    verifier = DeploymentVerifier(\\'http://localhost:8080/health\\')\\n    verifier.verify_deployment()\\n\\n']' timed out after 10 seconds"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"import requests\\nimport time\\n\\nclass DeploymentVerifier:\\n    def __init__(self, url):\\n        self.url = url\\n\\n    def health_check(self):\\n        try:\\n            response = requests.get(self.url)\\n            return response.status_code == 200\\n        except requests.exceptions.RequestException:\\n            return False\\n\\n    def verify_deployment(self):\\n        for _ in range(5):\\n            if self.health_check():\\n                print('Deployment verified: Application is healthy.')\\n                return\\n            time.sleep(2)\\n        print('Deployment verification failed: Application is not healthy.')\\n\\nverifier = DeploymentVerifier('http://localhost:8080/health')\\nverifier.verify_deployment()\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Build a deployment verification system with health checks",
    "code_form": "verifier class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class that implements a deployment verification system with health checks for a web application.",
      "role": "user"
    },
    "chosen_code": "import requests\nimport time\nfrom typing import Optional\n\nclass DeploymentVerifier:\n    \"\"\"\n    A class to verify the deployment of a web application by performing health checks.\n\n    Attributes:\n        url (str): The URL of the health check endpoint.\n    \"\"\"\n\n    def __init__(self, url: str) -> None:\n        \"\"\"\n        Initializes the DeploymentVerifier with the specified health check URL.\n\n        Args:\n            url (str): The URL to check for application health.\n        \"\"\"\n        self.url = url\n\n    def health_check(self) -> bool:\n        \"\"\"\n        Performs a health check by sending a GET request to the URL.\n\n        Returns:\n            bool: True if the application is healthy (HTTP 200), False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(self.url)\n            return response.status_code == 200\n        except requests.exceptions.RequestException:\n            return False\n\n    def verify_deployment(self, retries: int = 5, delay: int = 2) -> None:\n        \"\"\"\n        Verifies the deployment by performing health checks up to a specified number of retries.\n\n        Args:\n            retries (int): Number of times to check the health of the application (default is 5).\n            delay (int): Delay in seconds between health checks (default is 2).\n        \"\"\"\n        for attempt in range(retries):\n            if self.health_check():\n                print('Deployment verified: Application is healthy.')\n                return\n            time.sleep(delay)\n        print('Deployment verification failed: Application is not healthy.')\n\nif __name__ == '__main__':\n    verifier = DeploymentVerifier('http://localhost:8080/health')\n    verifier.verify_deployment()",
    "rejected_code": "import requests\nimport time\n\nclass DeploymentVerifier:\n    def __init__(self, url):\n        self.url = url\n\n    def health_check(self):\n        try:\n            response = requests.get(self.url)\n            return response.status_code == 200\n        except requests.exceptions.RequestException:\n            return False\n\n    def verify_deployment(self):\n        for _ in range(5):\n            if self.health_check():\n                print('Deployment verified: Application is healthy.')\n                return\n            time.sleep(2)\n        print('Deployment verification failed: Application is not healthy.')\n\nverifier = DeploymentVerifier('http://localhost:8080/health')\nverifier.verify_deployment()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', 'import requests\\nimport time\\nfrom typing import Optional\\n\\nclass DeploymentVerifier:\\n    \"\"\"\\n    A class to verify the deployment of a web application by performing health checks.\\n\\n    Attributes:\\n        url (str): The URL of the health check endpoint.\\n    \"\"\"\\n\\n    def __init__(self, url: str) -> None:\\n        \"\"\"\\n        Initializes the DeploymentVerifier with the specified health check URL.\\n\\n        Args:\\n            url (str): The URL to check for application health.\\n        \"\"\"\\n        self.url = url\\n\\n    def health_check(self) -> bool:\\n        \"\"\"\\n        Performs a health check by sending a GET request to the URL.\\n\\n        Returns:\\n            bool: True if the application is healthy (HTTP 200), False otherwise.\\n        \"\"\"\\n        try:\\n            response = requests.get(self.url)\\n            return response.status_code == 200\\n        except requests.exceptions.RequestException:\\n            return False\\n\\n    def verify_deployment(self, retries: int = 5, delay: int = 2) -> None:\\n        \"\"\"\\n        Verifies the deployment by performing health checks up to a specified number of retries.\\n\\n        Args:\\n            retries (int): Number of times to check the health of the application (default is 5).\\n            delay (int): Delay in seconds between health checks (default is 2).\\n        \"\"\"\\n        for attempt in range(retries):\\n            if self.health_check():\\n                print(\\'Deployment verified: Application is healthy.\\')\\n                return\\n            time.sleep(delay)\\n        print(\\'Deployment verification failed: Application is not healthy.\\')\\n\\nif __name__ == \\'__main__\\':\\n    verifier = DeploymentVerifier(\\'http://localhost:8080/health\\')\\n    verifier.verify_deployment()\\n\\n']' timed out after 10 seconds"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"import requests\\nimport time\\n\\nclass DeploymentVerifier:\\n    def __init__(self, url):\\n        self.url = url\\n\\n    def health_check(self):\\n        try:\\n            response = requests.get(self.url)\\n            return response.status_code == 200\\n        except requests.exceptions.RequestException:\\n            return False\\n\\n    def verify_deployment(self):\\n        for _ in range(5):\\n            if self.health_check():\\n                print('Deployment verified: Application is healthy.')\\n                return\\n            time.sleep(2)\\n        print('Deployment verification failed: Application is not healthy.')\\n\\nverifier = DeploymentVerifier('http://localhost:8080/health')\\nverifier.verify_deployment()\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Build a deployment verification system with health checks",
    "code_form": "verifier class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a class with methods that checks the health of a web application and returns appropriate results, using specific input/output types.",
      "role": "user"
    },
    "chosen_code": "import requests\nimport time\nfrom typing import Optional\n\nclass DeploymentVerifier:\n    \"\"\"\n    A class to verify the deployment of a web application by performing health checks.\n\n    Attributes:\n        url (str): The URL of the health check endpoint.\n    \"\"\"\n\n    def __init__(self, url: str) -> None:\n        \"\"\"\n        Initializes the DeploymentVerifier with the specified health check URL.\n\n        Args:\n            url (str): The URL to check for application health.\n        \"\"\"\n        self.url = url\n\n    def health_check(self) -> bool:\n        \"\"\"\n        Performs a health check by sending a GET request to the URL.\n\n        Returns:\n            bool: True if the application is healthy (HTTP 200), False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(self.url)\n            return response.status_code == 200\n        except requests.exceptions.RequestException:\n            return False\n\n    def verify_deployment(self, retries: int = 5, delay: int = 2) -> None:\n        \"\"\"\n        Verifies the deployment by performing health checks up to a specified number of retries.\n\n        Args:\n            retries (int): Number of times to check the health of the application (default is 5).\n            delay (int): Delay in seconds between health checks (default is 2).\n        \"\"\"\n        for attempt in range(retries):\n            if self.health_check():\n                print('Deployment verified: Application is healthy.')\n                return\n            time.sleep(delay)\n        print('Deployment verification failed: Application is not healthy.')\n\nif __name__ == '__main__':\n    verifier = DeploymentVerifier('http://localhost:8080/health')\n    verifier.verify_deployment()",
    "rejected_code": "import requests\nimport time\n\nclass DeploymentVerifier:\n    def __init__(self, url):\n        self.url = url\n\n    def health_check(self):\n        try:\n            response = requests.get(self.url)\n            return response.status_code == 200\n        except requests.exceptions.RequestException:\n            return False\n\n    def verify_deployment(self):\n        for _ in range(5):\n            if self.health_check():\n                print('Deployment verified: Application is healthy.')\n                return\n            time.sleep(2)\n        print('Deployment verification failed: Application is not healthy.')\n\nverifier = DeploymentVerifier('http://localhost:8080/health')\nverifier.verify_deployment()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', 'import requests\\nimport time\\nfrom typing import Optional\\n\\nclass DeploymentVerifier:\\n    \"\"\"\\n    A class to verify the deployment of a web application by performing health checks.\\n\\n    Attributes:\\n        url (str): The URL of the health check endpoint.\\n    \"\"\"\\n\\n    def __init__(self, url: str) -> None:\\n        \"\"\"\\n        Initializes the DeploymentVerifier with the specified health check URL.\\n\\n        Args:\\n            url (str): The URL to check for application health.\\n        \"\"\"\\n        self.url = url\\n\\n    def health_check(self) -> bool:\\n        \"\"\"\\n        Performs a health check by sending a GET request to the URL.\\n\\n        Returns:\\n            bool: True if the application is healthy (HTTP 200), False otherwise.\\n        \"\"\"\\n        try:\\n            response = requests.get(self.url)\\n            return response.status_code == 200\\n        except requests.exceptions.RequestException:\\n            return False\\n\\n    def verify_deployment(self, retries: int = 5, delay: int = 2) -> None:\\n        \"\"\"\\n        Verifies the deployment by performing health checks up to a specified number of retries.\\n\\n        Args:\\n            retries (int): Number of times to check the health of the application (default is 5).\\n            delay (int): Delay in seconds between health checks (default is 2).\\n        \"\"\"\\n        for attempt in range(retries):\\n            if self.health_check():\\n                print(\\'Deployment verified: Application is healthy.\\')\\n                return\\n            time.sleep(delay)\\n        print(\\'Deployment verification failed: Application is not healthy.\\')\\n\\nif __name__ == \\'__main__\\':\\n    verifier = DeploymentVerifier(\\'http://localhost:8080/health\\')\\n    verifier.verify_deployment()\\n\\n']' timed out after 10 seconds"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Command '['python', '-c', \"import requests\\nimport time\\n\\nclass DeploymentVerifier:\\n    def __init__(self, url):\\n        self.url = url\\n\\n    def health_check(self):\\n        try:\\n            response = requests.get(self.url)\\n            return response.status_code == 200\\n        except requests.exceptions.RequestException:\\n            return False\\n\\n    def verify_deployment(self):\\n        for _ in range(5):\\n            if self.health_check():\\n                print('Deployment verified: Application is healthy.')\\n                return\\n            time.sleep(2)\\n        print('Deployment verification failed: Application is not healthy.')\\n\\nverifier = DeploymentVerifier('http://localhost:8080/health')\\nverifier.verify_deployment()\\n\\n\"]' timed out after 10 seconds"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Create a metrics collection class with alerting thresholds",
    "code_form": "collector class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create a metrics collection class with alerting thresholds for monitoring build success rates in a CI/CD pipeline?",
      "role": "user"
    },
    "chosen_code": "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\nfrom typing import Union\n\nclass MetricsCollector:\n    \"\"\"\n    A class to collect and monitor build metrics in a CI/CD pipeline.\n    It tracks the number of successful and failed builds, calculates the success rate,\n    and triggers alerts if the success rate falls below a specified threshold.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the metrics collector with a registry and metrics gauges.\n        \"\"\"\n        self.registry: CollectorRegistry = CollectorRegistry()\n        self.success_count: Gauge = Gauge('build_success_count', 'Number of successful builds', registry=self.registry)\n        self.failure_count: Gauge = Gauge('build_failure_count', 'Number of failed builds', registry=self.registry)\n\n    def record_success(self) -> None:\n        \"\"\"\n        Records a successful build and checks for alerts.\n        \"\"\"\n        self.success_count.inc()  # Increment the success count\n        self.check_alerts()  # Check if alerts need to be triggered\n\n    def record_failure(self) -> None:\n        \"\"\"\n        Records a failed build and checks for alerts.\n        \"\"\"\n        self.failure_count.inc()  # Increment the failure count\n        self.check_alerts()  # Check if alerts need to be triggered\n\n    def check_alerts(self) -> None:\n        \"\"\"\n        Checks the success rate and triggers an alert if it falls below the threshold.\n        \"\"\"\n        total: float = self.success_count._value.get() + self.failure_count._value.get()\n        if total > 0:\n            success_rate: float = self.success_count._value.get() / total\n            if success_rate < 0.8:\n                self.trigger_alert()  # Trigger alert if below threshold\n\n    def trigger_alert(self) -> None:\n        \"\"\"\n        Triggers an alert indicating that the build success rate is below the threshold.\n        \"\"\"\n        print('Alert: Build success rate below threshold!')\n\n    def push_metrics(self, gateway: str) -> None:\n        \"\"\"\n        Pushes the collected metrics to the specified Prometheus gateway.\n        \n        :param gateway: The address of the Prometheus push gateway.\n        \"\"\"\n        push_to_gateway(gateway, job='ci_build', registry=self.registry)\n\n# Example usage of the MetricsCollector class\nif __name__ == '__main__':\n    collector = MetricsCollector()\n    collector.record_success()  # Simulate a successful build\n    collector.record_failure()  # Simulate a failed build\n    collector.push_metrics('http://localhost:9091')  # Push metrics to the gateway",
    "rejected_code": "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\nclass MetricsCollector:\n    def __init__(self):\n        self.registry = CollectorRegistry()\n        self.success_count = Gauge('build_success_count', 'Number of successful builds', registry=self.registry)\n        self.failure_count = Gauge('build_failure_count', 'Number of failed builds', registry=self.registry)\n\n    def record_success(self):\n        self.success_count.inc()\n        self.check_alerts()\n\n    def record_failure(self):\n        self.failure_count.inc()\n        self.check_alerts()\n\n    def check_alerts(self):\n        total = self.success_count._value.get() + self.failure_count._value.get()\n        if total > 0:\n            success_rate = self.success_count._value.get() / total\n            if success_rate < 0.8:\n                self.trigger_alert()\n\n    def trigger_alert(self):\n        print('Alert: Build success rate below threshold!')\n\n    def push_metrics(self, gateway):\n        push_to_gateway(gateway, job='ci_build', registry=self.registry)\n\ncollector = MetricsCollector()\ncollector.record_success()\ncollector.record_failure()\ncollector.push_metrics('http://localhost:9091')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.016129032258064516,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'prometheus_client'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'prometheus_client'"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Create a metrics collection class with alerting thresholds",
    "code_form": "collector class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python class that implements a metrics collection system with alerting thresholds for CI/CD build success rates.",
      "role": "user"
    },
    "chosen_code": "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\nfrom typing import Union\n\nclass MetricsCollector:\n    \"\"\"\n    A class to collect and monitor build metrics in a CI/CD pipeline.\n    It tracks the number of successful and failed builds, calculates the success rate,\n    and triggers alerts if the success rate falls below a specified threshold.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the metrics collector with a registry and metrics gauges.\n        \"\"\"\n        self.registry: CollectorRegistry = CollectorRegistry()\n        self.success_count: Gauge = Gauge('build_success_count', 'Number of successful builds', registry=self.registry)\n        self.failure_count: Gauge = Gauge('build_failure_count', 'Number of failed builds', registry=self.registry)\n\n    def record_success(self) -> None:\n        \"\"\"\n        Records a successful build and checks for alerts.\n        \"\"\"\n        self.success_count.inc()  # Increment the success count\n        self.check_alerts()  # Check if alerts need to be triggered\n\n    def record_failure(self) -> None:\n        \"\"\"\n        Records a failed build and checks for alerts.\n        \"\"\"\n        self.failure_count.inc()  # Increment the failure count\n        self.check_alerts()  # Check if alerts need to be triggered\n\n    def check_alerts(self) -> None:\n        \"\"\"\n        Checks the success rate and triggers an alert if it falls below the threshold.\n        \"\"\"\n        total: float = self.success_count._value.get() + self.failure_count._value.get()\n        if total > 0:\n            success_rate: float = self.success_count._value.get() / total\n            if success_rate < 0.8:\n                self.trigger_alert()  # Trigger alert if below threshold\n\n    def trigger_alert(self) -> None:\n        \"\"\"\n        Triggers an alert indicating that the build success rate is below the threshold.\n        \"\"\"\n        print('Alert: Build success rate below threshold!')\n\n    def push_metrics(self, gateway: str) -> None:\n        \"\"\"\n        Pushes the collected metrics to the specified Prometheus gateway.\n        \n        :param gateway: The address of the Prometheus push gateway.\n        \"\"\"\n        push_to_gateway(gateway, job='ci_build', registry=self.registry)\n\n# Example usage of the MetricsCollector class\nif __name__ == '__main__':\n    collector = MetricsCollector()\n    collector.record_success()  # Simulate a successful build\n    collector.record_failure()  # Simulate a failed build\n    collector.push_metrics('http://localhost:9091')  # Push metrics to the gateway",
    "rejected_code": "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\nclass MetricsCollector:\n    def __init__(self):\n        self.registry = CollectorRegistry()\n        self.success_count = Gauge('build_success_count', 'Number of successful builds', registry=self.registry)\n        self.failure_count = Gauge('build_failure_count', 'Number of failed builds', registry=self.registry)\n\n    def record_success(self):\n        self.success_count.inc()\n        self.check_alerts()\n\n    def record_failure(self):\n        self.failure_count.inc()\n        self.check_alerts()\n\n    def check_alerts(self):\n        total = self.success_count._value.get() + self.failure_count._value.get()\n        if total > 0:\n            success_rate = self.success_count._value.get() / total\n            if success_rate < 0.8:\n                self.trigger_alert()\n\n    def trigger_alert(self):\n        print('Alert: Build success rate below threshold!')\n\n    def push_metrics(self, gateway):\n        push_to_gateway(gateway, job='ci_build', registry=self.registry)\n\ncollector = MetricsCollector()\ncollector.record_success()\ncollector.record_failure()\ncollector.push_metrics('http://localhost:9091')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.016129032258064516,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'prometheus_client'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'prometheus_client'"
      }
    }
  },
  {
    "domain": "devops and CI/CD",
    "task": "Create a metrics collection class with alerting thresholds",
    "code_form": "collector class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you write a Python class that collects metrics with specific input and output types, focusing on build success rates and alerting thresholds in a CI/CD pipeline?",
      "role": "user"
    },
    "chosen_code": "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\nfrom typing import Union\n\nclass MetricsCollector:\n    \"\"\"\n    A class to collect and monitor build metrics in a CI/CD pipeline.\n    It tracks the number of successful and failed builds, calculates the success rate,\n    and triggers alerts if the success rate falls below a specified threshold.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the metrics collector with a registry and metrics gauges.\n        \"\"\"\n        self.registry: CollectorRegistry = CollectorRegistry()\n        self.success_count: Gauge = Gauge('build_success_count', 'Number of successful builds', registry=self.registry)\n        self.failure_count: Gauge = Gauge('build_failure_count', 'Number of failed builds', registry=self.registry)\n\n    def record_success(self) -> None:\n        \"\"\"\n        Records a successful build and checks for alerts.\n        \"\"\"\n        self.success_count.inc()  # Increment the success count\n        self.check_alerts()  # Check if alerts need to be triggered\n\n    def record_failure(self) -> None:\n        \"\"\"\n        Records a failed build and checks for alerts.\n        \"\"\"\n        self.failure_count.inc()  # Increment the failure count\n        self.check_alerts()  # Check if alerts need to be triggered\n\n    def check_alerts(self) -> None:\n        \"\"\"\n        Checks the success rate and triggers an alert if it falls below the threshold.\n        \"\"\"\n        total: float = self.success_count._value.get() + self.failure_count._value.get()\n        if total > 0:\n            success_rate: float = self.success_count._value.get() / total\n            if success_rate < 0.8:\n                self.trigger_alert()  # Trigger alert if below threshold\n\n    def trigger_alert(self) -> None:\n        \"\"\"\n        Triggers an alert indicating that the build success rate is below the threshold.\n        \"\"\"\n        print('Alert: Build success rate below threshold!')\n\n    def push_metrics(self, gateway: str) -> None:\n        \"\"\"\n        Pushes the collected metrics to the specified Prometheus gateway.\n        \n        :param gateway: The address of the Prometheus push gateway.\n        \"\"\"\n        push_to_gateway(gateway, job='ci_build', registry=self.registry)\n\n# Example usage of the MetricsCollector class\nif __name__ == '__main__':\n    collector = MetricsCollector()\n    collector.record_success()  # Simulate a successful build\n    collector.record_failure()  # Simulate a failed build\n    collector.push_metrics('http://localhost:9091')  # Push metrics to the gateway",
    "rejected_code": "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\nclass MetricsCollector:\n    def __init__(self):\n        self.registry = CollectorRegistry()\n        self.success_count = Gauge('build_success_count', 'Number of successful builds', registry=self.registry)\n        self.failure_count = Gauge('build_failure_count', 'Number of failed builds', registry=self.registry)\n\n    def record_success(self):\n        self.success_count.inc()\n        self.check_alerts()\n\n    def record_failure(self):\n        self.failure_count.inc()\n        self.check_alerts()\n\n    def check_alerts(self):\n        total = self.success_count._value.get() + self.failure_count._value.get()\n        if total > 0:\n            success_rate = self.success_count._value.get() / total\n            if success_rate < 0.8:\n                self.trigger_alert()\n\n    def trigger_alert(self):\n        print('Alert: Build success rate below threshold!')\n\n    def push_metrics(self, gateway):\n        push_to_gateway(gateway, job='ci_build', registry=self.registry)\n\ncollector = MetricsCollector()\ncollector.record_success()\ncollector.record_failure()\ncollector.push_metrics('http://localhost:9091')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.016129032258064516,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'prometheus_client'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'prometheus_client'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Create a web crawler with politeness controls and rate limiting",
    "code_form": "crawler class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create a web crawler with politeness controls and rate limiting?",
      "role": "user"
    },
    "chosen_code": "import time\nimport requests\nfrom bs4 import BeautifulSoup\nfrom typing import Optional\n\nclass Crawler:\n    def __init__(self, base_url: str, delay: int = 2, max_requests: int = 10) -> None:\n        \"\"\"\n        Initializes the Crawler with the base URL, delay between requests, and maximum number of requests.\n\n        :param base_url: The URL of the website to scrape.\n        :param delay: Time in seconds to wait between requests (default is 2).\n        :param max_requests: Maximum number of requests to send (default is 10).\n        \"\"\"\n        self.base_url = base_url\n        self.delay = delay\n        self.max_requests = max_requests\n\n    def crawl(self) -> None:\n        \"\"\"\n        Starts the crawling process, making requests to the base URL and parsing the response.\n        \"\"\"\n        count = 0\n        while count < self.max_requests:\n            response = requests.get(self.base_url)\n            if response.status_code == 200:\n                self.parse(response.text)\n                count += 1\n                time.sleep(self.delay)\n            else:\n                print('Failed to retrieve:', self.base_url)\n                break\n\n    def parse(self, html: str) -> None:\n        \"\"\"\n        Parses the HTML content to extract book titles and prices.\n\n        :param html: The HTML content of the page to parse.\n        \"\"\"\n        soup = BeautifulSoup(html, 'html.parser')\n        books = soup.find_all('div', class_='book-item')\n        for book in books:\n            title: Optional[str] = book.find('h2').text\n            price: Optional[str] = book.find('span', class_='price').text\n            print(f'Title: {title}, Price: {price}')\n\nif __name__ == '__main__':\n    crawler = Crawler('http://example.com/books')\n    crawler.crawl()",
    "rejected_code": "import time\nimport requests\nfrom bs4 import BeautifulSoup\n\nclass Crawler:\n    def __init__(self, base_url, delay=2, max_requests=10):\n        self.base_url = base_url\n        self.delay = delay\n        self.max_requests = max_requests\n\n    def crawl(self):\n        count = 0\n        while count < self.max_requests:\n            response = requests.get(self.base_url)\n            if response.status_code == 200:\n                self.parse(response.text)\n                count += 1\n                time.sleep(self.delay)\n            else:\n                print('Failed to retrieve:', self.base_url)\n                break\n\n    def parse(self, html):\n        soup = BeautifulSoup(html, 'html.parser')\n        books = soup.find_all('div', class_='book-item')\n        for book in books:\n            title = book.find('h2').text\n            price = book.find('span', class_='price').text\n            print(f'Title: {title}, Price: {price}')  \n\ncrawler = Crawler('http://example.com/books')\ncrawler.crawl()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Create a web crawler with politeness controls and rate limiting",
    "code_form": "crawler class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a class-based implementation of a web crawler with politeness controls and rate limiting.",
      "role": "user"
    },
    "chosen_code": "import time\nimport requests\nfrom bs4 import BeautifulSoup\nfrom typing import Optional\n\nclass Crawler:\n    def __init__(self, base_url: str, delay: int = 2, max_requests: int = 10) -> None:\n        \"\"\"\n        Initializes the Crawler with the base URL, delay between requests, and maximum number of requests.\n\n        :param base_url: The URL of the website to scrape.\n        :param delay: Time in seconds to wait between requests (default is 2).\n        :param max_requests: Maximum number of requests to send (default is 10).\n        \"\"\"\n        self.base_url = base_url\n        self.delay = delay\n        self.max_requests = max_requests\n\n    def crawl(self) -> None:\n        \"\"\"\n        Starts the crawling process, making requests to the base URL and parsing the response.\n        \"\"\"\n        count = 0\n        while count < self.max_requests:\n            response = requests.get(self.base_url)\n            if response.status_code == 200:\n                self.parse(response.text)\n                count += 1\n                time.sleep(self.delay)\n            else:\n                print('Failed to retrieve:', self.base_url)\n                break\n\n    def parse(self, html: str) -> None:\n        \"\"\"\n        Parses the HTML content to extract book titles and prices.\n\n        :param html: The HTML content of the page to parse.\n        \"\"\"\n        soup = BeautifulSoup(html, 'html.parser')\n        books = soup.find_all('div', class_='book-item')\n        for book in books:\n            title: Optional[str] = book.find('h2').text\n            price: Optional[str] = book.find('span', class_='price').text\n            print(f'Title: {title}, Price: {price}')\n\nif __name__ == '__main__':\n    crawler = Crawler('http://example.com/books')\n    crawler.crawl()",
    "rejected_code": "import time\nimport requests\nfrom bs4 import BeautifulSoup\n\nclass Crawler:\n    def __init__(self, base_url, delay=2, max_requests=10):\n        self.base_url = base_url\n        self.delay = delay\n        self.max_requests = max_requests\n\n    def crawl(self):\n        count = 0\n        while count < self.max_requests:\n            response = requests.get(self.base_url)\n            if response.status_code == 200:\n                self.parse(response.text)\n                count += 1\n                time.sleep(self.delay)\n            else:\n                print('Failed to retrieve:', self.base_url)\n                break\n\n    def parse(self, html):\n        soup = BeautifulSoup(html, 'html.parser')\n        books = soup.find_all('div', class_='book-item')\n        for book in books:\n            title = book.find('h2').text\n            price = book.find('span', class_='price').text\n            print(f'Title: {title}, Price: {price}')  \n\ncrawler = Crawler('http://example.com/books')\ncrawler.crawl()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Create a web crawler with politeness controls and rate limiting",
    "code_form": "crawler class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a class in Python for a web crawler that implements politeness controls and rate limiting, specifying input types for the constructor and output types for the methods.",
      "role": "user"
    },
    "chosen_code": "import time\nimport requests\nfrom bs4 import BeautifulSoup\nfrom typing import Optional\n\nclass Crawler:\n    def __init__(self, base_url: str, delay: int = 2, max_requests: int = 10) -> None:\n        \"\"\"\n        Initializes the Crawler with the base URL, delay between requests, and maximum number of requests.\n\n        :param base_url: The URL of the website to scrape.\n        :param delay: Time in seconds to wait between requests (default is 2).\n        :param max_requests: Maximum number of requests to send (default is 10).\n        \"\"\"\n        self.base_url = base_url\n        self.delay = delay\n        self.max_requests = max_requests\n\n    def crawl(self) -> None:\n        \"\"\"\n        Starts the crawling process, making requests to the base URL and parsing the response.\n        \"\"\"\n        count = 0\n        while count < self.max_requests:\n            response = requests.get(self.base_url)\n            if response.status_code == 200:\n                self.parse(response.text)\n                count += 1\n                time.sleep(self.delay)\n            else:\n                print('Failed to retrieve:', self.base_url)\n                break\n\n    def parse(self, html: str) -> None:\n        \"\"\"\n        Parses the HTML content to extract book titles and prices.\n\n        :param html: The HTML content of the page to parse.\n        \"\"\"\n        soup = BeautifulSoup(html, 'html.parser')\n        books = soup.find_all('div', class_='book-item')\n        for book in books:\n            title: Optional[str] = book.find('h2').text\n            price: Optional[str] = book.find('span', class_='price').text\n            print(f'Title: {title}, Price: {price}')\n\nif __name__ == '__main__':\n    crawler = Crawler('http://example.com/books')\n    crawler.crawl()",
    "rejected_code": "import time\nimport requests\nfrom bs4 import BeautifulSoup\n\nclass Crawler:\n    def __init__(self, base_url, delay=2, max_requests=10):\n        self.base_url = base_url\n        self.delay = delay\n        self.max_requests = max_requests\n\n    def crawl(self):\n        count = 0\n        while count < self.max_requests:\n            response = requests.get(self.base_url)\n            if response.status_code == 200:\n                self.parse(response.text)\n                count += 1\n                time.sleep(self.delay)\n            else:\n                print('Failed to retrieve:', self.base_url)\n                break\n\n    def parse(self, html):\n        soup = BeautifulSoup(html, 'html.parser')\n        books = soup.find_all('div', class_='book-item')\n        for book in books:\n            title = book.find('h2').text\n            price = book.find('span', class_='price').text\n            print(f'Title: {title}, Price: {price}')  \n\ncrawler = Crawler('http://example.com/books')\ncrawler.crawl()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Implement a content extraction function with configurable selectors",
    "code_form": "extractor function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to extract product titles and prices from an e-commerce website with configurable CSS selectors?",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom bs4 import BeautifulSoup\nfrom typing import List, Tuple\n\n\ndef extract_content(url: str, title_selector: str, price_selector: str) -> List[Tuple[str, str]]:\n    \"\"\"\n    Extracts product titles and prices from a given e-commerce URL using specified CSS selectors.\n\n    Parameters:\n    - url (str): The URL of the e-commerce page to scrape.\n    - title_selector (str): The CSS selector for product titles.\n    - price_selector (str): The CSS selector for product prices.\n\n    Returns:\n    - List[Tuple[str, str]]: A list of tuples, each containing a product title and its corresponding price.\n    \"\"\"\n    # Send a GET request to the specified URL\n    response = requests.get(url)\n    # Raise an exception if the request was unsuccessful\n    response.raise_for_status()\n\n    # Parse the HTML content of the page\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    # Extract titles and prices using the provided selectors\n    titles = [elem.text.strip() for elem in soup.select(title_selector)]\n    prices = [elem.text.strip() for elem in soup.select(price_selector)]\n\n    # Return a list of tuples containing titles and prices\n    return list(zip(titles, prices))\n\n\nif __name__ == '__main__':\n    # Example usage of the extract_content function\n    url = 'https://example-ecommerce.com'\n    title_selector = '.product-title'\n    price_selector = '.product-price'\n    products = extract_content(url, title_selector, price_selector)\n    print(products)",
    "rejected_code": "import requests\nfrom bs4 import BeautifulSoup\n\ndef extract_content(url, title_selector, price_selector):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    titles = [elem.text.strip() for elem in soup.select(title_selector)]\n    prices = [elem.text.strip() for elem in soup.select(price_selector)]\n    return list(zip(titles, prices))\n\nurl = 'https://example-ecommerce.com'\ntitle_selector = '.product-title'\nprice_selector = '.product-price'\nproducts = extract_content(url, title_selector, price_selector)\nprint(products)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.15,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Implement a content extraction function with configurable selectors",
    "code_form": "extractor function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a function in Python that extracts product titles and prices from an e-commerce website using configurable CSS selectors.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom bs4 import BeautifulSoup\nfrom typing import List, Tuple\n\n\ndef extract_content(url: str, title_selector: str, price_selector: str) -> List[Tuple[str, str]]:\n    \"\"\"\n    Extracts product titles and prices from a given e-commerce URL using specified CSS selectors.\n\n    Parameters:\n    - url (str): The URL of the e-commerce page to scrape.\n    - title_selector (str): The CSS selector for product titles.\n    - price_selector (str): The CSS selector for product prices.\n\n    Returns:\n    - List[Tuple[str, str]]: A list of tuples, each containing a product title and its corresponding price.\n    \"\"\"\n    # Send a GET request to the specified URL\n    response = requests.get(url)\n    # Raise an exception if the request was unsuccessful\n    response.raise_for_status()\n\n    # Parse the HTML content of the page\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    # Extract titles and prices using the provided selectors\n    titles = [elem.text.strip() for elem in soup.select(title_selector)]\n    prices = [elem.text.strip() for elem in soup.select(price_selector)]\n\n    # Return a list of tuples containing titles and prices\n    return list(zip(titles, prices))\n\n\nif __name__ == '__main__':\n    # Example usage of the extract_content function\n    url = 'https://example-ecommerce.com'\n    title_selector = '.product-title'\n    price_selector = '.product-price'\n    products = extract_content(url, title_selector, price_selector)\n    print(products)",
    "rejected_code": "import requests\nfrom bs4 import BeautifulSoup\n\ndef extract_content(url, title_selector, price_selector):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    titles = [elem.text.strip() for elem in soup.select(title_selector)]\n    prices = [elem.text.strip() for elem in soup.select(price_selector)]\n    return list(zip(titles, prices))\n\nurl = 'https://example-ecommerce.com'\ntitle_selector = '.product-title'\nprice_selector = '.product-price'\nproducts = extract_content(url, title_selector, price_selector)\nprint(products)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.15,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Implement a content extraction function with configurable selectors",
    "code_form": "extractor function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you create a Python function that takes a URL, title selector, and price selector as inputs and returns a list of tuples containing product titles and prices?",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom bs4 import BeautifulSoup\nfrom typing import List, Tuple\n\n\ndef extract_content(url: str, title_selector: str, price_selector: str) -> List[Tuple[str, str]]:\n    \"\"\"\n    Extracts product titles and prices from a given e-commerce URL using specified CSS selectors.\n\n    Parameters:\n    - url (str): The URL of the e-commerce page to scrape.\n    - title_selector (str): The CSS selector for product titles.\n    - price_selector (str): The CSS selector for product prices.\n\n    Returns:\n    - List[Tuple[str, str]]: A list of tuples, each containing a product title and its corresponding price.\n    \"\"\"\n    # Send a GET request to the specified URL\n    response = requests.get(url)\n    # Raise an exception if the request was unsuccessful\n    response.raise_for_status()\n\n    # Parse the HTML content of the page\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    # Extract titles and prices using the provided selectors\n    titles = [elem.text.strip() for elem in soup.select(title_selector)]\n    prices = [elem.text.strip() for elem in soup.select(price_selector)]\n\n    # Return a list of tuples containing titles and prices\n    return list(zip(titles, prices))\n\n\nif __name__ == '__main__':\n    # Example usage of the extract_content function\n    url = 'https://example-ecommerce.com'\n    title_selector = '.product-title'\n    price_selector = '.product-price'\n    products = extract_content(url, title_selector, price_selector)\n    print(products)",
    "rejected_code": "import requests\nfrom bs4 import BeautifulSoup\n\ndef extract_content(url, title_selector, price_selector):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    titles = [elem.text.strip() for elem in soup.select(title_selector)]\n    prices = [elem.text.strip() for elem in soup.select(price_selector)]\n    return list(zip(titles, prices))\n\nurl = 'https://example-ecommerce.com'\ntitle_selector = '.product-title'\nprice_selector = '.product-price'\nproducts = extract_content(url, title_selector, price_selector)\nprint(products)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.15,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Develop a data cleaning function for scraped HTML content",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to clean scraped HTML content and extract article titles.",
      "role": "user"
    },
    "chosen_code": "from typing import List\nfrom bs4 import BeautifulSoup\n\n\ndef clean_html(content: str) -> List[str]:\n    \"\"\"\n    Cleans the provided HTML content to extract article titles.\n\n    This function uses BeautifulSoup to parse the HTML content and find all\n    <h1> tags. It then extracts the text from each <h1> tag, strips any\n    leading and trailing whitespace, and returns a list of cleaned titles.\n\n    Args:\n        content (str): A string containing the HTML content to be cleaned.\n\n    Returns:\n        List[str]: A list of cleaned article titles extracted from the HTML.\n    \"\"\"\n    # Parse the HTML content using BeautifulSoup\n    soup = BeautifulSoup(content, 'html.parser')\n\n    # Find all <h1> tags in the HTML\n    titles = soup.find_all('h1')\n\n    # Extract and clean the text from each <h1> tag\n    cleaned_titles = [title.get_text(strip=True) for title in titles]\n\n    return cleaned_titles\n\n\n# Example usage of the clean_html function\nhtml_content = '<html><body><h1> Article One </h1><p>Some text.</p><h1> Article Two </h1></body></html>'\nprint(clean_html(html_content))",
    "rejected_code": "from bs4 import BeautifulSoup\n\ndef clean_html(content):\n    soup = BeautifulSoup(content, 'html.parser')\n    titles = soup.find_all('h1')\n    cleaned_titles = []\n    for title in titles:\n        cleaned_title = title.get_text(strip=True)\n        cleaned_titles.append(cleaned_title)\n    return cleaned_titles\n\nhtml_content = '<html><body><h1> Article One </h1><p>Some text.</p><h1> Article Two </h1></body></html>'\nprint(clean_html(html_content))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.12121212121212122,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Develop a data cleaning function for scraped HTML content",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a function to clean scraped HTML content and extract article titles?",
      "role": "user"
    },
    "chosen_code": "from typing import List\nfrom bs4 import BeautifulSoup\n\n\ndef clean_html(content: str) -> List[str]:\n    \"\"\"\n    Cleans the provided HTML content to extract article titles.\n\n    This function uses BeautifulSoup to parse the HTML content and find all\n    <h1> tags. It then extracts the text from each <h1> tag, strips any\n    leading and trailing whitespace, and returns a list of cleaned titles.\n\n    Args:\n        content (str): A string containing the HTML content to be cleaned.\n\n    Returns:\n        List[str]: A list of cleaned article titles extracted from the HTML.\n    \"\"\"\n    # Parse the HTML content using BeautifulSoup\n    soup = BeautifulSoup(content, 'html.parser')\n\n    # Find all <h1> tags in the HTML\n    titles = soup.find_all('h1')\n\n    # Extract and clean the text from each <h1> tag\n    cleaned_titles = [title.get_text(strip=True) for title in titles]\n\n    return cleaned_titles\n\n\n# Example usage of the clean_html function\nhtml_content = '<html><body><h1> Article One </h1><p>Some text.</p><h1> Article Two </h1></body></html>'\nprint(clean_html(html_content))",
    "rejected_code": "from bs4 import BeautifulSoup\n\ndef clean_html(content):\n    soup = BeautifulSoup(content, 'html.parser')\n    titles = soup.find_all('h1')\n    cleaned_titles = []\n    for title in titles:\n        cleaned_title = title.get_text(strip=True)\n        cleaned_titles.append(cleaned_title)\n    return cleaned_titles\n\nhtml_content = '<html><body><h1> Article One </h1><p>Some text.</p><h1> Article Two </h1></body></html>'\nprint(clean_html(html_content))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.12121212121212122,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Develop a data cleaning function for scraped HTML content",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a function that takes a string of HTML content as input and returns a list of cleaned article titles.",
      "role": "user"
    },
    "chosen_code": "from typing import List\nfrom bs4 import BeautifulSoup\n\n\ndef clean_html(content: str) -> List[str]:\n    \"\"\"\n    Cleans the provided HTML content to extract article titles.\n\n    This function uses BeautifulSoup to parse the HTML content and find all\n    <h1> tags. It then extracts the text from each <h1> tag, strips any\n    leading and trailing whitespace, and returns a list of cleaned titles.\n\n    Args:\n        content (str): A string containing the HTML content to be cleaned.\n\n    Returns:\n        List[str]: A list of cleaned article titles extracted from the HTML.\n    \"\"\"\n    # Parse the HTML content using BeautifulSoup\n    soup = BeautifulSoup(content, 'html.parser')\n\n    # Find all <h1> tags in the HTML\n    titles = soup.find_all('h1')\n\n    # Extract and clean the text from each <h1> tag\n    cleaned_titles = [title.get_text(strip=True) for title in titles]\n\n    return cleaned_titles\n\n\n# Example usage of the clean_html function\nhtml_content = '<html><body><h1> Article One </h1><p>Some text.</p><h1> Article Two </h1></body></html>'\nprint(clean_html(html_content))",
    "rejected_code": "from bs4 import BeautifulSoup\n\ndef clean_html(content):\n    soup = BeautifulSoup(content, 'html.parser')\n    titles = soup.find_all('h1')\n    cleaned_titles = []\n    for title in titles:\n        cleaned_title = title.get_text(strip=True)\n        cleaned_titles.append(cleaned_title)\n    return cleaned_titles\n\nhtml_content = '<html><body><h1> Article One </h1><p>Some text.</p><h1> Article Two </h1></body></html>'\nprint(clean_html(html_content))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.12121212121212122,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'bs4'"
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Build a proxy rotation class with validation and fallback",
    "code_form": "manager class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to build a proxy rotation class with validation and fallback for web scraping?",
      "role": "user"
    },
    "chosen_code": "import requests\nimport random\nfrom typing import List, Optional\n\nclass ProxyManager:\n    \"\"\"\n    A class responsible for managing a list of proxy servers, including\n    proxy rotation and validation.\n    \"\"\"\n\n    def __init__(self, proxies: List[str]) -> None:\n        \"\"\"\n        Initialize the ProxyManager with a list of proxies.\n\n        :param proxies: A list of proxy server URLs.\n        \"\"\"\n        self.proxies = proxies\n        self.current_proxy: Optional[str] = None\n\n    def get_proxy(self) -> str:\n        \"\"\"\n        Selects a random proxy from the list of proxies.\n\n        :return: A randomly selected proxy URL.\n        \"\"\"\n        self.current_proxy = random.choice(self.proxies)\n        return self.current_proxy\n\n    def validate_proxy(self) -> bool:\n        \"\"\"\n        Validates the current proxy by making a request to a test URL.\n\n        :return: True if the proxy is valid, False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(\n                'https://httpbin.org/ip',\n                proxies={'http': self.current_proxy, 'https': self.current_proxy},\n                timeout=5\n            )\n            return response.status_code == 200\n        except requests.RequestException:\n            return False\n\n    def get_valid_proxy(self) -> Optional[str]:\n        \"\"\"\n        Attempts to find a valid proxy from the list of proxies.\n\n        :return: A valid proxy URL if found, None otherwise.\n        \"\"\"\n        for _ in range(len(self.proxies)):\n            proxy = self.get_proxy()\n            if self.validate_proxy():\n                return proxy\n        return None\n\nclass Scraper:\n    \"\"\"\n    A class responsible for scraping web pages using a proxy manager.\n    \"\"\"\n\n    def __init__(self, proxy_manager: ProxyManager) -> None:\n        \"\"\"\n        Initialize the Scraper with a ProxyManager instance.\n\n        :param proxy_manager: An instance of ProxyManager for proxy management.\n        \"\"\"\n        self.proxy_manager = proxy_manager\n\n    def scrape(self, url: str) -> str:\n        \"\"\"\n        Scrapes the given URL using a valid proxy.\n\n        :param url: The URL to scrape.\n        :return: The HTML content of the page or an error message.\n        \"\"\"\n        proxy = self.proxy_manager.get_valid_proxy()\n        if not proxy:\n            return 'No valid proxy available'\n        try:\n            response = requests.get(url, proxies={'http': proxy, 'https': proxy})\n            return response.text\n        except requests.RequestException:\n            return 'Request failed'\n\n# Example usage\nproxies = ['http://proxy1.com', 'http://proxy2.com', 'http://proxy3.com']\nproxy_manager = ProxyManager(proxies)\nscraper = Scraper(proxy_manager)\nresult = scraper.scrape('https://example-ecommerce.com/products')",
    "rejected_code": "import requests\nimport random\n\nclass ProxyManager:\n    def __init__(self, proxies):\n        self.proxies = proxies\n        self.current_proxy = None\n\n    def get_proxy(self):\n        self.current_proxy = random.choice(self.proxies)\n        return self.current_proxy\n\n    def validate_proxy(self):\n        try:\n            response = requests.get('https://httpbin.org/ip', proxies={'http': self.current_proxy, 'https': self.current_proxy}, timeout=5)\n            return response.status_code == 200\n        except:\n            return False\n\n    def get_valid_proxy(self):\n        for _ in range(len(self.proxies)):\n            proxy = self.get_proxy()\n            if self.validate_proxy():\n                return proxy\n        return None\n\nclass Scraper:\n    def __init__(self, proxy_manager):\n        self.proxy_manager = proxy_manager\n\n    def scrape(self, url):\n        proxy = self.proxy_manager.get_valid_proxy()\n        if not proxy:\n            return 'No valid proxy available'\n        try:\n            response = requests.get(url, proxies={'http': proxy, 'https': proxy})\n            return response.text\n        except:\n            return 'Request failed'\n\nproxies = ['http://proxy1.com', 'http://proxy2.com', 'http://proxy3.com']\nproxy_manager = ProxyManager(proxies)\nscraper = Scraper(proxy_manager)\nresult = scraper.scrape('https://example-ecommerce.com/products')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.125,
      "pep8_compliance": null,
      "comment_density": 0.011111111111111112,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.125,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Build a proxy rotation class with validation and fallback",
    "code_form": "manager class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Could you write a Python class that implements a proxy rotation system with validation and fallback for web scraping?",
      "role": "user"
    },
    "chosen_code": "import requests\nimport random\nfrom typing import List, Optional\n\nclass ProxyManager:\n    \"\"\"\n    A class responsible for managing a list of proxy servers, including\n    proxy rotation and validation.\n    \"\"\"\n\n    def __init__(self, proxies: List[str]) -> None:\n        \"\"\"\n        Initialize the ProxyManager with a list of proxies.\n\n        :param proxies: A list of proxy server URLs.\n        \"\"\"\n        self.proxies = proxies\n        self.current_proxy: Optional[str] = None\n\n    def get_proxy(self) -> str:\n        \"\"\"\n        Selects a random proxy from the list of proxies.\n\n        :return: A randomly selected proxy URL.\n        \"\"\"\n        self.current_proxy = random.choice(self.proxies)\n        return self.current_proxy\n\n    def validate_proxy(self) -> bool:\n        \"\"\"\n        Validates the current proxy by making a request to a test URL.\n\n        :return: True if the proxy is valid, False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(\n                'https://httpbin.org/ip',\n                proxies={'http': self.current_proxy, 'https': self.current_proxy},\n                timeout=5\n            )\n            return response.status_code == 200\n        except requests.RequestException:\n            return False\n\n    def get_valid_proxy(self) -> Optional[str]:\n        \"\"\"\n        Attempts to find a valid proxy from the list of proxies.\n\n        :return: A valid proxy URL if found, None otherwise.\n        \"\"\"\n        for _ in range(len(self.proxies)):\n            proxy = self.get_proxy()\n            if self.validate_proxy():\n                return proxy\n        return None\n\nclass Scraper:\n    \"\"\"\n    A class responsible for scraping web pages using a proxy manager.\n    \"\"\"\n\n    def __init__(self, proxy_manager: ProxyManager) -> None:\n        \"\"\"\n        Initialize the Scraper with a ProxyManager instance.\n\n        :param proxy_manager: An instance of ProxyManager for proxy management.\n        \"\"\"\n        self.proxy_manager = proxy_manager\n\n    def scrape(self, url: str) -> str:\n        \"\"\"\n        Scrapes the given URL using a valid proxy.\n\n        :param url: The URL to scrape.\n        :return: The HTML content of the page or an error message.\n        \"\"\"\n        proxy = self.proxy_manager.get_valid_proxy()\n        if not proxy:\n            return 'No valid proxy available'\n        try:\n            response = requests.get(url, proxies={'http': proxy, 'https': proxy})\n            return response.text\n        except requests.RequestException:\n            return 'Request failed'\n\n# Example usage\nproxies = ['http://proxy1.com', 'http://proxy2.com', 'http://proxy3.com']\nproxy_manager = ProxyManager(proxies)\nscraper = Scraper(proxy_manager)\nresult = scraper.scrape('https://example-ecommerce.com/products')",
    "rejected_code": "import requests\nimport random\n\nclass ProxyManager:\n    def __init__(self, proxies):\n        self.proxies = proxies\n        self.current_proxy = None\n\n    def get_proxy(self):\n        self.current_proxy = random.choice(self.proxies)\n        return self.current_proxy\n\n    def validate_proxy(self):\n        try:\n            response = requests.get('https://httpbin.org/ip', proxies={'http': self.current_proxy, 'https': self.current_proxy}, timeout=5)\n            return response.status_code == 200\n        except:\n            return False\n\n    def get_valid_proxy(self):\n        for _ in range(len(self.proxies)):\n            proxy = self.get_proxy()\n            if self.validate_proxy():\n                return proxy\n        return None\n\nclass Scraper:\n    def __init__(self, proxy_manager):\n        self.proxy_manager = proxy_manager\n\n    def scrape(self, url):\n        proxy = self.proxy_manager.get_valid_proxy()\n        if not proxy:\n            return 'No valid proxy available'\n        try:\n            response = requests.get(url, proxies={'http': proxy, 'https': proxy})\n            return response.text\n        except:\n            return 'Request failed'\n\nproxies = ['http://proxy1.com', 'http://proxy2.com', 'http://proxy3.com']\nproxy_manager = ProxyManager(proxies)\nscraper = Scraper(proxy_manager)\nresult = scraper.scrape('https://example-ecommerce.com/products')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.125,
      "pep8_compliance": null,
      "comment_density": 0.011111111111111112,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.125,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "web scraping",
    "task": "Build a proxy rotation class with validation and fallback",
    "code_form": "manager class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please generate a Python class that manages proxy rotation with validation and fallback, specifying input types for the constructor and output types for the methods.",
      "role": "user"
    },
    "chosen_code": "import requests\nimport random\nfrom typing import List, Optional\n\nclass ProxyManager:\n    \"\"\"\n    A class responsible for managing a list of proxy servers, including\n    proxy rotation and validation.\n    \"\"\"\n\n    def __init__(self, proxies: List[str]) -> None:\n        \"\"\"\n        Initialize the ProxyManager with a list of proxies.\n\n        :param proxies: A list of proxy server URLs.\n        \"\"\"\n        self.proxies = proxies\n        self.current_proxy: Optional[str] = None\n\n    def get_proxy(self) -> str:\n        \"\"\"\n        Selects a random proxy from the list of proxies.\n\n        :return: A randomly selected proxy URL.\n        \"\"\"\n        self.current_proxy = random.choice(self.proxies)\n        return self.current_proxy\n\n    def validate_proxy(self) -> bool:\n        \"\"\"\n        Validates the current proxy by making a request to a test URL.\n\n        :return: True if the proxy is valid, False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(\n                'https://httpbin.org/ip',\n                proxies={'http': self.current_proxy, 'https': self.current_proxy},\n                timeout=5\n            )\n            return response.status_code == 200\n        except requests.RequestException:\n            return False\n\n    def get_valid_proxy(self) -> Optional[str]:\n        \"\"\"\n        Attempts to find a valid proxy from the list of proxies.\n\n        :return: A valid proxy URL if found, None otherwise.\n        \"\"\"\n        for _ in range(len(self.proxies)):\n            proxy = self.get_proxy()\n            if self.validate_proxy():\n                return proxy\n        return None\n\nclass Scraper:\n    \"\"\"\n    A class responsible for scraping web pages using a proxy manager.\n    \"\"\"\n\n    def __init__(self, proxy_manager: ProxyManager) -> None:\n        \"\"\"\n        Initialize the Scraper with a ProxyManager instance.\n\n        :param proxy_manager: An instance of ProxyManager for proxy management.\n        \"\"\"\n        self.proxy_manager = proxy_manager\n\n    def scrape(self, url: str) -> str:\n        \"\"\"\n        Scrapes the given URL using a valid proxy.\n\n        :param url: The URL to scrape.\n        :return: The HTML content of the page or an error message.\n        \"\"\"\n        proxy = self.proxy_manager.get_valid_proxy()\n        if not proxy:\n            return 'No valid proxy available'\n        try:\n            response = requests.get(url, proxies={'http': proxy, 'https': proxy})\n            return response.text\n        except requests.RequestException:\n            return 'Request failed'\n\n# Example usage\nproxies = ['http://proxy1.com', 'http://proxy2.com', 'http://proxy3.com']\nproxy_manager = ProxyManager(proxies)\nscraper = Scraper(proxy_manager)\nresult = scraper.scrape('https://example-ecommerce.com/products')",
    "rejected_code": "import requests\nimport random\n\nclass ProxyManager:\n    def __init__(self, proxies):\n        self.proxies = proxies\n        self.current_proxy = None\n\n    def get_proxy(self):\n        self.current_proxy = random.choice(self.proxies)\n        return self.current_proxy\n\n    def validate_proxy(self):\n        try:\n            response = requests.get('https://httpbin.org/ip', proxies={'http': self.current_proxy, 'https': self.current_proxy}, timeout=5)\n            return response.status_code == 200\n        except:\n            return False\n\n    def get_valid_proxy(self):\n        for _ in range(len(self.proxies)):\n            proxy = self.get_proxy()\n            if self.validate_proxy():\n                return proxy\n        return None\n\nclass Scraper:\n    def __init__(self, proxy_manager):\n        self.proxy_manager = proxy_manager\n\n    def scrape(self, url):\n        proxy = self.proxy_manager.get_valid_proxy()\n        if not proxy:\n            return 'No valid proxy available'\n        try:\n            response = requests.get(url, proxies={'http': proxy, 'https': proxy})\n            return response.text\n        except:\n            return 'Request failed'\n\nproxies = ['http://proxy1.com', 'http://proxy2.com', 'http://proxy3.com']\nproxy_manager = ProxyManager(proxies)\nscraper = Scraper(proxy_manager)\nresult = scraper.scrape('https://example-ecommerce.com/products')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.125,
      "pep8_compliance": null,
      "comment_density": 0.011111111111111112,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.125,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Implement a stock price prediction function using time series models",
    "code_form": "prediction function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide a Python code example to predict stock prices using historical data?",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List\n\n\ndef download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.Series:\n    \"\"\"\n    Download historical stock price data for a given ticker symbol.\n\n    :param ticker: Stock ticker symbol (e.g., 'AAPL').\n    :param start_date: Start date for historical data in 'YYYY-MM-DD' format.\n    :param end_date: End date for historical data in 'YYYY-MM-DD' format.\n    :return: A pandas Series containing the closing prices of the stock.\n    \"\"\"\n    stock_data = yf.download(ticker, start=start_date, end=end_date)\n    return stock_data['Close']\n\n\ndef predict_stock_prices(stock_prices: pd.Series, forecast_days: int = 30) -> List[float]:\n    \"\"\"\n    Predict future stock prices using the ARIMA time series model.\n\n    :param stock_prices: A pandas Series containing historical stock prices.\n    :param forecast_days: Number of days to forecast into the future (default is 30).\n    :return: A list of predicted stock prices for the specified number of days.\n    \"\"\"\n    # Fit the ARIMA model (order can be adjusted based on analysis)\n    model = ARIMA(stock_prices, order=(5, 1, 0))\n    model_fit = model.fit()\n\n    # Forecast the next 'forecast_days' days\n    forecast = model_fit.forecast(steps=forecast_days)\n    return forecast.tolist()\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to execute the stock price prediction workflow.\n    \"\"\"\n    ticker = 'AAPL'\n    start_date = '2020-01-01'\n    end_date = '2023-10-01'\n\n    # Download stock data\n    stock_prices = download_stock_data(ticker, start_date, end_date)\n\n    # Predict future stock prices\n    predicted_prices = predict_stock_prices(stock_prices)\n\n    # Print the predicted stock prices\n    print(predicted_prices)\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "import pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom statsmodels.tsa.arima.model import ARIMA\n\n# Download historical stock price data for AAPL\nstock_data = yf.download('AAPL', start='2020-01-01', end='2023-10-01')\n\n# Prepare the data\nstock_prices = stock_data['Close']\n\n# Fit the ARIMA model\nmodel = ARIMA(stock_prices, order=(5, 1, 0))\nmodel_fit = model.fit()\n\n# Forecast the next 30 days\nforecast = model_fit.forecast(steps=30)\n\n# Print the predicted stock prices\nprint(forecast)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.08771929824561403,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.25,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Implement a stock price prediction function using time series models",
    "code_form": "prediction function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a Python function to predict stock prices using historical data?",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List\n\n\ndef download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.Series:\n    \"\"\"\n    Download historical stock price data for a given ticker symbol.\n\n    :param ticker: Stock ticker symbol (e.g., 'AAPL').\n    :param start_date: Start date for historical data in 'YYYY-MM-DD' format.\n    :param end_date: End date for historical data in 'YYYY-MM-DD' format.\n    :return: A pandas Series containing the closing prices of the stock.\n    \"\"\"\n    stock_data = yf.download(ticker, start=start_date, end=end_date)\n    return stock_data['Close']\n\n\ndef predict_stock_prices(stock_prices: pd.Series, forecast_days: int = 30) -> List[float]:\n    \"\"\"\n    Predict future stock prices using the ARIMA time series model.\n\n    :param stock_prices: A pandas Series containing historical stock prices.\n    :param forecast_days: Number of days to forecast into the future (default is 30).\n    :return: A list of predicted stock prices for the specified number of days.\n    \"\"\"\n    # Fit the ARIMA model (order can be adjusted based on analysis)\n    model = ARIMA(stock_prices, order=(5, 1, 0))\n    model_fit = model.fit()\n\n    # Forecast the next 'forecast_days' days\n    forecast = model_fit.forecast(steps=forecast_days)\n    return forecast.tolist()\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to execute the stock price prediction workflow.\n    \"\"\"\n    ticker = 'AAPL'\n    start_date = '2020-01-01'\n    end_date = '2023-10-01'\n\n    # Download stock data\n    stock_prices = download_stock_data(ticker, start_date, end_date)\n\n    # Predict future stock prices\n    predicted_prices = predict_stock_prices(stock_prices)\n\n    # Print the predicted stock prices\n    print(predicted_prices)\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "import pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom statsmodels.tsa.arima.model import ARIMA\n\n# Download historical stock price data for AAPL\nstock_data = yf.download('AAPL', start='2020-01-01', end='2023-10-01')\n\n# Prepare the data\nstock_prices = stock_data['Close']\n\n# Fit the ARIMA model\nmodel = ARIMA(stock_prices, order=(5, 1, 0))\nmodel_fit = model.fit()\n\n# Forecast the next 30 days\nforecast = model_fit.forecast(steps=30)\n\n# Print the predicted stock prices\nprint(forecast)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.08771929824561403,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.25,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Implement a stock price prediction function using time series models",
    "code_form": "prediction function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you create a Python function that takes a pandas Series of historical stock prices as input and returns a list of predicted future prices?",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom typing import List\n\n\ndef download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.Series:\n    \"\"\"\n    Download historical stock price data for a given ticker symbol.\n\n    :param ticker: Stock ticker symbol (e.g., 'AAPL').\n    :param start_date: Start date for historical data in 'YYYY-MM-DD' format.\n    :param end_date: End date for historical data in 'YYYY-MM-DD' format.\n    :return: A pandas Series containing the closing prices of the stock.\n    \"\"\"\n    stock_data = yf.download(ticker, start=start_date, end=end_date)\n    return stock_data['Close']\n\n\ndef predict_stock_prices(stock_prices: pd.Series, forecast_days: int = 30) -> List[float]:\n    \"\"\"\n    Predict future stock prices using the ARIMA time series model.\n\n    :param stock_prices: A pandas Series containing historical stock prices.\n    :param forecast_days: Number of days to forecast into the future (default is 30).\n    :return: A list of predicted stock prices for the specified number of days.\n    \"\"\"\n    # Fit the ARIMA model (order can be adjusted based on analysis)\n    model = ARIMA(stock_prices, order=(5, 1, 0))\n    model_fit = model.fit()\n\n    # Forecast the next 'forecast_days' days\n    forecast = model_fit.forecast(steps=forecast_days)\n    return forecast.tolist()\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to execute the stock price prediction workflow.\n    \"\"\"\n    ticker = 'AAPL'\n    start_date = '2020-01-01'\n    end_date = '2023-10-01'\n\n    # Download stock data\n    stock_prices = download_stock_data(ticker, start_date, end_date)\n\n    # Predict future stock prices\n    predicted_prices = predict_stock_prices(stock_prices)\n\n    # Print the predicted stock prices\n    print(predicted_prices)\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "import pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom statsmodels.tsa.arima.model import ARIMA\n\n# Download historical stock price data for AAPL\nstock_data = yf.download('AAPL', start='2020-01-01', end='2023-10-01')\n\n# Prepare the data\nstock_prices = stock_data['Close']\n\n# Fit the ARIMA model\nmodel = ARIMA(stock_prices, order=(5, 1, 0))\nmodel_fit = model.fit()\n\n# Forecast the next 30 days\nforecast = model_fit.forecast(steps=30)\n\n# Print the predicted stock prices\nprint(forecast)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.08771929824561403,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0,
      "docstring_coverage": 0,
      "code_complexity": 0.0,
      "pep8_compliance": null,
      "comment_density": 0.25,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Build a portfolio risk analyzer with multiple risk metrics",
    "code_form": "analyzer class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to build a portfolio risk analyzer that calculates key risk metrics like VaR, CVaR, and the Sharpe Ratio for a portfolio of stocks.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nfrom typing import Tuple, List\n\nclass PortfolioRiskAnalyzer:\n    \"\"\"\n    A class to analyze the risk of a financial portfolio using multiple risk metrics.\n    \"\"\"\n\n    def __init__(self, tickers: List[str], weights: List[float]) -> None:\n        \"\"\"\n        Initializes the PortfolioRiskAnalyzer with given stock tickers and their respective weights.\n        \n        :param tickers: A list of stock tickers (e.g., ['AAPL', 'MSFT', 'AMZN']).\n        :param weights: A list of weights corresponding to each stock in the portfolio.\n        \"\"\"\n        self.tickers = tickers\n        self.weights = weights\n        self.prices = self._fetch_price_data()\n        self.returns = self.prices.pct_change().dropna()\n\n    def _fetch_price_data(self) -> pd.DataFrame:\n        \"\"\"\n        Fetches historical price data for the specified tickers from Yahoo Finance.\n        \n        :return: A DataFrame containing the closing prices of the stocks.\n        \"\"\"\n        price_data = pd.DataFrame()\n        for ticker in self.tickers:\n            price_data[ticker] = pd.read_csv(f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=1622505600&period2=1654041600&interval=1d&events=history')['Close']\n        return price_data\n\n    def portfolio_return(self) -> np.ndarray:\n        \"\"\"\n        Calculates the portfolio return based on the weights and stock returns.\n        \n        :return: The calculated portfolio returns as a NumPy array.\n        \"\"\"\n        return np.dot(self.weights, self.returns.T)\n\n    def calculate_risk_metrics(self, returns: np.ndarray) -> Tuple[float, float, float]:\n        \"\"\"\n        Calculates key risk metrics: Value at Risk (VaR), Conditional Value at Risk (CVaR), and Sharpe Ratio.\n        \n        :param returns: The portfolio returns as a NumPy array.\n        :return: A tuple containing VaR, CVaR, and Sharpe Ratio.\n        \"\"\"\n        mean_return = np.mean(returns)\n        volatility = np.std(returns)\n        VaR = np.percentile(returns, 5)\n        CVaR = returns[returns <= VaR].mean()\n        sharpe_ratio = mean_return / volatility\n        return VaR, CVaR, sharpe_ratio\n\n    def analyze(self) -> None:\n        \"\"\"\n        Conducts the analysis and prints the risk metrics.\n        \"\"\"\n        portfolio_ret = self.portfolio_return()\n        VaR, CVaR, sharpe_ratio = self.calculate_risk_metrics(portfolio_ret)\n        print('Value at Risk:', VaR)\n        print('Conditional Value at Risk:', CVaR)\n        print('Sharpe Ratio:', sharpe_ratio)\n\n# Example usage:\nif __name__ == '__main__':\n    analyzer = PortfolioRiskAnalyzer(tickers=['AAPL', 'MSFT', 'AMZN'], weights=[0.4, 0.4, 0.2])\n    analyzer.analyze()",
    "rejected_code": "import pandas as pd\nimport numpy as np\nyf = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/AAPL?period1=1622505600&period2=1654041600&interval=1d&events=history')\nmsft = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/MSFT?period1=1622505600&period2=1654041600&interval=1d&events=history')\namzn = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/AMZN?period1=1622505600&period2=1654041600&interval=1d&events=history')\n\ndef portfolio_return(weights, returns):\n    return np.dot(weights, returns)\n\ndef calculate_risk_metrics(returns):\n    mean_return = np.mean(returns)\n    volatility = np.std(returns)\n    VaR = np.percentile(returns, 5)\n    CVaR = returns[returns <= VaR].mean()\n    sharpe_ratio = mean_return / volatility\n    return VaR, CVaR, sharpe_ratio\n\nprices = pd.DataFrame()\nprices['AAPL'] = yf['Close']\nprices['MSFT'] = msft['Close']\nprices['AMZN'] = amzn['Close']\n\nreturns = prices.pct_change().dropna()\nweights = np.array([0.4, 0.4, 0.2])\n\nportfolio_ret = portfolio_return(weights, returns.T)\nVaR, CVaR, sharpe_ratio = calculate_risk_metrics(portfolio_ret)\n\nprint('Value at Risk:', VaR)\nprint('Conditional Value at Risk:', CVaR)\nprint('Sharpe Ratio:', sharpe_ratio)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.014705882352941176,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 67, in <module>\n  File \"<string>\", line 19, in __init__\n  File \"<string>\", line 30, in _fetch_price_data\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 728, in get_handle\n    ioargs = _get_filepath_or_buffer(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 384, in _get_filepath_or_buffer\n    with urlopen(req_info) as req:\n         ^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 289, in urlopen\n    return urllib.request.urlopen(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 216, in urlopen\n    return opener.open(url, data, timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 525, in open\n    response = meth(req, response)\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 634, in http_response\n    response = self.parent.error(\n               ^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 563, in error\n    return self._call_chain(*args)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n    result = func(*args)\n             ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 429: Too Many Requests"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 728, in get_handle\n    ioargs = _get_filepath_or_buffer(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 384, in _get_filepath_or_buffer\n    with urlopen(req_info) as req:\n         ^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 289, in urlopen\n    return urllib.request.urlopen(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 216, in urlopen\n    return opener.open(url, data, timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 525, in open\n    response = meth(req, response)\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 634, in http_response\n    response = self.parent.error(\n               ^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 563, in error\n    return self._call_chain(*args)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n    result = func(*args)\n             ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 429: Too Many Requests"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Build a portfolio risk analyzer with multiple risk metrics",
    "code_form": "analyzer class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a class to implement a portfolio risk analyzer that calculates key risk metrics like VaR, CVaR, and the Sharpe Ratio for a portfolio of stocks?",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nfrom typing import Tuple, List\n\nclass PortfolioRiskAnalyzer:\n    \"\"\"\n    A class to analyze the risk of a financial portfolio using multiple risk metrics.\n    \"\"\"\n\n    def __init__(self, tickers: List[str], weights: List[float]) -> None:\n        \"\"\"\n        Initializes the PortfolioRiskAnalyzer with given stock tickers and their respective weights.\n        \n        :param tickers: A list of stock tickers (e.g., ['AAPL', 'MSFT', 'AMZN']).\n        :param weights: A list of weights corresponding to each stock in the portfolio.\n        \"\"\"\n        self.tickers = tickers\n        self.weights = weights\n        self.prices = self._fetch_price_data()\n        self.returns = self.prices.pct_change().dropna()\n\n    def _fetch_price_data(self) -> pd.DataFrame:\n        \"\"\"\n        Fetches historical price data for the specified tickers from Yahoo Finance.\n        \n        :return: A DataFrame containing the closing prices of the stocks.\n        \"\"\"\n        price_data = pd.DataFrame()\n        for ticker in self.tickers:\n            price_data[ticker] = pd.read_csv(f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=1622505600&period2=1654041600&interval=1d&events=history')['Close']\n        return price_data\n\n    def portfolio_return(self) -> np.ndarray:\n        \"\"\"\n        Calculates the portfolio return based on the weights and stock returns.\n        \n        :return: The calculated portfolio returns as a NumPy array.\n        \"\"\"\n        return np.dot(self.weights, self.returns.T)\n\n    def calculate_risk_metrics(self, returns: np.ndarray) -> Tuple[float, float, float]:\n        \"\"\"\n        Calculates key risk metrics: Value at Risk (VaR), Conditional Value at Risk (CVaR), and Sharpe Ratio.\n        \n        :param returns: The portfolio returns as a NumPy array.\n        :return: A tuple containing VaR, CVaR, and Sharpe Ratio.\n        \"\"\"\n        mean_return = np.mean(returns)\n        volatility = np.std(returns)\n        VaR = np.percentile(returns, 5)\n        CVaR = returns[returns <= VaR].mean()\n        sharpe_ratio = mean_return / volatility\n        return VaR, CVaR, sharpe_ratio\n\n    def analyze(self) -> None:\n        \"\"\"\n        Conducts the analysis and prints the risk metrics.\n        \"\"\"\n        portfolio_ret = self.portfolio_return()\n        VaR, CVaR, sharpe_ratio = self.calculate_risk_metrics(portfolio_ret)\n        print('Value at Risk:', VaR)\n        print('Conditional Value at Risk:', CVaR)\n        print('Sharpe Ratio:', sharpe_ratio)\n\n# Example usage:\nif __name__ == '__main__':\n    analyzer = PortfolioRiskAnalyzer(tickers=['AAPL', 'MSFT', 'AMZN'], weights=[0.4, 0.4, 0.2])\n    analyzer.analyze()",
    "rejected_code": "import pandas as pd\nimport numpy as np\nyf = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/AAPL?period1=1622505600&period2=1654041600&interval=1d&events=history')\nmsft = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/MSFT?period1=1622505600&period2=1654041600&interval=1d&events=history')\namzn = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/AMZN?period1=1622505600&period2=1654041600&interval=1d&events=history')\n\ndef portfolio_return(weights, returns):\n    return np.dot(weights, returns)\n\ndef calculate_risk_metrics(returns):\n    mean_return = np.mean(returns)\n    volatility = np.std(returns)\n    VaR = np.percentile(returns, 5)\n    CVaR = returns[returns <= VaR].mean()\n    sharpe_ratio = mean_return / volatility\n    return VaR, CVaR, sharpe_ratio\n\nprices = pd.DataFrame()\nprices['AAPL'] = yf['Close']\nprices['MSFT'] = msft['Close']\nprices['AMZN'] = amzn['Close']\n\nreturns = prices.pct_change().dropna()\nweights = np.array([0.4, 0.4, 0.2])\n\nportfolio_ret = portfolio_return(weights, returns.T)\nVaR, CVaR, sharpe_ratio = calculate_risk_metrics(portfolio_ret)\n\nprint('Value at Risk:', VaR)\nprint('Conditional Value at Risk:', CVaR)\nprint('Sharpe Ratio:', sharpe_ratio)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.014705882352941176,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 67, in <module>\n  File \"<string>\", line 19, in __init__\n  File \"<string>\", line 30, in _fetch_price_data\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 728, in get_handle\n    ioargs = _get_filepath_or_buffer(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 384, in _get_filepath_or_buffer\n    with urlopen(req_info) as req:\n         ^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 289, in urlopen\n    return urllib.request.urlopen(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 216, in urlopen\n    return opener.open(url, data, timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 525, in open\n    response = meth(req, response)\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 634, in http_response\n    response = self.parent.error(\n               ^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 563, in error\n    return self._call_chain(*args)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n    result = func(*args)\n             ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 429: Too Many Requests"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 728, in get_handle\n    ioargs = _get_filepath_or_buffer(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 384, in _get_filepath_or_buffer\n    with urlopen(req_info) as req:\n         ^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 289, in urlopen\n    return urllib.request.urlopen(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 216, in urlopen\n    return opener.open(url, data, timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 525, in open\n    response = meth(req, response)\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 634, in http_response\n    response = self.parent.error(\n               ^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 563, in error\n    return self._call_chain(*args)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n    result = func(*args)\n             ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 429: Too Many Requests"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Build a portfolio risk analyzer with multiple risk metrics",
    "code_form": "analyzer class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you create a class that implements a portfolio risk analyzer with methods that accept and return specific types, calculating key risk metrics like VaR, CVaR, and the Sharpe Ratio for a portfolio of stocks?",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nfrom typing import Tuple, List\n\nclass PortfolioRiskAnalyzer:\n    \"\"\"\n    A class to analyze the risk of a financial portfolio using multiple risk metrics.\n    \"\"\"\n\n    def __init__(self, tickers: List[str], weights: List[float]) -> None:\n        \"\"\"\n        Initializes the PortfolioRiskAnalyzer with given stock tickers and their respective weights.\n        \n        :param tickers: A list of stock tickers (e.g., ['AAPL', 'MSFT', 'AMZN']).\n        :param weights: A list of weights corresponding to each stock in the portfolio.\n        \"\"\"\n        self.tickers = tickers\n        self.weights = weights\n        self.prices = self._fetch_price_data()\n        self.returns = self.prices.pct_change().dropna()\n\n    def _fetch_price_data(self) -> pd.DataFrame:\n        \"\"\"\n        Fetches historical price data for the specified tickers from Yahoo Finance.\n        \n        :return: A DataFrame containing the closing prices of the stocks.\n        \"\"\"\n        price_data = pd.DataFrame()\n        for ticker in self.tickers:\n            price_data[ticker] = pd.read_csv(f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1=1622505600&period2=1654041600&interval=1d&events=history')['Close']\n        return price_data\n\n    def portfolio_return(self) -> np.ndarray:\n        \"\"\"\n        Calculates the portfolio return based on the weights and stock returns.\n        \n        :return: The calculated portfolio returns as a NumPy array.\n        \"\"\"\n        return np.dot(self.weights, self.returns.T)\n\n    def calculate_risk_metrics(self, returns: np.ndarray) -> Tuple[float, float, float]:\n        \"\"\"\n        Calculates key risk metrics: Value at Risk (VaR), Conditional Value at Risk (CVaR), and Sharpe Ratio.\n        \n        :param returns: The portfolio returns as a NumPy array.\n        :return: A tuple containing VaR, CVaR, and Sharpe Ratio.\n        \"\"\"\n        mean_return = np.mean(returns)\n        volatility = np.std(returns)\n        VaR = np.percentile(returns, 5)\n        CVaR = returns[returns <= VaR].mean()\n        sharpe_ratio = mean_return / volatility\n        return VaR, CVaR, sharpe_ratio\n\n    def analyze(self) -> None:\n        \"\"\"\n        Conducts the analysis and prints the risk metrics.\n        \"\"\"\n        portfolio_ret = self.portfolio_return()\n        VaR, CVaR, sharpe_ratio = self.calculate_risk_metrics(portfolio_ret)\n        print('Value at Risk:', VaR)\n        print('Conditional Value at Risk:', CVaR)\n        print('Sharpe Ratio:', sharpe_ratio)\n\n# Example usage:\nif __name__ == '__main__':\n    analyzer = PortfolioRiskAnalyzer(tickers=['AAPL', 'MSFT', 'AMZN'], weights=[0.4, 0.4, 0.2])\n    analyzer.analyze()",
    "rejected_code": "import pandas as pd\nimport numpy as np\nyf = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/AAPL?period1=1622505600&period2=1654041600&interval=1d&events=history')\nmsft = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/MSFT?period1=1622505600&period2=1654041600&interval=1d&events=history')\namzn = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/AMZN?period1=1622505600&period2=1654041600&interval=1d&events=history')\n\ndef portfolio_return(weights, returns):\n    return np.dot(weights, returns)\n\ndef calculate_risk_metrics(returns):\n    mean_return = np.mean(returns)\n    volatility = np.std(returns)\n    VaR = np.percentile(returns, 5)\n    CVaR = returns[returns <= VaR].mean()\n    sharpe_ratio = mean_return / volatility\n    return VaR, CVaR, sharpe_ratio\n\nprices = pd.DataFrame()\nprices['AAPL'] = yf['Close']\nprices['MSFT'] = msft['Close']\nprices['AMZN'] = amzn['Close']\n\nreturns = prices.pct_change().dropna()\nweights = np.array([0.4, 0.4, 0.2])\n\nportfolio_ret = portfolio_return(weights, returns.T)\nVaR, CVaR, sharpe_ratio = calculate_risk_metrics(portfolio_ret)\n\nprint('Value at Risk:', VaR)\nprint('Conditional Value at Risk:', CVaR)\nprint('Sharpe Ratio:', sharpe_ratio)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.014705882352941176,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 67, in <module>\n  File \"<string>\", line 19, in __init__\n  File \"<string>\", line 30, in _fetch_price_data\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 728, in get_handle\n    ioargs = _get_filepath_or_buffer(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 384, in _get_filepath_or_buffer\n    with urlopen(req_info) as req:\n         ^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 289, in urlopen\n    return urllib.request.urlopen(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 216, in urlopen\n    return opener.open(url, data, timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 525, in open\n    response = meth(req, response)\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 634, in http_response\n    response = self.parent.error(\n               ^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 563, in error\n    return self._call_chain(*args)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n    result = func(*args)\n             ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 429: Too Many Requests"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 728, in get_handle\n    ioargs = _get_filepath_or_buffer(\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 384, in _get_filepath_or_buffer\n    with urlopen(req_info) as req:\n         ^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 289, in urlopen\n    return urllib.request.urlopen(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 216, in urlopen\n    return opener.open(url, data, timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 525, in open\n    response = meth(req, response)\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 634, in http_response\n    response = self.parent.error(\n               ^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 563, in error\n    return self._call_chain(*args)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n    result = func(*args)\n             ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 429: Too Many Requests"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Develop a financial ratio analysis function with industry comparisons",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code for financial ratio analysis with industry comparisons?",
      "role": "user"
    },
    "chosen_code": "import yfinance as yf\nfrom typing import List, Dict, Optional\n\n# Industry average financial ratios for comparison\nindustry_avg_ratios: Dict[str, float] = {'P/E': 25.0, 'Debt-to-Equity': 0.5, 'Current Ratio': 1.5}\n\ndef financial_ratio_analysis(tickers: List[str]) -> Dict[str, Dict[str, Optional[float]]]:\n    \"\"\"\n    Analyzes financial ratios for a list of stock tickers.\n\n    Args:\n        tickers (List[str]): A list of stock ticker symbols.\n\n    Returns:\n        Dict[str, Dict[str, Optional[float]]]: A dictionary where each key is a ticker symbol and the value is a dictionary of financial ratios.\n    \"\"\"\n    ratios: Dict[str, Dict[str, Optional[float]]] = {}\n    for ticker in tickers:\n        stock = yf.Ticker(ticker)\n        info = stock.info\n        ratios[ticker] = {\n            'P/E': info.get('forwardPE'),\n            'Debt-to-Equity': info.get('debtToEquity'),\n            'Current Ratio': info.get('currentRatio')\n        }\n    return ratios\n\n\ndef compare_ratios_to_industry(ratios: Dict[str, Dict[str, Optional[float]]]) -> Dict[str, Dict[str, bool]]:\n    \"\"\"\n    Compares the financial ratios of the provided tickers against industry averages.\n\n    Args:\n        ratios (Dict[str, Dict[str, Optional[float]]]): A dictionary of financial ratios for various tickers.\n\n    Returns:\n        Dict[str, Dict[str, bool]]: A dictionary indicating whether each ticker's ratios are above or below the industry averages.\n    \"\"\"\n    comparison: Dict[str, Dict[str, bool]] = {}\n    for ticker, vals in ratios.items():\n        comparison[ticker] = {\n            'P/E Comparison': vals['P/E'] is not None and vals['P/E'] < industry_avg_ratios['P/E'],\n            'Debt-to-Equity Comparison': vals['Debt-to-Equity'] is not None and vals['Debt-to-Equity'] < industry_avg_ratios['Debt-to-Equity'],\n            'Current Ratio Comparison': vals['Current Ratio'] is not None and vals['Current Ratio'] > industry_avg_ratios['Current Ratio']\n        }\n    return comparison\n\n# Example usage\nif __name__ == '__main__':\n    tech_tickers: List[str] = ['AAPL', 'MSFT', 'GOOGL']\n    ratios = financial_ratio_analysis(tech_tickers)\n    comparison_results = compare_ratios_to_industry(ratios)\n    print(comparison_results)",
    "rejected_code": "import pandas as pd\nimport yfinance as yf\n\nindustry_avg_ratios = {'P/E': 25, 'Debt-to-Equity': 0.5, 'Current Ratio': 1.5}\n\ndef financial_ratio_analysis(tickers):\n    ratios = {}\n    for ticker in tickers:\n        stock = yf.Ticker(ticker)\n        info = stock.info\n        pe_ratio = info.get('forwardPE', None)\n        debt_to_equity = info.get('debtToEquity', None)\n        current_ratio = info.get('currentRatio', None)\n        ratios[ticker] = {'P/E': pe_ratio, 'Debt-to-Equity': debt_to_equity, 'Current Ratio': current_ratio}\n    return ratios\n\ndef compare_ratios_to_industry(ratios):\n    comparison = {}\n    for ticker, vals in ratios.items():\n        comparison[ticker] = {\n            'P/E Comparison': vals['P/E'] < industry_avg_ratios['P/E'],\n            'Debt-to-Equity Comparison': vals['Debt-to-Equity'] < industry_avg_ratios['Debt-to-Equity'],\n            'Current Ratio Comparison': vals['Current Ratio'] > industry_avg_ratios['Current Ratio']\n        }\n    return comparison\n\n# Example usage\ntech_tickers = ['AAPL', 'MSFT', 'GOOGL']\nratios = financial_ratio_analysis(tech_tickers)\ncomparison_results = compare_ratios_to_industry(ratios)\nprint(comparison_results)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.5,
      "pep8_compliance": null,
      "comment_density": 0.03773584905660377,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.03225806451612903,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Develop a financial ratio analysis function with industry comparisons",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a function that performs financial ratio analysis with industry comparisons in Python.",
      "role": "user"
    },
    "chosen_code": "import yfinance as yf\nfrom typing import List, Dict, Optional\n\n# Industry average financial ratios for comparison\nindustry_avg_ratios: Dict[str, float] = {'P/E': 25.0, 'Debt-to-Equity': 0.5, 'Current Ratio': 1.5}\n\ndef financial_ratio_analysis(tickers: List[str]) -> Dict[str, Dict[str, Optional[float]]]:\n    \"\"\"\n    Analyzes financial ratios for a list of stock tickers.\n\n    Args:\n        tickers (List[str]): A list of stock ticker symbols.\n\n    Returns:\n        Dict[str, Dict[str, Optional[float]]]: A dictionary where each key is a ticker symbol and the value is a dictionary of financial ratios.\n    \"\"\"\n    ratios: Dict[str, Dict[str, Optional[float]]] = {}\n    for ticker in tickers:\n        stock = yf.Ticker(ticker)\n        info = stock.info\n        ratios[ticker] = {\n            'P/E': info.get('forwardPE'),\n            'Debt-to-Equity': info.get('debtToEquity'),\n            'Current Ratio': info.get('currentRatio')\n        }\n    return ratios\n\n\ndef compare_ratios_to_industry(ratios: Dict[str, Dict[str, Optional[float]]]) -> Dict[str, Dict[str, bool]]:\n    \"\"\"\n    Compares the financial ratios of the provided tickers against industry averages.\n\n    Args:\n        ratios (Dict[str, Dict[str, Optional[float]]]): A dictionary of financial ratios for various tickers.\n\n    Returns:\n        Dict[str, Dict[str, bool]]: A dictionary indicating whether each ticker's ratios are above or below the industry averages.\n    \"\"\"\n    comparison: Dict[str, Dict[str, bool]] = {}\n    for ticker, vals in ratios.items():\n        comparison[ticker] = {\n            'P/E Comparison': vals['P/E'] is not None and vals['P/E'] < industry_avg_ratios['P/E'],\n            'Debt-to-Equity Comparison': vals['Debt-to-Equity'] is not None and vals['Debt-to-Equity'] < industry_avg_ratios['Debt-to-Equity'],\n            'Current Ratio Comparison': vals['Current Ratio'] is not None and vals['Current Ratio'] > industry_avg_ratios['Current Ratio']\n        }\n    return comparison\n\n# Example usage\nif __name__ == '__main__':\n    tech_tickers: List[str] = ['AAPL', 'MSFT', 'GOOGL']\n    ratios = financial_ratio_analysis(tech_tickers)\n    comparison_results = compare_ratios_to_industry(ratios)\n    print(comparison_results)",
    "rejected_code": "import pandas as pd\nimport yfinance as yf\n\nindustry_avg_ratios = {'P/E': 25, 'Debt-to-Equity': 0.5, 'Current Ratio': 1.5}\n\ndef financial_ratio_analysis(tickers):\n    ratios = {}\n    for ticker in tickers:\n        stock = yf.Ticker(ticker)\n        info = stock.info\n        pe_ratio = info.get('forwardPE', None)\n        debt_to_equity = info.get('debtToEquity', None)\n        current_ratio = info.get('currentRatio', None)\n        ratios[ticker] = {'P/E': pe_ratio, 'Debt-to-Equity': debt_to_equity, 'Current Ratio': current_ratio}\n    return ratios\n\ndef compare_ratios_to_industry(ratios):\n    comparison = {}\n    for ticker, vals in ratios.items():\n        comparison[ticker] = {\n            'P/E Comparison': vals['P/E'] < industry_avg_ratios['P/E'],\n            'Debt-to-Equity Comparison': vals['Debt-to-Equity'] < industry_avg_ratios['Debt-to-Equity'],\n            'Current Ratio Comparison': vals['Current Ratio'] > industry_avg_ratios['Current Ratio']\n        }\n    return comparison\n\n# Example usage\ntech_tickers = ['AAPL', 'MSFT', 'GOOGL']\nratios = financial_ratio_analysis(tech_tickers)\ncomparison_results = compare_ratios_to_industry(ratios)\nprint(comparison_results)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.5,
      "pep8_compliance": null,
      "comment_density": 0.03773584905660377,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.03225806451612903,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Develop a financial ratio analysis function with industry comparisons",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python function that takes a list of stock tickers as input and returns a comparison of financial ratios against industry averages.",
      "role": "user"
    },
    "chosen_code": "import yfinance as yf\nfrom typing import List, Dict, Optional\n\n# Industry average financial ratios for comparison\nindustry_avg_ratios: Dict[str, float] = {'P/E': 25.0, 'Debt-to-Equity': 0.5, 'Current Ratio': 1.5}\n\ndef financial_ratio_analysis(tickers: List[str]) -> Dict[str, Dict[str, Optional[float]]]:\n    \"\"\"\n    Analyzes financial ratios for a list of stock tickers.\n\n    Args:\n        tickers (List[str]): A list of stock ticker symbols.\n\n    Returns:\n        Dict[str, Dict[str, Optional[float]]]: A dictionary where each key is a ticker symbol and the value is a dictionary of financial ratios.\n    \"\"\"\n    ratios: Dict[str, Dict[str, Optional[float]]] = {}\n    for ticker in tickers:\n        stock = yf.Ticker(ticker)\n        info = stock.info\n        ratios[ticker] = {\n            'P/E': info.get('forwardPE'),\n            'Debt-to-Equity': info.get('debtToEquity'),\n            'Current Ratio': info.get('currentRatio')\n        }\n    return ratios\n\n\ndef compare_ratios_to_industry(ratios: Dict[str, Dict[str, Optional[float]]]) -> Dict[str, Dict[str, bool]]:\n    \"\"\"\n    Compares the financial ratios of the provided tickers against industry averages.\n\n    Args:\n        ratios (Dict[str, Dict[str, Optional[float]]]): A dictionary of financial ratios for various tickers.\n\n    Returns:\n        Dict[str, Dict[str, bool]]: A dictionary indicating whether each ticker's ratios are above or below the industry averages.\n    \"\"\"\n    comparison: Dict[str, Dict[str, bool]] = {}\n    for ticker, vals in ratios.items():\n        comparison[ticker] = {\n            'P/E Comparison': vals['P/E'] is not None and vals['P/E'] < industry_avg_ratios['P/E'],\n            'Debt-to-Equity Comparison': vals['Debt-to-Equity'] is not None and vals['Debt-to-Equity'] < industry_avg_ratios['Debt-to-Equity'],\n            'Current Ratio Comparison': vals['Current Ratio'] is not None and vals['Current Ratio'] > industry_avg_ratios['Current Ratio']\n        }\n    return comparison\n\n# Example usage\nif __name__ == '__main__':\n    tech_tickers: List[str] = ['AAPL', 'MSFT', 'GOOGL']\n    ratios = financial_ratio_analysis(tech_tickers)\n    comparison_results = compare_ratios_to_industry(ratios)\n    print(comparison_results)",
    "rejected_code": "import pandas as pd\nimport yfinance as yf\n\nindustry_avg_ratios = {'P/E': 25, 'Debt-to-Equity': 0.5, 'Current Ratio': 1.5}\n\ndef financial_ratio_analysis(tickers):\n    ratios = {}\n    for ticker in tickers:\n        stock = yf.Ticker(ticker)\n        info = stock.info\n        pe_ratio = info.get('forwardPE', None)\n        debt_to_equity = info.get('debtToEquity', None)\n        current_ratio = info.get('currentRatio', None)\n        ratios[ticker] = {'P/E': pe_ratio, 'Debt-to-Equity': debt_to_equity, 'Current Ratio': current_ratio}\n    return ratios\n\ndef compare_ratios_to_industry(ratios):\n    comparison = {}\n    for ticker, vals in ratios.items():\n        comparison[ticker] = {\n            'P/E Comparison': vals['P/E'] < industry_avg_ratios['P/E'],\n            'Debt-to-Equity Comparison': vals['Debt-to-Equity'] < industry_avg_ratios['Debt-to-Equity'],\n            'Current Ratio Comparison': vals['Current Ratio'] > industry_avg_ratios['Current Ratio']\n        }\n    return comparison\n\n# Example usage\ntech_tickers = ['AAPL', 'MSFT', 'GOOGL']\nratios = financial_ratio_analysis(tech_tickers)\ncomparison_results = compare_ratios_to_industry(ratios)\nprint(comparison_results)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.5,
      "pep8_compliance": null,
      "comment_density": 0.03773584905660377,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.03225806451612903,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'yfinance'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Implement a procedural terrain generation algorithm",
    "code_form": "generator function",
    "prompt_type": "default",
    "prompt": {
      "content": "Generate Python code to implement a procedural terrain generation algorithm for a 2D platformer game.",
      "role": "user"
    },
    "chosen_code": "import pygame\nfrom noise import snoise2\nfrom typing import Generator, List\n\n\ndef generate_terrain(width: int, height: int, scale: float, octaves: int, persistence: float, lacunarity: float) -> Generator[List[int], None, None]:\n    \"\"\"\n    Generates a 2D terrain using Perlin noise.\n    \n    Args:\n        width (int): The width of the terrain.\n        height (int): The height of the terrain.\n        scale (float): The scale of the noise.\n        octaves (int): The number of octaves for the noise generation.\n        persistence (float): The persistence of the noise.\n        lacunarity (float): The lacunarity of the noise.\n    \n    Yields:\n        Generator[List[int]]: A generator that yields rows of terrain height values.\n    \"\"\"\n    for x in range(width):\n        row = []\n        for y in range(height):\n            # Generate noise value and scale it to a height value\n            noise_value = snoise2(x / scale, y / scale, octaves, persistence=persistence, lacunarity=lacunarity)\n            height_value = int((noise_value + 1) * 255 / 2)\n            row.append(height_value)\n        yield row\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to initialize Pygame and run the terrain generation and display loop.\n    \"\"\"\n    pygame.init()\n    screen = pygame.display.set_mode((800, 600))\n    clock = pygame.time.Clock()\n    terrain = generate_terrain(800, 600, 100, 6, 0.5, 2.0)\n\n    running = True\n    while running:\n        screen.fill((135, 206, 250))  # Fill the screen with sky color\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                running = False\n\n        # Draw the terrain\n        for y, row in enumerate(terrain):\n            for x, height in enumerate(row):\n                pygame.draw.rect(screen, (0, height, 0), (x, 600 - height, 1, height))\n\n        pygame.display.flip()  # Update the display\n        clock.tick(60)  # Cap the frame rate at 60 FPS\n\n    pygame.quit()  # Clean up and close Pygame\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "import pygame\nimport numpy as np\nfrom noise import snoise2\n\ndef generate_terrain(width, height, scale, octaves, persistence, lacunarity):\n    for x in range(width):\n        row = []\n        for y in range(height):\n            noise_value = snoise2(x / scale, y / scale, octaves, persistence=persistence, lacunarity=lacunarity)\n            row.append(int((noise_value + 1) * 255 / 2))\n        yield row\n\npygame.init()\nscreen = pygame.display.set_mode((800, 600))\nclock = pygame.time.Clock()\nterrain = generate_terrain(800, 600, 100, 6, 0.5, 2.0)\n\nrunning = True\nwhile running:\n    screen.fill((135, 206, 250))\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n    for y, row in enumerate(terrain):\n        for x, height in enumerate(row):\n            pygame.draw.rect(screen, (0, height, 0), (x, 600-height, 1, height))\n    pygame.display.flip()\n    clock.tick(60)\npygame.quit()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.5,
      "pep8_compliance": null,
      "comment_density": 0.03389830508474576,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Implement a procedural terrain generation algorithm",
    "code_form": "generator function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a function in Python that generates procedural terrain for a 2D platformer game.",
      "role": "user"
    },
    "chosen_code": "import pygame\nfrom noise import snoise2\nfrom typing import Generator, List\n\n\ndef generate_terrain(width: int, height: int, scale: float, octaves: int, persistence: float, lacunarity: float) -> Generator[List[int], None, None]:\n    \"\"\"\n    Generates a 2D terrain using Perlin noise.\n    \n    Args:\n        width (int): The width of the terrain.\n        height (int): The height of the terrain.\n        scale (float): The scale of the noise.\n        octaves (int): The number of octaves for the noise generation.\n        persistence (float): The persistence of the noise.\n        lacunarity (float): The lacunarity of the noise.\n    \n    Yields:\n        Generator[List[int]]: A generator that yields rows of terrain height values.\n    \"\"\"\n    for x in range(width):\n        row = []\n        for y in range(height):\n            # Generate noise value and scale it to a height value\n            noise_value = snoise2(x / scale, y / scale, octaves, persistence=persistence, lacunarity=lacunarity)\n            height_value = int((noise_value + 1) * 255 / 2)\n            row.append(height_value)\n        yield row\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to initialize Pygame and run the terrain generation and display loop.\n    \"\"\"\n    pygame.init()\n    screen = pygame.display.set_mode((800, 600))\n    clock = pygame.time.Clock()\n    terrain = generate_terrain(800, 600, 100, 6, 0.5, 2.0)\n\n    running = True\n    while running:\n        screen.fill((135, 206, 250))  # Fill the screen with sky color\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                running = False\n\n        # Draw the terrain\n        for y, row in enumerate(terrain):\n            for x, height in enumerate(row):\n                pygame.draw.rect(screen, (0, height, 0), (x, 600 - height, 1, height))\n\n        pygame.display.flip()  # Update the display\n        clock.tick(60)  # Cap the frame rate at 60 FPS\n\n    pygame.quit()  # Clean up and close Pygame\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "import pygame\nimport numpy as np\nfrom noise import snoise2\n\ndef generate_terrain(width, height, scale, octaves, persistence, lacunarity):\n    for x in range(width):\n        row = []\n        for y in range(height):\n            noise_value = snoise2(x / scale, y / scale, octaves, persistence=persistence, lacunarity=lacunarity)\n            row.append(int((noise_value + 1) * 255 / 2))\n        yield row\n\npygame.init()\nscreen = pygame.display.set_mode((800, 600))\nclock = pygame.time.Clock()\nterrain = generate_terrain(800, 600, 100, 6, 0.5, 2.0)\n\nrunning = True\nwhile running:\n    screen.fill((135, 206, 250))\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n    for y, row in enumerate(terrain):\n        for x, height in enumerate(row):\n            pygame.draw.rect(screen, (0, height, 0), (x, 600-height, 1, height))\n    pygame.display.flip()\n    clock.tick(60)\npygame.quit()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.5,
      "pep8_compliance": null,
      "comment_density": 0.03389830508474576,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Implement a procedural terrain generation algorithm",
    "code_form": "generator function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python function that generates procedural terrain for a 2D platformer game, with specified input types: width (int), height (int), scale (float), octaves (int), persistence (float), lacunarity (float), and output type as a generator of lists of integers.",
      "role": "user"
    },
    "chosen_code": "import pygame\nfrom noise import snoise2\nfrom typing import Generator, List\n\n\ndef generate_terrain(width: int, height: int, scale: float, octaves: int, persistence: float, lacunarity: float) -> Generator[List[int], None, None]:\n    \"\"\"\n    Generates a 2D terrain using Perlin noise.\n    \n    Args:\n        width (int): The width of the terrain.\n        height (int): The height of the terrain.\n        scale (float): The scale of the noise.\n        octaves (int): The number of octaves for the noise generation.\n        persistence (float): The persistence of the noise.\n        lacunarity (float): The lacunarity of the noise.\n    \n    Yields:\n        Generator[List[int]]: A generator that yields rows of terrain height values.\n    \"\"\"\n    for x in range(width):\n        row = []\n        for y in range(height):\n            # Generate noise value and scale it to a height value\n            noise_value = snoise2(x / scale, y / scale, octaves, persistence=persistence, lacunarity=lacunarity)\n            height_value = int((noise_value + 1) * 255 / 2)\n            row.append(height_value)\n        yield row\n\n\ndef main() -> None:\n    \"\"\"\n    Main function to initialize Pygame and run the terrain generation and display loop.\n    \"\"\"\n    pygame.init()\n    screen = pygame.display.set_mode((800, 600))\n    clock = pygame.time.Clock()\n    terrain = generate_terrain(800, 600, 100, 6, 0.5, 2.0)\n\n    running = True\n    while running:\n        screen.fill((135, 206, 250))  # Fill the screen with sky color\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT:\n                running = False\n\n        # Draw the terrain\n        for y, row in enumerate(terrain):\n            for x, height in enumerate(row):\n                pygame.draw.rect(screen, (0, height, 0), (x, 600 - height, 1, height))\n\n        pygame.display.flip()  # Update the display\n        clock.tick(60)  # Cap the frame rate at 60 FPS\n\n    pygame.quit()  # Clean up and close Pygame\n\n\nif __name__ == '__main__':\n    main()",
    "rejected_code": "import pygame\nimport numpy as np\nfrom noise import snoise2\n\ndef generate_terrain(width, height, scale, octaves, persistence, lacunarity):\n    for x in range(width):\n        row = []\n        for y in range(height):\n            noise_value = snoise2(x / scale, y / scale, octaves, persistence=persistence, lacunarity=lacunarity)\n            row.append(int((noise_value + 1) * 255 / 2))\n        yield row\n\npygame.init()\nscreen = pygame.display.set_mode((800, 600))\nclock = pygame.time.Clock()\nterrain = generate_terrain(800, 600, 100, 6, 0.5, 2.0)\n\nrunning = True\nwhile running:\n    screen.fill((135, 206, 250))\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n    for y, row in enumerate(terrain):\n        for x, height in enumerate(row):\n            pygame.draw.rect(screen, (0, height, 0), (x, 600-height, 1, height))\n    pygame.display.flip()\n    clock.tick(60)\npygame.quit()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 4.5,
      "pep8_compliance": null,
      "comment_density": 0.03389830508474576,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Build a game state management class with save/load functionality",
    "code_form": "state manager class",
    "prompt_type": "default",
    "prompt": {
      "content": "Generate Python code for a game state management class with save/load functionality.",
      "role": "user"
    },
    "chosen_code": "import json\nfrom typing import Dict, Tuple\nimport pygame\n\nclass GameStateManager:\n    \"\"\"\n    A class to manage the game state, including saving and loading functionality.\n    The game state consists of the current level, score, and player position.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the game state with default values.\n        \"\"\"\n        self.state: Dict[str, int] = {\n            'level': 1,\n            'score': 0,\n            'player_position': (0, 0)\n        }\n\n    def save_state(self, filename: str) -> None:\n        \"\"\"\n        Save the current game state to a file in JSON format.\n        \n        :param filename: The name of the file to save the state to.\n        \"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.state, f)\n\n    def load_state(self, filename: str) -> None:\n        \"\"\"\n        Load the game state from a file in JSON format.\n        \n        :param filename: The name of the file to load the state from.\n        \"\"\"\n        with open(filename, 'r') as f:\n            self.state = json.load(f)\n\n    def update_state(self, level: int, score: int, player_position: Tuple[int, int]) -> None:\n        \"\"\"\n        Update the game state with new values.\n        \n        :param level: The current level of the game.\n        :param score: The current score of the player.\n        :param player_position: The current position of the player as a tuple (x, y).\n        \"\"\"\n        self.state['level'] = level\n        self.state['score'] = score\n        self.state['player_position'] = player_position\n\n    def get_state(self) -> Dict[str, int]:\n        \"\"\"\n        Get the current game state.\n        \n        :return: The current state of the game as a dictionary.\n        \"\"\"\n        return self.state\n\n# Initialize Pygame\npygame.init()\n\n# Create an instance of the GameStateManager\nstate_manager = GameStateManager()\n\n# Update the game state\nstate_manager.update_state(2, 100, (50, 150))\n\n# Save the current state to a file\nstate_manager.save_state('savefile.json')\n\n# Load the state from the file\nstate_manager.load_state('savefile.json')\n\n# Print the current state\nprint(state_manager.get_state())",
    "rejected_code": "import json\nimport pygame\n\nclass GameStateManager:\n    def __init__(self):\n        self.state = {\n            'level': 1,\n            'score': 0,\n            'player_position': (0, 0)\n        }\n\n    def save_state(self, filename):\n        with open(filename, 'w') as f:\n            json.dump(self.state, f)\n\n    def load_state(self, filename):\n        with open(filename, 'r') as f:\n            self.state = json.load(f)\n\n    def update_state(self, level, score, player_position):\n        self.state['level'] = level\n        self.state['score'] = score\n        self.state['player_position'] = player_position\n\n    def get_state(self):\n        return self.state\n\npygame.init()\nstate_manager = GameStateManager()\nstate_manager.update_state(2, 100, (50, 150))\nstate_manager.save_state('savefile.json')\nstate_manager.load_state('savefile.json')\nprint(state_manager.get_state())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.08,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Build a game state management class with save/load functionality",
    "code_form": "state manager class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a Python class that implements a game state management system with save and load capabilities.",
      "role": "user"
    },
    "chosen_code": "import json\nfrom typing import Dict, Tuple\nimport pygame\n\nclass GameStateManager:\n    \"\"\"\n    A class to manage the game state, including saving and loading functionality.\n    The game state consists of the current level, score, and player position.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the game state with default values.\n        \"\"\"\n        self.state: Dict[str, int] = {\n            'level': 1,\n            'score': 0,\n            'player_position': (0, 0)\n        }\n\n    def save_state(self, filename: str) -> None:\n        \"\"\"\n        Save the current game state to a file in JSON format.\n        \n        :param filename: The name of the file to save the state to.\n        \"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.state, f)\n\n    def load_state(self, filename: str) -> None:\n        \"\"\"\n        Load the game state from a file in JSON format.\n        \n        :param filename: The name of the file to load the state from.\n        \"\"\"\n        with open(filename, 'r') as f:\n            self.state = json.load(f)\n\n    def update_state(self, level: int, score: int, player_position: Tuple[int, int]) -> None:\n        \"\"\"\n        Update the game state with new values.\n        \n        :param level: The current level of the game.\n        :param score: The current score of the player.\n        :param player_position: The current position of the player as a tuple (x, y).\n        \"\"\"\n        self.state['level'] = level\n        self.state['score'] = score\n        self.state['player_position'] = player_position\n\n    def get_state(self) -> Dict[str, int]:\n        \"\"\"\n        Get the current game state.\n        \n        :return: The current state of the game as a dictionary.\n        \"\"\"\n        return self.state\n\n# Initialize Pygame\npygame.init()\n\n# Create an instance of the GameStateManager\nstate_manager = GameStateManager()\n\n# Update the game state\nstate_manager.update_state(2, 100, (50, 150))\n\n# Save the current state to a file\nstate_manager.save_state('savefile.json')\n\n# Load the state from the file\nstate_manager.load_state('savefile.json')\n\n# Print the current state\nprint(state_manager.get_state())",
    "rejected_code": "import json\nimport pygame\n\nclass GameStateManager:\n    def __init__(self):\n        self.state = {\n            'level': 1,\n            'score': 0,\n            'player_position': (0, 0)\n        }\n\n    def save_state(self, filename):\n        with open(filename, 'w') as f:\n            json.dump(self.state, f)\n\n    def load_state(self, filename):\n        with open(filename, 'r') as f:\n            self.state = json.load(f)\n\n    def update_state(self, level, score, player_position):\n        self.state['level'] = level\n        self.state['score'] = score\n        self.state['player_position'] = player_position\n\n    def get_state(self):\n        return self.state\n\npygame.init()\nstate_manager = GameStateManager()\nstate_manager.update_state(2, 100, (50, 150))\nstate_manager.save_state('savefile.json')\nstate_manager.load_state('savefile.json')\nprint(state_manager.get_state())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.08,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Build a game state management class with save/load functionality",
    "code_form": "state manager class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python class with defined input/output types for a game state manager that can save and load game state.",
      "role": "user"
    },
    "chosen_code": "import json\nfrom typing import Dict, Tuple\nimport pygame\n\nclass GameStateManager:\n    \"\"\"\n    A class to manage the game state, including saving and loading functionality.\n    The game state consists of the current level, score, and player position.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the game state with default values.\n        \"\"\"\n        self.state: Dict[str, int] = {\n            'level': 1,\n            'score': 0,\n            'player_position': (0, 0)\n        }\n\n    def save_state(self, filename: str) -> None:\n        \"\"\"\n        Save the current game state to a file in JSON format.\n        \n        :param filename: The name of the file to save the state to.\n        \"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.state, f)\n\n    def load_state(self, filename: str) -> None:\n        \"\"\"\n        Load the game state from a file in JSON format.\n        \n        :param filename: The name of the file to load the state from.\n        \"\"\"\n        with open(filename, 'r') as f:\n            self.state = json.load(f)\n\n    def update_state(self, level: int, score: int, player_position: Tuple[int, int]) -> None:\n        \"\"\"\n        Update the game state with new values.\n        \n        :param level: The current level of the game.\n        :param score: The current score of the player.\n        :param player_position: The current position of the player as a tuple (x, y).\n        \"\"\"\n        self.state['level'] = level\n        self.state['score'] = score\n        self.state['player_position'] = player_position\n\n    def get_state(self) -> Dict[str, int]:\n        \"\"\"\n        Get the current game state.\n        \n        :return: The current state of the game as a dictionary.\n        \"\"\"\n        return self.state\n\n# Initialize Pygame\npygame.init()\n\n# Create an instance of the GameStateManager\nstate_manager = GameStateManager()\n\n# Update the game state\nstate_manager.update_state(2, 100, (50, 150))\n\n# Save the current state to a file\nstate_manager.save_state('savefile.json')\n\n# Load the state from the file\nstate_manager.load_state('savefile.json')\n\n# Print the current state\nprint(state_manager.get_state())",
    "rejected_code": "import json\nimport pygame\n\nclass GameStateManager:\n    def __init__(self):\n        self.state = {\n            'level': 1,\n            'score': 0,\n            'player_position': (0, 0)\n        }\n\n    def save_state(self, filename):\n        with open(filename, 'w') as f:\n            json.dump(self.state, f)\n\n    def load_state(self, filename):\n        with open(filename, 'r') as f:\n            self.state = json.load(f)\n\n    def update_state(self, level, score, player_position):\n        self.state['level'] = level\n        self.state['score'] = score\n        self.state['player_position'] = player_position\n\n    def get_state(self):\n        return self.state\n\npygame.init()\nstate_manager = GameStateManager()\nstate_manager.update_state(2, 100, (50, 150))\nstate_manager.save_state('savefile.json')\nstate_manager.load_state('savefile.json')\nprint(state_manager.get_state())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.08,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Create an options pricing class with different models",
    "code_form": "calculator class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create an options pricing class that implements different models for estimating the fair value of European call and put options?",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport scipy.stats as si\nfrom typing import Literal, Union\n\nclass OptionsPricing:\n    \"\"\"\n    A class to price European call and put options using different models.\n    This class implements the Black-Scholes model and the Binomial model.\n\n    Attributes:\n        S (float): Current stock price.\n        K (float): Option strike price.\n        T (float): Time to expiration in years.\n        r (float): Risk-free interest rate.\n        sigma (float): Volatility of the underlying asset.\n    \"\"\"\n\n    def __init__(self, S: float, K: float, T: float, r: float, sigma: float) -> None:\n        \"\"\"Initialize the option pricing model with required parameters.\"\"\"\n        self.S = S  # Current stock price\n        self.K = K  # Strike price\n        self.T = T  # Time to expiration\n        self.r = r  # Risk-free rate\n        self.sigma = sigma  # Volatility\n\n    def black_scholes_call(self) -> float:\n        \"\"\"Calculate the Black-Scholes price for a call option.\"\"\"\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        call_price = (self.S * si.norm.cdf(d1) - self.K * np.exp(-self.r * self.T) * si.norm.cdf(d2))\n        return call_price\n\n    def black_scholes_put(self) -> float:\n        \"\"\"Calculate the Black-Scholes price for a put option.\"\"\"\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        put_price = (self.K * np.exp(-self.r * self.T) * si.norm.cdf(-d2) - self.S * si.norm.cdf(-d1))\n        return put_price\n\n    def binomial_model(self, N: int, option_type: Literal['call', 'put'] = 'call') -> float:\n        \"\"\"Calculate the option price using the Binomial model.\n\n        Args:\n            N (int): Number of time steps in the binomial model.\n            option_type (Literal['call', 'put']): Type of option to price.\n\n        Returns:\n            float: The price of the option as per the Binomial model.\n        \"\"\"\n        dt = self.T / N  # Time step\n        u = np.exp(self.sigma * np.sqrt(dt))  # Up factor\n        d = 1 / u  # Down factor\n        p = (np.exp(self.r * dt) - d) / (u - d)  # Risk-neutral probability\n\n        # Initialize stock price array\n        stock_price = np.zeros(N + 1)\n        stock_price[0] = self.S * (d ** N)\n        for i in range(1, N + 1):\n            stock_price[i] = stock_price[i - 1] * (u / d)\n\n        # Initialize option price array\n        option_price = np.zeros(N + 1)\n        if option_type == 'call':\n            option_price = np.maximum(0, stock_price - self.K)\n        else:\n            option_price = np.maximum(0, self.K - stock_price)\n\n        # Backward induction to calculate option price\n        for j in range(N - 1, -1, -1):\n            option_price[j] = np.exp(-self.r * dt) * (p * option_price[j + 1] + (1 - p) * option_price[j])\n\n        return option_price[0]  # Price of the option at time 0\n\n# Example usage:\n# op = OptionsPricing(S=100, K=100, T=1, r=0.05, sigma=0.2)\n# print(op.black_scholes_call())\n# print(op.black_scholes_put())\n# print(op.binomial_model(N=100, option_type='call'))",
    "rejected_code": "import numpy as np\nimport scipy.stats as si\n\nclass OptionsPricing:\n    def __init__(self, S, K, T, r, sigma):\n        self.S = S\n        self.K = K\n        self.T = T\n        self.r = r\n        self.sigma = sigma\n\n    def black_scholes_call(self):\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        call_price = (self.S * si.norm.cdf(d1, 0.0, 1.0) - self.K * np.exp(-self.r * self.T) * si.norm.cdf(d2, 0.0, 1.0))\n        return call_price\n\n    def black_scholes_put(self):\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        put_price = (self.K * np.exp(-self.r * self.T) * si.norm.cdf(-d2, 0.0, 1.0) - self.S * si.norm.cdf(-d1, 0.0, 1.0))\n        return put_price\n\n    def binomial_model(self, N, option_type='call'):\n        dt = self.T / N\n        u = np.exp(self.sigma * np.sqrt(dt))\n        d = 1 / u\n        p = (np.exp(self.r * dt) - d) / (u - d)\n        stock_price = np.zeros(N + 1)\n        stock_price[0] = self.S * (d ** N)\n        for i in range(1, N + 1):\n            stock_price[i] = stock_price[i - 1] * (u / d)\n        option_price = np.zeros(N + 1)\n        if option_type == 'call':\n            option_price = np.maximum(0, stock_price - self.K)\n        else:\n            option_price = np.maximum(0, self.K - stock_price)\n        for j in range(N - 1, -1, -1):\n            option_price[j] = np.exp(-self.r * dt) * (p * option_price[j + 1] + (1 - p) * option_price[j])\n        return option_price[0]\n\n# Example usage:\n# op = OptionsPricing(S=100, K=100, T=1, r=0.05, sigma=0.2)\n# print(op.black_scholes_call())\n# print(op.black_scholes_put())\n# print(op.binomial_model(N=100, option_type='call'))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.10256410256410256,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.10869565217391304,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Create an options pricing class with different models",
    "code_form": "calculator class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python class that implements an options pricing model for European call and put options using the Black-Scholes and Binomial models.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport scipy.stats as si\nfrom typing import Literal, Union\n\nclass OptionsPricing:\n    \"\"\"\n    A class to price European call and put options using different models.\n    This class implements the Black-Scholes model and the Binomial model.\n\n    Attributes:\n        S (float): Current stock price.\n        K (float): Option strike price.\n        T (float): Time to expiration in years.\n        r (float): Risk-free interest rate.\n        sigma (float): Volatility of the underlying asset.\n    \"\"\"\n\n    def __init__(self, S: float, K: float, T: float, r: float, sigma: float) -> None:\n        \"\"\"Initialize the option pricing model with required parameters.\"\"\"\n        self.S = S  # Current stock price\n        self.K = K  # Strike price\n        self.T = T  # Time to expiration\n        self.r = r  # Risk-free rate\n        self.sigma = sigma  # Volatility\n\n    def black_scholes_call(self) -> float:\n        \"\"\"Calculate the Black-Scholes price for a call option.\"\"\"\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        call_price = (self.S * si.norm.cdf(d1) - self.K * np.exp(-self.r * self.T) * si.norm.cdf(d2))\n        return call_price\n\n    def black_scholes_put(self) -> float:\n        \"\"\"Calculate the Black-Scholes price for a put option.\"\"\"\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        put_price = (self.K * np.exp(-self.r * self.T) * si.norm.cdf(-d2) - self.S * si.norm.cdf(-d1))\n        return put_price\n\n    def binomial_model(self, N: int, option_type: Literal['call', 'put'] = 'call') -> float:\n        \"\"\"Calculate the option price using the Binomial model.\n\n        Args:\n            N (int): Number of time steps in the binomial model.\n            option_type (Literal['call', 'put']): Type of option to price.\n\n        Returns:\n            float: The price of the option as per the Binomial model.\n        \"\"\"\n        dt = self.T / N  # Time step\n        u = np.exp(self.sigma * np.sqrt(dt))  # Up factor\n        d = 1 / u  # Down factor\n        p = (np.exp(self.r * dt) - d) / (u - d)  # Risk-neutral probability\n\n        # Initialize stock price array\n        stock_price = np.zeros(N + 1)\n        stock_price[0] = self.S * (d ** N)\n        for i in range(1, N + 1):\n            stock_price[i] = stock_price[i - 1] * (u / d)\n\n        # Initialize option price array\n        option_price = np.zeros(N + 1)\n        if option_type == 'call':\n            option_price = np.maximum(0, stock_price - self.K)\n        else:\n            option_price = np.maximum(0, self.K - stock_price)\n\n        # Backward induction to calculate option price\n        for j in range(N - 1, -1, -1):\n            option_price[j] = np.exp(-self.r * dt) * (p * option_price[j + 1] + (1 - p) * option_price[j])\n\n        return option_price[0]  # Price of the option at time 0\n\n# Example usage:\n# op = OptionsPricing(S=100, K=100, T=1, r=0.05, sigma=0.2)\n# print(op.black_scholes_call())\n# print(op.black_scholes_put())\n# print(op.binomial_model(N=100, option_type='call'))",
    "rejected_code": "import numpy as np\nimport scipy.stats as si\n\nclass OptionsPricing:\n    def __init__(self, S, K, T, r, sigma):\n        self.S = S\n        self.K = K\n        self.T = T\n        self.r = r\n        self.sigma = sigma\n\n    def black_scholes_call(self):\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        call_price = (self.S * si.norm.cdf(d1, 0.0, 1.0) - self.K * np.exp(-self.r * self.T) * si.norm.cdf(d2, 0.0, 1.0))\n        return call_price\n\n    def black_scholes_put(self):\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        put_price = (self.K * np.exp(-self.r * self.T) * si.norm.cdf(-d2, 0.0, 1.0) - self.S * si.norm.cdf(-d1, 0.0, 1.0))\n        return put_price\n\n    def binomial_model(self, N, option_type='call'):\n        dt = self.T / N\n        u = np.exp(self.sigma * np.sqrt(dt))\n        d = 1 / u\n        p = (np.exp(self.r * dt) - d) / (u - d)\n        stock_price = np.zeros(N + 1)\n        stock_price[0] = self.S * (d ** N)\n        for i in range(1, N + 1):\n            stock_price[i] = stock_price[i - 1] * (u / d)\n        option_price = np.zeros(N + 1)\n        if option_type == 'call':\n            option_price = np.maximum(0, stock_price - self.K)\n        else:\n            option_price = np.maximum(0, self.K - stock_price)\n        for j in range(N - 1, -1, -1):\n            option_price[j] = np.exp(-self.r * dt) * (p * option_price[j + 1] + (1 - p) * option_price[j])\n        return option_price[0]\n\n# Example usage:\n# op = OptionsPricing(S=100, K=100, T=1, r=0.05, sigma=0.2)\n# print(op.black_scholes_call())\n# print(op.black_scholes_put())\n# print(op.binomial_model(N=100, option_type='call'))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.10256410256410256,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.10869565217391304,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "finance and economics",
    "task": "Create an options pricing class with different models",
    "code_form": "calculator class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python class with specified input types and return types that implements options pricing models for European call and put options using the Black-Scholes and Binomial methods.",
      "role": "user"
    },
    "chosen_code": "import numpy as np\nimport scipy.stats as si\nfrom typing import Literal, Union\n\nclass OptionsPricing:\n    \"\"\"\n    A class to price European call and put options using different models.\n    This class implements the Black-Scholes model and the Binomial model.\n\n    Attributes:\n        S (float): Current stock price.\n        K (float): Option strike price.\n        T (float): Time to expiration in years.\n        r (float): Risk-free interest rate.\n        sigma (float): Volatility of the underlying asset.\n    \"\"\"\n\n    def __init__(self, S: float, K: float, T: float, r: float, sigma: float) -> None:\n        \"\"\"Initialize the option pricing model with required parameters.\"\"\"\n        self.S = S  # Current stock price\n        self.K = K  # Strike price\n        self.T = T  # Time to expiration\n        self.r = r  # Risk-free rate\n        self.sigma = sigma  # Volatility\n\n    def black_scholes_call(self) -> float:\n        \"\"\"Calculate the Black-Scholes price for a call option.\"\"\"\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        call_price = (self.S * si.norm.cdf(d1) - self.K * np.exp(-self.r * self.T) * si.norm.cdf(d2))\n        return call_price\n\n    def black_scholes_put(self) -> float:\n        \"\"\"Calculate the Black-Scholes price for a put option.\"\"\"\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        put_price = (self.K * np.exp(-self.r * self.T) * si.norm.cdf(-d2) - self.S * si.norm.cdf(-d1))\n        return put_price\n\n    def binomial_model(self, N: int, option_type: Literal['call', 'put'] = 'call') -> float:\n        \"\"\"Calculate the option price using the Binomial model.\n\n        Args:\n            N (int): Number of time steps in the binomial model.\n            option_type (Literal['call', 'put']): Type of option to price.\n\n        Returns:\n            float: The price of the option as per the Binomial model.\n        \"\"\"\n        dt = self.T / N  # Time step\n        u = np.exp(self.sigma * np.sqrt(dt))  # Up factor\n        d = 1 / u  # Down factor\n        p = (np.exp(self.r * dt) - d) / (u - d)  # Risk-neutral probability\n\n        # Initialize stock price array\n        stock_price = np.zeros(N + 1)\n        stock_price[0] = self.S * (d ** N)\n        for i in range(1, N + 1):\n            stock_price[i] = stock_price[i - 1] * (u / d)\n\n        # Initialize option price array\n        option_price = np.zeros(N + 1)\n        if option_type == 'call':\n            option_price = np.maximum(0, stock_price - self.K)\n        else:\n            option_price = np.maximum(0, self.K - stock_price)\n\n        # Backward induction to calculate option price\n        for j in range(N - 1, -1, -1):\n            option_price[j] = np.exp(-self.r * dt) * (p * option_price[j + 1] + (1 - p) * option_price[j])\n\n        return option_price[0]  # Price of the option at time 0\n\n# Example usage:\n# op = OptionsPricing(S=100, K=100, T=1, r=0.05, sigma=0.2)\n# print(op.black_scholes_call())\n# print(op.black_scholes_put())\n# print(op.binomial_model(N=100, option_type='call'))",
    "rejected_code": "import numpy as np\nimport scipy.stats as si\n\nclass OptionsPricing:\n    def __init__(self, S, K, T, r, sigma):\n        self.S = S\n        self.K = K\n        self.T = T\n        self.r = r\n        self.sigma = sigma\n\n    def black_scholes_call(self):\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        call_price = (self.S * si.norm.cdf(d1, 0.0, 1.0) - self.K * np.exp(-self.r * self.T) * si.norm.cdf(d2, 0.0, 1.0))\n        return call_price\n\n    def black_scholes_put(self):\n        d1 = (np.log(self.S / self.K) + (self.r + 0.5 * self.sigma ** 2) * self.T) / (self.sigma * np.sqrt(self.T))\n        d2 = d1 - self.sigma * np.sqrt(self.T)\n        put_price = (self.K * np.exp(-self.r * self.T) * si.norm.cdf(-d2, 0.0, 1.0) - self.S * si.norm.cdf(-d1, 0.0, 1.0))\n        return put_price\n\n    def binomial_model(self, N, option_type='call'):\n        dt = self.T / N\n        u = np.exp(self.sigma * np.sqrt(dt))\n        d = 1 / u\n        p = (np.exp(self.r * dt) - d) / (u - d)\n        stock_price = np.zeros(N + 1)\n        stock_price[0] = self.S * (d ** N)\n        for i in range(1, N + 1):\n            stock_price[i] = stock_price[i - 1] * (u / d)\n        option_price = np.zeros(N + 1)\n        if option_type == 'call':\n            option_price = np.maximum(0, stock_price - self.K)\n        else:\n            option_price = np.maximum(0, self.K - stock_price)\n        for j in range(N - 1, -1, -1):\n            option_price[j] = np.exp(-self.r * dt) * (p * option_price[j + 1] + (1 - p) * option_price[j])\n        return option_price[0]\n\n# Example usage:\n# op = OptionsPricing(S=100, K=100, T=1, r=0.05, sigma=0.2)\n# print(op.black_scholes_call())\n# print(op.black_scholes_put())\n# print(op.binomial_model(N=100, option_type='call'))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.10256410256410256,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.10869565217391304,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Create a physics-based collision detection system",
    "code_form": "physics class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code for a physics-based collision detection system in a simple 2D space shooter game.",
      "role": "user"
    },
    "chosen_code": "import pygame\nimport random\nfrom typing import List\n\npygame.init()\n\n# Set up the game window dimensions\nSCREEN_WIDTH: int = 800\nSCREEN_HEIGHT: int = 600\n\n# Create the game screen and clock for controlling the frame rate\nscreen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\nclock = pygame.time.Clock()\n\nclass SpaceShip:\n    \"\"\"\n    Represents the player's spaceship in the game.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the spaceship with a green square image and sets its initial position.\n        \"\"\"\n        self.image: pygame.Surface = pygame.Surface((50, 50))\n        self.image.fill((0, 255, 0))  # Color the spaceship green\n        self.rect: pygame.Rect = self.image.get_rect(center=(SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n\n    def move(self, dx: int, dy: int) -> None:\n        \"\"\"\n        Moves the spaceship by the specified offsets.\n\n        :param dx: Change in x position\n        :param dy: Change in y position\n        \"\"\"\n        self.rect.x += dx\n        self.rect.y += dy\n\nclass Asteroid:\n    \"\"\"\n    Represents an asteroid in the game that moves down the screen.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the asteroid with a red square image and sets its initial random position.\n        \"\"\"\n        self.image: pygame.Surface = pygame.Surface((50, 50))\n        self.image.fill((255, 0, 0))  # Color the asteroid red\n        self.rect: pygame.Rect = self.image.get_rect(center=(random.randint(0, SCREEN_WIDTH), random.randint(0, SCREEN_HEIGHT)))\n\n    def move(self) -> None:\n        \"\"\"\n        Moves the asteroid down the screen. If it goes off the bottom, it reappears at the top with a new random x position.\n        \"\"\"\n        self.rect.y += 5\n        if self.rect.y > SCREEN_HEIGHT:\n            self.rect.y = -50  # Reset position to above the screen\n            self.rect.x = random.randint(0, SCREEN_WIDTH)  # Randomize x position\n\n# Create an instance of the spaceship\nspaceship = SpaceShip()\n# Create a list of asteroids\nasteroids: List[Asteroid] = [Asteroid() for _ in range(5)]\n\nrunning: bool = True\nwhile running:\n    # Process events in the game\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n\n    # Handle player input for spaceship movement\n    keys = pygame.key.get_pressed()\n    if keys[pygame.K_LEFT]:\n        spaceship.move(-5, 0)\n    if keys[pygame.K_RIGHT]:\n        spaceship.move(5, 0)\n    if keys[pygame.K_UP]:\n        spaceship.move(0, -5)\n    if keys[pygame.K_DOWN]:\n        spaceship.move(0, 5)\n\n    # Move asteroids and check for collisions\n    for asteroid in asteroids:\n        asteroid.move()\n        if spaceship.rect.colliderect(asteroid.rect):\n            running = False  # End the game on collision\n\n    # Render the game scene\n    screen.fill((0, 0, 0))  # Clear the screen with black\n    screen.blit(spaceship.image, spaceship.rect)  # Draw the spaceship\n    for asteroid in asteroids:\n        screen.blit(asteroid.image, asteroid.rect)  # Draw each asteroid\n    pygame.display.flip()  # Update the display\n    clock.tick(60)  # Cap the frame rate at 60 FPS\n\npygame.quit()",
    "rejected_code": "import pygame\nimport random\n\npygame.init()\n\nscreen = pygame.display.set_mode((800, 600))\nclock = pygame.time.Clock()\n\nclass SpaceShip:\n    def __init__(self):\n        self.image = pygame.Surface((50, 50))\n        self.image.fill((0, 255, 0))\n        self.rect = self.image.get_rect(center=(400, 300))\n\n    def move(self, dx, dy):\n        self.rect.x += dx\n        self.rect.y += dy\n\nclass Asteroid:\n    def __init__(self):\n        self.image = pygame.Surface((50, 50))\n        self.image.fill((255, 0, 0))\n        self.rect = self.image.get_rect(center=(random.randint(0, 800), random.randint(0, 600)))\n\n    def move(self):\n        self.rect.y += 5\n        if self.rect.y > 600:\n            self.rect.y = -50\n            self.rect.x = random.randint(0, 800)\n\nspaceship = SpaceShip()\nasteroids = [Asteroid() for _ in range(5)]\n\nrunning = True\nwhile running:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n\n    keys = pygame.key.get_pressed()\n    if keys[pygame.K_LEFT]:\n        spaceship.move(-5, 0)\n    if keys[pygame.K_RIGHT]:\n        spaceship.move(5, 0)\n    if keys[pygame.K_UP]:\n        spaceship.move(0, -5)\n    if keys[pygame.K_DOWN]:\n        spaceship.move(0, 5)\n\n    for asteroid in asteroids:\n        asteroid.move()\n        if spaceship.rect.colliderect(asteroid.rect):\n            running = False\n\n    screen.fill((0, 0, 0))\n    screen.blit(spaceship.image, spaceship.rect)\n    for asteroid in asteroids:\n        screen.blit(asteroid.image, asteroid.rect)\n    pygame.display.flip()\n    clock.tick(60)\n\npygame.quit()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.6666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.08247422680412371,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Create a physics-based collision detection system",
    "code_form": "physics class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a Python class implementation for a physics-based collision detection system in a simple 2D space shooter game.",
      "role": "user"
    },
    "chosen_code": "import pygame\nimport random\nfrom typing import List\n\npygame.init()\n\n# Set up the game window dimensions\nSCREEN_WIDTH: int = 800\nSCREEN_HEIGHT: int = 600\n\n# Create the game screen and clock for controlling the frame rate\nscreen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\nclock = pygame.time.Clock()\n\nclass SpaceShip:\n    \"\"\"\n    Represents the player's spaceship in the game.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the spaceship with a green square image and sets its initial position.\n        \"\"\"\n        self.image: pygame.Surface = pygame.Surface((50, 50))\n        self.image.fill((0, 255, 0))  # Color the spaceship green\n        self.rect: pygame.Rect = self.image.get_rect(center=(SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n\n    def move(self, dx: int, dy: int) -> None:\n        \"\"\"\n        Moves the spaceship by the specified offsets.\n\n        :param dx: Change in x position\n        :param dy: Change in y position\n        \"\"\"\n        self.rect.x += dx\n        self.rect.y += dy\n\nclass Asteroid:\n    \"\"\"\n    Represents an asteroid in the game that moves down the screen.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the asteroid with a red square image and sets its initial random position.\n        \"\"\"\n        self.image: pygame.Surface = pygame.Surface((50, 50))\n        self.image.fill((255, 0, 0))  # Color the asteroid red\n        self.rect: pygame.Rect = self.image.get_rect(center=(random.randint(0, SCREEN_WIDTH), random.randint(0, SCREEN_HEIGHT)))\n\n    def move(self) -> None:\n        \"\"\"\n        Moves the asteroid down the screen. If it goes off the bottom, it reappears at the top with a new random x position.\n        \"\"\"\n        self.rect.y += 5\n        if self.rect.y > SCREEN_HEIGHT:\n            self.rect.y = -50  # Reset position to above the screen\n            self.rect.x = random.randint(0, SCREEN_WIDTH)  # Randomize x position\n\n# Create an instance of the spaceship\nspaceship = SpaceShip()\n# Create a list of asteroids\nasteroids: List[Asteroid] = [Asteroid() for _ in range(5)]\n\nrunning: bool = True\nwhile running:\n    # Process events in the game\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n\n    # Handle player input for spaceship movement\n    keys = pygame.key.get_pressed()\n    if keys[pygame.K_LEFT]:\n        spaceship.move(-5, 0)\n    if keys[pygame.K_RIGHT]:\n        spaceship.move(5, 0)\n    if keys[pygame.K_UP]:\n        spaceship.move(0, -5)\n    if keys[pygame.K_DOWN]:\n        spaceship.move(0, 5)\n\n    # Move asteroids and check for collisions\n    for asteroid in asteroids:\n        asteroid.move()\n        if spaceship.rect.colliderect(asteroid.rect):\n            running = False  # End the game on collision\n\n    # Render the game scene\n    screen.fill((0, 0, 0))  # Clear the screen with black\n    screen.blit(spaceship.image, spaceship.rect)  # Draw the spaceship\n    for asteroid in asteroids:\n        screen.blit(asteroid.image, asteroid.rect)  # Draw each asteroid\n    pygame.display.flip()  # Update the display\n    clock.tick(60)  # Cap the frame rate at 60 FPS\n\npygame.quit()",
    "rejected_code": "import pygame\nimport random\n\npygame.init()\n\nscreen = pygame.display.set_mode((800, 600))\nclock = pygame.time.Clock()\n\nclass SpaceShip:\n    def __init__(self):\n        self.image = pygame.Surface((50, 50))\n        self.image.fill((0, 255, 0))\n        self.rect = self.image.get_rect(center=(400, 300))\n\n    def move(self, dx, dy):\n        self.rect.x += dx\n        self.rect.y += dy\n\nclass Asteroid:\n    def __init__(self):\n        self.image = pygame.Surface((50, 50))\n        self.image.fill((255, 0, 0))\n        self.rect = self.image.get_rect(center=(random.randint(0, 800), random.randint(0, 600)))\n\n    def move(self):\n        self.rect.y += 5\n        if self.rect.y > 600:\n            self.rect.y = -50\n            self.rect.x = random.randint(0, 800)\n\nspaceship = SpaceShip()\nasteroids = [Asteroid() for _ in range(5)]\n\nrunning = True\nwhile running:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n\n    keys = pygame.key.get_pressed()\n    if keys[pygame.K_LEFT]:\n        spaceship.move(-5, 0)\n    if keys[pygame.K_RIGHT]:\n        spaceship.move(5, 0)\n    if keys[pygame.K_UP]:\n        spaceship.move(0, -5)\n    if keys[pygame.K_DOWN]:\n        spaceship.move(0, 5)\n\n    for asteroid in asteroids:\n        asteroid.move()\n        if spaceship.rect.colliderect(asteroid.rect):\n            running = False\n\n    screen.fill((0, 0, 0))\n    screen.blit(spaceship.image, spaceship.rect)\n    for asteroid in asteroids:\n        screen.blit(asteroid.image, asteroid.rect)\n    pygame.display.flip()\n    clock.tick(60)\n\npygame.quit()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.6666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.08247422680412371,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Create a physics-based collision detection system",
    "code_form": "physics class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a Python class implementation for a physics-based collision detection system in a simple 2D space shooter game, specifying input types for methods and output types where applicable.",
      "role": "user"
    },
    "chosen_code": "import pygame\nimport random\nfrom typing import List\n\npygame.init()\n\n# Set up the game window dimensions\nSCREEN_WIDTH: int = 800\nSCREEN_HEIGHT: int = 600\n\n# Create the game screen and clock for controlling the frame rate\nscreen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\nclock = pygame.time.Clock()\n\nclass SpaceShip:\n    \"\"\"\n    Represents the player's spaceship in the game.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the spaceship with a green square image and sets its initial position.\n        \"\"\"\n        self.image: pygame.Surface = pygame.Surface((50, 50))\n        self.image.fill((0, 255, 0))  # Color the spaceship green\n        self.rect: pygame.Rect = self.image.get_rect(center=(SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n\n    def move(self, dx: int, dy: int) -> None:\n        \"\"\"\n        Moves the spaceship by the specified offsets.\n\n        :param dx: Change in x position\n        :param dy: Change in y position\n        \"\"\"\n        self.rect.x += dx\n        self.rect.y += dy\n\nclass Asteroid:\n    \"\"\"\n    Represents an asteroid in the game that moves down the screen.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the asteroid with a red square image and sets its initial random position.\n        \"\"\"\n        self.image: pygame.Surface = pygame.Surface((50, 50))\n        self.image.fill((255, 0, 0))  # Color the asteroid red\n        self.rect: pygame.Rect = self.image.get_rect(center=(random.randint(0, SCREEN_WIDTH), random.randint(0, SCREEN_HEIGHT)))\n\n    def move(self) -> None:\n        \"\"\"\n        Moves the asteroid down the screen. If it goes off the bottom, it reappears at the top with a new random x position.\n        \"\"\"\n        self.rect.y += 5\n        if self.rect.y > SCREEN_HEIGHT:\n            self.rect.y = -50  # Reset position to above the screen\n            self.rect.x = random.randint(0, SCREEN_WIDTH)  # Randomize x position\n\n# Create an instance of the spaceship\nspaceship = SpaceShip()\n# Create a list of asteroids\nasteroids: List[Asteroid] = [Asteroid() for _ in range(5)]\n\nrunning: bool = True\nwhile running:\n    # Process events in the game\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n\n    # Handle player input for spaceship movement\n    keys = pygame.key.get_pressed()\n    if keys[pygame.K_LEFT]:\n        spaceship.move(-5, 0)\n    if keys[pygame.K_RIGHT]:\n        spaceship.move(5, 0)\n    if keys[pygame.K_UP]:\n        spaceship.move(0, -5)\n    if keys[pygame.K_DOWN]:\n        spaceship.move(0, 5)\n\n    # Move asteroids and check for collisions\n    for asteroid in asteroids:\n        asteroid.move()\n        if spaceship.rect.colliderect(asteroid.rect):\n            running = False  # End the game on collision\n\n    # Render the game scene\n    screen.fill((0, 0, 0))  # Clear the screen with black\n    screen.blit(spaceship.image, spaceship.rect)  # Draw the spaceship\n    for asteroid in asteroids:\n        screen.blit(asteroid.image, asteroid.rect)  # Draw each asteroid\n    pygame.display.flip()  # Update the display\n    clock.tick(60)  # Cap the frame rate at 60 FPS\n\npygame.quit()",
    "rejected_code": "import pygame\nimport random\n\npygame.init()\n\nscreen = pygame.display.set_mode((800, 600))\nclock = pygame.time.Clock()\n\nclass SpaceShip:\n    def __init__(self):\n        self.image = pygame.Surface((50, 50))\n        self.image.fill((0, 255, 0))\n        self.rect = self.image.get_rect(center=(400, 300))\n\n    def move(self, dx, dy):\n        self.rect.x += dx\n        self.rect.y += dy\n\nclass Asteroid:\n    def __init__(self):\n        self.image = pygame.Surface((50, 50))\n        self.image.fill((255, 0, 0))\n        self.rect = self.image.get_rect(center=(random.randint(0, 800), random.randint(0, 600)))\n\n    def move(self):\n        self.rect.y += 5\n        if self.rect.y > 600:\n            self.rect.y = -50\n            self.rect.x = random.randint(0, 800)\n\nspaceship = SpaceShip()\nasteroids = [Asteroid() for _ in range(5)]\n\nrunning = True\nwhile running:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n\n    keys = pygame.key.get_pressed()\n    if keys[pygame.K_LEFT]:\n        spaceship.move(-5, 0)\n    if keys[pygame.K_RIGHT]:\n        spaceship.move(5, 0)\n    if keys[pygame.K_UP]:\n        spaceship.move(0, -5)\n    if keys[pygame.K_DOWN]:\n        spaceship.move(0, 5)\n\n    for asteroid in asteroids:\n        asteroid.move()\n        if spaceship.rect.colliderect(asteroid.rect):\n            running = False\n\n    screen.fill((0, 0, 0))\n    screen.blit(spaceship.image, spaceship.rect)\n    for asteroid in asteroids:\n        screen.blit(asteroid.image, asteroid.rect)\n    pygame.display.flip()\n    clock.tick(60)\n\npygame.quit()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.6666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.08247422680412371,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.6666666666666667,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Build a resilient API client with retry logic and circuit breaking",
    "code_form": "client class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to build a resilient API client with retry logic and circuit breaking?",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nimport time\nfrom typing import Dict, Any, Optional\n\nclass ResilientApiClient:\n    def __init__(self, base_url: str) -> None:\n        \"\"\"\n        Initializes the API client with a base URL.\n\n        :param base_url: The base URL for the external API.\n        \"\"\"\n        self.base_url = base_url\n        self.failure_count: int = 0  # Count of consecutive failures\n        self.circuit_open: bool = False  # Circuit breaker state\n\n    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n    def fetch_product(self, product_id: int) -> Dict[str, Any]:\n        \"\"\"\n        Fetches product details from the external API.\n\n        :param product_id: The ID of the product to fetch.\n        :return: A dictionary containing product details.\n        :raises Exception: If the circuit is open or if the request fails.\n        \"\"\"\n        if self.circuit_open:\n            raise Exception('Circuit is open')\n\n        url = f'{self.base_url}/products/{product_id}'\n        try:\n            response = requests.get(url)\n            response.raise_for_status()  # Raise an error for bad responses\n            self.failure_count = 0  # Reset failure count on success\n            return response.json()  # Return the JSON response\n        except RequestException:\n            self.failure_count += 1  # Increment failure count\n            if self.failure_count >= 3:\n                self.circuit_open = True  # Open circuit after 3 failures\n                time.sleep(5)  # Wait before allowing further requests\n            raise  # Re-raise the exception for further handling\n\n    def reset_circuit(self) -> None:\n        \"\"\"\n        Resets the circuit breaker, allowing requests to be made again.\n        \"\"\"\n        self.failure_count = 0  # Reset failure count\n        self.circuit_open = False  # Close the circuit\n\n# Example usage\nif __name__ == '__main__':\n    client = ResilientApiClient('https://api.example.com')\n    try:\n        product = client.fetch_product(123)\n        print(product)\n    except Exception as e:\n        print(f'Error fetching product: {e}')",
    "rejected_code": "import requests\nfrom requests.exceptions import RequestException\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nimport time\n\nclass ResilientApiClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n        self.failure_count = 0\n        self.circuit_open = False\n\n    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n    def fetch_product(self, product_id):\n        if self.circuit_open:\n            raise Exception('Circuit is open')\n        url = f'{self.base_url}/products/{product_id}'\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            self.failure_count = 0\n            return response.json()\n        except RequestException:\n            self.failure_count += 1\n            if self.failure_count >= 3:\n                self.circuit_open = True\n                time.sleep(5)\n            raise\n\n    def reset_circuit(self):\n        self.failure_count = 0\n        self.circuit_open = False\n\nclient = ResilientApiClient('https://api.example.com')\ntry:\n    product = client.fetch_product(123)\n    print(product)\nexcept Exception as e:\n    print(e)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.017543859649122806,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'tenacity'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'tenacity'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Build a resilient API client with retry logic and circuit breaking",
    "code_form": "client class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class in Python that implements a resilient API client with retry logic and circuit breaking.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nimport time\nfrom typing import Dict, Any, Optional\n\nclass ResilientApiClient:\n    def __init__(self, base_url: str) -> None:\n        \"\"\"\n        Initializes the API client with a base URL.\n\n        :param base_url: The base URL for the external API.\n        \"\"\"\n        self.base_url = base_url\n        self.failure_count: int = 0  # Count of consecutive failures\n        self.circuit_open: bool = False  # Circuit breaker state\n\n    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n    def fetch_product(self, product_id: int) -> Dict[str, Any]:\n        \"\"\"\n        Fetches product details from the external API.\n\n        :param product_id: The ID of the product to fetch.\n        :return: A dictionary containing product details.\n        :raises Exception: If the circuit is open or if the request fails.\n        \"\"\"\n        if self.circuit_open:\n            raise Exception('Circuit is open')\n\n        url = f'{self.base_url}/products/{product_id}'\n        try:\n            response = requests.get(url)\n            response.raise_for_status()  # Raise an error for bad responses\n            self.failure_count = 0  # Reset failure count on success\n            return response.json()  # Return the JSON response\n        except RequestException:\n            self.failure_count += 1  # Increment failure count\n            if self.failure_count >= 3:\n                self.circuit_open = True  # Open circuit after 3 failures\n                time.sleep(5)  # Wait before allowing further requests\n            raise  # Re-raise the exception for further handling\n\n    def reset_circuit(self) -> None:\n        \"\"\"\n        Resets the circuit breaker, allowing requests to be made again.\n        \"\"\"\n        self.failure_count = 0  # Reset failure count\n        self.circuit_open = False  # Close the circuit\n\n# Example usage\nif __name__ == '__main__':\n    client = ResilientApiClient('https://api.example.com')\n    try:\n        product = client.fetch_product(123)\n        print(product)\n    except Exception as e:\n        print(f'Error fetching product: {e}')",
    "rejected_code": "import requests\nfrom requests.exceptions import RequestException\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nimport time\n\nclass ResilientApiClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n        self.failure_count = 0\n        self.circuit_open = False\n\n    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n    def fetch_product(self, product_id):\n        if self.circuit_open:\n            raise Exception('Circuit is open')\n        url = f'{self.base_url}/products/{product_id}'\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            self.failure_count = 0\n            return response.json()\n        except RequestException:\n            self.failure_count += 1\n            if self.failure_count >= 3:\n                self.circuit_open = True\n                time.sleep(5)\n            raise\n\n    def reset_circuit(self):\n        self.failure_count = 0\n        self.circuit_open = False\n\nclient = ResilientApiClient('https://api.example.com')\ntry:\n    product = client.fetch_product(123)\n    print(product)\nexcept Exception as e:\n    print(e)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.017543859649122806,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'tenacity'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'tenacity'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Build a resilient API client with retry logic and circuit breaking",
    "code_form": "client class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python class that implements a resilient API client with retry logic and circuit breaking. Please specify the input/output types for the methods.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nimport time\nfrom typing import Dict, Any, Optional\n\nclass ResilientApiClient:\n    def __init__(self, base_url: str) -> None:\n        \"\"\"\n        Initializes the API client with a base URL.\n\n        :param base_url: The base URL for the external API.\n        \"\"\"\n        self.base_url = base_url\n        self.failure_count: int = 0  # Count of consecutive failures\n        self.circuit_open: bool = False  # Circuit breaker state\n\n    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n    def fetch_product(self, product_id: int) -> Dict[str, Any]:\n        \"\"\"\n        Fetches product details from the external API.\n\n        :param product_id: The ID of the product to fetch.\n        :return: A dictionary containing product details.\n        :raises Exception: If the circuit is open or if the request fails.\n        \"\"\"\n        if self.circuit_open:\n            raise Exception('Circuit is open')\n\n        url = f'{self.base_url}/products/{product_id}'\n        try:\n            response = requests.get(url)\n            response.raise_for_status()  # Raise an error for bad responses\n            self.failure_count = 0  # Reset failure count on success\n            return response.json()  # Return the JSON response\n        except RequestException:\n            self.failure_count += 1  # Increment failure count\n            if self.failure_count >= 3:\n                self.circuit_open = True  # Open circuit after 3 failures\n                time.sleep(5)  # Wait before allowing further requests\n            raise  # Re-raise the exception for further handling\n\n    def reset_circuit(self) -> None:\n        \"\"\"\n        Resets the circuit breaker, allowing requests to be made again.\n        \"\"\"\n        self.failure_count = 0  # Reset failure count\n        self.circuit_open = False  # Close the circuit\n\n# Example usage\nif __name__ == '__main__':\n    client = ResilientApiClient('https://api.example.com')\n    try:\n        product = client.fetch_product(123)\n        print(product)\n    except Exception as e:\n        print(f'Error fetching product: {e}')",
    "rejected_code": "import requests\nfrom requests.exceptions import RequestException\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nimport time\n\nclass ResilientApiClient:\n    def __init__(self, base_url):\n        self.base_url = base_url\n        self.failure_count = 0\n        self.circuit_open = False\n\n    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n    def fetch_product(self, product_id):\n        if self.circuit_open:\n            raise Exception('Circuit is open')\n        url = f'{self.base_url}/products/{product_id}'\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            self.failure_count = 0\n            return response.json()\n        except RequestException:\n            self.failure_count += 1\n            if self.failure_count >= 3:\n                self.circuit_open = True\n                time.sleep(5)\n            raise\n\n    def reset_circuit(self):\n        self.failure_count = 0\n        self.circuit_open = False\n\nclient = ResilientApiClient('https://api.example.com')\ntry:\n    product = client.fetch_product(123)\n    print(product)\nexcept Exception as e:\n    print(e)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.017543859649122806,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'tenacity'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'tenacity'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Implement a request validation function with schema checking",
    "code_form": "validator function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to implement a request validation function with schema checking for an API that creates tasks.",
      "role": "user"
    },
    "chosen_code": "from fastapi import FastAPI, HTTPException, Request\nfrom pydantic import BaseModel, validator\nfrom typing import Any\n\napp = FastAPI()\n\nclass Task(BaseModel):\n    title: str  # The title of the task\n    description: str  # A description of the task\n    due_date: str  # The due date for the task in string format\n\n    @validator('due_date')\n    def check_due_date(cls, value: str) -> str:\n        \"\"\"\n        Validate the due date to ensure it is not empty.\n\n        Args:\n            cls: The class being validated.\n            value (str): The due date value to validate.\n\n        Raises:\n            ValueError: If the due date is an empty string.\n\n        Returns:\n            str: The validated due date.\n        \"\"\"\n        if not value:\n            raise ValueError('Due date must be provided')\n        return value\n\n@app.post('/tasks/')\nasync def create_task(task: Task) -> dict[str, Any]:\n    \"\"\"\n    Create a new task with the provided details.\n\n    Args:\n        task (Task): The task object containing title, description, and due date.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the created task.\n    \"\"\"\n    return {'task': task}\n\n@app.exception_handler(ValueError)\nasync def validation_exception_handler(request: Request, exc: ValueError) -> None:\n    \"\"\"\n    Handle validation exceptions by returning a 422 HTTP response.\n\n    Args:\n        request (Request): The incoming request that caused the exception.\n        exc (ValueError): The validation exception that occurred.\n\n    Raises:\n        HTTPException: A 422 HTTP exception with the validation error details.\n    \"\"\"\n    raise HTTPException(status_code=422, detail=str(exc))",
    "rejected_code": "from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, validator\n\napp = FastAPI()\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    due_date: str\n\n    @validator('due_date')\n    def check_due_date(cls, v):\n        if not v:\n            raise ValueError('Due date must be provided')\n        return v\n\n@app.post('/tasks/')\nasync def create_task(task: Task):\n    return {'task': task}\n\n@app.exception_handler(ValueError)\nasync def validation_exception_handler(request, exc):\n    raise HTTPException(status_code=422, detail=str(exc))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.75,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.75,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Implement a request validation function with schema checking",
    "code_form": "validator function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a Python function to implement a request validation function with schema checking for an API that creates tasks?",
      "role": "user"
    },
    "chosen_code": "from fastapi import FastAPI, HTTPException, Request\nfrom pydantic import BaseModel, validator\nfrom typing import Any\n\napp = FastAPI()\n\nclass Task(BaseModel):\n    title: str  # The title of the task\n    description: str  # A description of the task\n    due_date: str  # The due date for the task in string format\n\n    @validator('due_date')\n    def check_due_date(cls, value: str) -> str:\n        \"\"\"\n        Validate the due date to ensure it is not empty.\n\n        Args:\n            cls: The class being validated.\n            value (str): The due date value to validate.\n\n        Raises:\n            ValueError: If the due date is an empty string.\n\n        Returns:\n            str: The validated due date.\n        \"\"\"\n        if not value:\n            raise ValueError('Due date must be provided')\n        return value\n\n@app.post('/tasks/')\nasync def create_task(task: Task) -> dict[str, Any]:\n    \"\"\"\n    Create a new task with the provided details.\n\n    Args:\n        task (Task): The task object containing title, description, and due date.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the created task.\n    \"\"\"\n    return {'task': task}\n\n@app.exception_handler(ValueError)\nasync def validation_exception_handler(request: Request, exc: ValueError) -> None:\n    \"\"\"\n    Handle validation exceptions by returning a 422 HTTP response.\n\n    Args:\n        request (Request): The incoming request that caused the exception.\n        exc (ValueError): The validation exception that occurred.\n\n    Raises:\n        HTTPException: A 422 HTTP exception with the validation error details.\n    \"\"\"\n    raise HTTPException(status_code=422, detail=str(exc))",
    "rejected_code": "from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, validator\n\napp = FastAPI()\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    due_date: str\n\n    @validator('due_date')\n    def check_due_date(cls, v):\n        if not v:\n            raise ValueError('Due date must be provided')\n        return v\n\n@app.post('/tasks/')\nasync def create_task(task: Task):\n    return {'task': task}\n\n@app.exception_handler(ValueError)\nasync def validation_exception_handler(request, exc):\n    raise HTTPException(status_code=422, detail=str(exc))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.75,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.75,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Implement a request validation function with schema checking",
    "code_form": "validator function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please create a Python class that implements a request validation function with schema checking for an API that creates tasks, specifying the input and output types.",
      "role": "user"
    },
    "chosen_code": "from fastapi import FastAPI, HTTPException, Request\nfrom pydantic import BaseModel, validator\nfrom typing import Any\n\napp = FastAPI()\n\nclass Task(BaseModel):\n    title: str  # The title of the task\n    description: str  # A description of the task\n    due_date: str  # The due date for the task in string format\n\n    @validator('due_date')\n    def check_due_date(cls, value: str) -> str:\n        \"\"\"\n        Validate the due date to ensure it is not empty.\n\n        Args:\n            cls: The class being validated.\n            value (str): The due date value to validate.\n\n        Raises:\n            ValueError: If the due date is an empty string.\n\n        Returns:\n            str: The validated due date.\n        \"\"\"\n        if not value:\n            raise ValueError('Due date must be provided')\n        return value\n\n@app.post('/tasks/')\nasync def create_task(task: Task) -> dict[str, Any]:\n    \"\"\"\n    Create a new task with the provided details.\n\n    Args:\n        task (Task): The task object containing title, description, and due date.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the created task.\n    \"\"\"\n    return {'task': task}\n\n@app.exception_handler(ValueError)\nasync def validation_exception_handler(request: Request, exc: ValueError) -> None:\n    \"\"\"\n    Handle validation exceptions by returning a 422 HTTP response.\n\n    Args:\n        request (Request): The incoming request that caused the exception.\n        exc (ValueError): The validation exception that occurred.\n\n    Raises:\n        HTTPException: A 422 HTTP exception with the validation error details.\n    \"\"\"\n    raise HTTPException(status_code=422, detail=str(exc))",
    "rejected_code": "from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, validator\n\napp = FastAPI()\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    due_date: str\n\n    @validator('due_date')\n    def check_due_date(cls, v):\n        if not v:\n            raise ValueError('Due date must be provided')\n        return v\n\n@app.post('/tasks/')\nasync def create_task(task: Task):\n    return {'task': task}\n\n@app.exception_handler(ValueError)\nasync def validation_exception_handler(request, exc):\n    raise HTTPException(status_code=422, detail=str(exc))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.75,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.75,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'fastapi'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Create a service discovery class with health checking",
    "code_form": "discovery class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code for a service discovery class with health checking in a microservices architecture.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom typing import List\n\nclass ServiceDiscovery:\n    \"\"\"\n    A class to discover and check the health of microservices.\n\n    Attributes:\n        services (List[str]): A list of service URLs to check.\n        health_check_endpoint (str): The endpoint to check service health.\n        active_services (List[str]): A list of currently active services.\n    \"\"\"\n\n    def __init__(self, services: List[str]) -> None:\n        \"\"\"\n        Initializes the ServiceDiscovery with a list of services.\n\n        Args:\n            services (List[str]): A list of service URLs.\n        \"\"\"\n        self.services = services\n        self.health_check_endpoint = '/health'\n        self.active_services = []\n\n    def check_health(self, service_url: str) -> bool:\n        \"\"\"\n        Checks the health of a given service by sending a GET request.\n\n        Args:\n            service_url (str): The URL of the service to check.\n\n        Returns:\n            bool: True if the service is healthy (HTTP 200), False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(service_url + self.health_check_endpoint)\n            return response.status_code == 200\n        except requests.RequestException:\n            return False\n\n    def discover_services(self) -> None:\n        \"\"\"\n        Discovers active services by checking their health.\n        Updates the list of active services based on health checks.\n        \"\"\"\n        for service in self.services:\n            if self.check_health(service):\n                self.active_services.append(service)\n\n    def get_active_services(self) -> List[str]:\n        \"\"\"\n        Retrieves the list of active services after performing health checks.\n\n        Returns:\n            List[str]: A list of active service URLs.\n        \"\"\"\n        self.discover_services()\n        return self.active_services\n\n# Example usage:\nif __name__ == '__main__':\n    services = ['http://service1.com', 'http://service2.com']\n    discovery = ServiceDiscovery(services)\n    active_services = discovery.get_active_services()\n    print(active_services)",
    "rejected_code": "import requests\n\nclass ServiceDiscovery:\n    def __init__(self, services):\n        self.services = services\n        self.health_check_endpoint = '/health'\n        self.active_services = []\n\n    def check_health(self, service_url):\n        try:\n            response = requests.get(service_url + self.health_check_endpoint)\n            if response.status_code == 200:\n                return True\n        except requests.RequestException:\n            return False\n        return False\n\n    def discover_services(self):\n        for service in self.services:\n            if self.check_health(service):\n                self.active_services.append(service)\n\n    def get_active_services(self):\n        self.discover_services()\n        return self.active_services\n\n# Example usage:\nservices = ['http://service1.com', 'http://service2.com']\ndiscovery = ServiceDiscovery(services)\nactive_services = discovery.get_active_services()\nprint(active_services)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.015384615384615385,
      "execution_result": {
        "success": true,
        "output": "[]",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.2,
      "pep8_compliance": null,
      "comment_density": 0.03225806451612903,
      "execution_result": {
        "success": true,
        "output": "[]",
        "error": ""
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Create a service discovery class with health checking",
    "code_form": "discovery class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a Python class that implements a service discovery mechanism with health checking.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom typing import List\n\nclass ServiceDiscovery:\n    \"\"\"\n    A class to discover and check the health of microservices.\n\n    Attributes:\n        services (List[str]): A list of service URLs to check.\n        health_check_endpoint (str): The endpoint to check service health.\n        active_services (List[str]): A list of currently active services.\n    \"\"\"\n\n    def __init__(self, services: List[str]) -> None:\n        \"\"\"\n        Initializes the ServiceDiscovery with a list of services.\n\n        Args:\n            services (List[str]): A list of service URLs.\n        \"\"\"\n        self.services = services\n        self.health_check_endpoint = '/health'\n        self.active_services = []\n\n    def check_health(self, service_url: str) -> bool:\n        \"\"\"\n        Checks the health of a given service by sending a GET request.\n\n        Args:\n            service_url (str): The URL of the service to check.\n\n        Returns:\n            bool: True if the service is healthy (HTTP 200), False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(service_url + self.health_check_endpoint)\n            return response.status_code == 200\n        except requests.RequestException:\n            return False\n\n    def discover_services(self) -> None:\n        \"\"\"\n        Discovers active services by checking their health.\n        Updates the list of active services based on health checks.\n        \"\"\"\n        for service in self.services:\n            if self.check_health(service):\n                self.active_services.append(service)\n\n    def get_active_services(self) -> List[str]:\n        \"\"\"\n        Retrieves the list of active services after performing health checks.\n\n        Returns:\n            List[str]: A list of active service URLs.\n        \"\"\"\n        self.discover_services()\n        return self.active_services\n\n# Example usage:\nif __name__ == '__main__':\n    services = ['http://service1.com', 'http://service2.com']\n    discovery = ServiceDiscovery(services)\n    active_services = discovery.get_active_services()\n    print(active_services)",
    "rejected_code": "import requests\n\nclass ServiceDiscovery:\n    def __init__(self, services):\n        self.services = services\n        self.health_check_endpoint = '/health'\n        self.active_services = []\n\n    def check_health(self, service_url):\n        try:\n            response = requests.get(service_url + self.health_check_endpoint)\n            if response.status_code == 200:\n                return True\n        except requests.RequestException:\n            return False\n        return False\n\n    def discover_services(self):\n        for service in self.services:\n            if self.check_health(service):\n                self.active_services.append(service)\n\n    def get_active_services(self):\n        self.discover_services()\n        return self.active_services\n\n# Example usage:\nservices = ['http://service1.com', 'http://service2.com']\ndiscovery = ServiceDiscovery(services)\nactive_services = discovery.get_active_services()\nprint(active_services)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.015384615384615385,
      "execution_result": {
        "success": true,
        "output": "[]",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.2,
      "pep8_compliance": null,
      "comment_density": 0.03225806451612903,
      "execution_result": {
        "success": true,
        "output": "[]",
        "error": ""
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Create a service discovery class with health checking",
    "code_form": "discovery class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a Python class with type annotations that implements a service discovery mechanism with health checking, taking a list of service URLs as input and returning a list of active services.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom typing import List\n\nclass ServiceDiscovery:\n    \"\"\"\n    A class to discover and check the health of microservices.\n\n    Attributes:\n        services (List[str]): A list of service URLs to check.\n        health_check_endpoint (str): The endpoint to check service health.\n        active_services (List[str]): A list of currently active services.\n    \"\"\"\n\n    def __init__(self, services: List[str]) -> None:\n        \"\"\"\n        Initializes the ServiceDiscovery with a list of services.\n\n        Args:\n            services (List[str]): A list of service URLs.\n        \"\"\"\n        self.services = services\n        self.health_check_endpoint = '/health'\n        self.active_services = []\n\n    def check_health(self, service_url: str) -> bool:\n        \"\"\"\n        Checks the health of a given service by sending a GET request.\n\n        Args:\n            service_url (str): The URL of the service to check.\n\n        Returns:\n            bool: True if the service is healthy (HTTP 200), False otherwise.\n        \"\"\"\n        try:\n            response = requests.get(service_url + self.health_check_endpoint)\n            return response.status_code == 200\n        except requests.RequestException:\n            return False\n\n    def discover_services(self) -> None:\n        \"\"\"\n        Discovers active services by checking their health.\n        Updates the list of active services based on health checks.\n        \"\"\"\n        for service in self.services:\n            if self.check_health(service):\n                self.active_services.append(service)\n\n    def get_active_services(self) -> List[str]:\n        \"\"\"\n        Retrieves the list of active services after performing health checks.\n\n        Returns:\n            List[str]: A list of active service URLs.\n        \"\"\"\n        self.discover_services()\n        return self.active_services\n\n# Example usage:\nif __name__ == '__main__':\n    services = ['http://service1.com', 'http://service2.com']\n    discovery = ServiceDiscovery(services)\n    active_services = discovery.get_active_services()\n    print(active_services)",
    "rejected_code": "import requests\n\nclass ServiceDiscovery:\n    def __init__(self, services):\n        self.services = services\n        self.health_check_endpoint = '/health'\n        self.active_services = []\n\n    def check_health(self, service_url):\n        try:\n            response = requests.get(service_url + self.health_check_endpoint)\n            if response.status_code == 200:\n                return True\n        except requests.RequestException:\n            return False\n        return False\n\n    def discover_services(self):\n        for service in self.services:\n            if self.check_health(service):\n                self.active_services.append(service)\n\n    def get_active_services(self):\n        self.discover_services()\n        return self.active_services\n\n# Example usage:\nservices = ['http://service1.com', 'http://service2.com']\ndiscovery = ServiceDiscovery(services)\nactive_services = discovery.get_active_services()\nprint(active_services)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.015384615384615385,
      "execution_result": {
        "success": true,
        "output": "[]",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.2,
      "pep8_compliance": null,
      "comment_density": 0.03225806451612903,
      "execution_result": {
        "success": true,
        "output": "[]",
        "error": ""
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Develop a pathfinding function with multiple algorithms",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to develop a pathfinding function with multiple algorithms for a 2D grid-based game.",
      "role": "user"
    },
    "chosen_code": "import pygame\nimport numpy as np\nimport networkx as nx\nfrom typing import Tuple, List, Union\n\nclass Pathfinding:\n    def __init__(self, grid: np.ndarray) -> None:\n        \"\"\"\n        Initialize the Pathfinding class with a grid.\n        \n        Args:\n            grid (np.ndarray): A 2D numpy array representing the grid where 0 is walkable and 1 is an obstacle.\n        \"\"\"\n        self.grid = grid\n        self.graph = self.create_graph()\n\n    def create_graph(self) -> nx.Graph:\n        \"\"\"\n        Create a graph representation of the grid.\n        \n        Returns:\n            nx.Graph: A networkx graph representing the walkable paths in the grid.\n        \"\"\"\n        graph = nx.Graph()\n        rows, cols = self.grid.shape\n        for r in range(rows):\n            for c in range(cols):\n                if self.grid[r, c] == 0:\n                    if r > 0 and self.grid[r-1, c] == 0:\n                        graph.add_edge((r, c), (r-1, c))\n                    if c > 0 and self.grid[r, c-1] == 0:\n                        graph.add_edge((r, c), (r, c-1))\n                    if r < rows-1 and self.grid[r+1, c] == 0:\n                        graph.add_edge((r, c), (r+1, c))\n                    if c < cols-1 and self.grid[r, c+1] == 0:\n                        graph.add_edge((r, c), (r, c+1))\n        return graph\n\n    def a_star(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find the shortest path using the A* algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return nx.astar_path(self.graph, start, goal)\n\n    def dijkstra(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find the shortest path using Dijkstra's algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return nx.dijkstra_path(self.graph, start, goal)\n\n    def bfs(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find a path using the BFS algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return list(nx.bfs_edges(self.graph, start))\n\n    def find_path(self, algorithm: str, start: Tuple[int, int], goal: Tuple[int, int]) -> Union[List[Tuple[int, int]], None]:\n        \"\"\"\n        Find a path from start to goal using the specified algorithm.\n        \n        Args:\n            algorithm (str): The pathfinding algorithm to use ('A*', 'Dijkstra', 'BFS').\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            Union[List[Tuple[int, int]], None]: The path from start to goal, or None if the algorithm is not recognized.\n        \"\"\"\n        if algorithm == 'A*':\n            return self.a_star(start, goal)\n        elif algorithm == 'Dijkstra':\n            return self.dijkstra(start, goal)\n        elif algorithm == 'BFS':\n            return self.bfs(start, goal)\n        return None\n\n# Initialize pygame and the grid.\npygame.init()\ngrid = np.array([[0, 1, 0, 0], [0, 1, 0, 1], [0, 0, 0, 0], [1, 1, 1, 0]])\npathfinder = Pathfinding(grid)\nstart = (0, 0)\ngoal = (3, 3)\nalgorithm = 'A*'\npath = pathfinder.find_path(algorithm, start, goal)\nprint(path)",
    "rejected_code": "import pygame\nimport numpy as np\nimport networkx as nx\n\nclass Pathfinding:\n    def __init__(self, grid):\n        self.grid = grid\n        self.graph = self.create_graph()\n\n    def create_graph(self):\n        graph = nx.Graph()\n        rows, cols = self.grid.shape\n        for r in range(rows):\n            for c in range(cols):\n                if self.grid[r, c] == 0:\n                    if r > 0 and self.grid[r-1, c] == 0:\n                        graph.add_edge((r, c), (r-1, c))\n                    if c > 0 and self.grid[r, c-1] == 0:\n                        graph.add_edge((r, c), (r, c-1))\n                    if r < rows-1 and self.grid[r+1, c] == 0:\n                        graph.add_edge((r, c), (r+1, c))\n                    if c < cols-1 and self.grid[r, c+1] == 0:\n                        graph.add_edge((r, c), (r, c+1))\n        return graph\n\n    def a_star(self, start, goal):\n        return nx.astar_path(self.graph, start, goal)\n\n    def dijkstra(self, start, goal):\n        return nx.dijkstra_path(self.graph, start, goal)\n\n    def bfs(self, start, goal):\n        return nx.bfs_edges(self.graph, start)\n\n    def find_path(self, algorithm, start, goal):\n        if algorithm == 'A*':\n            return self.a_star(start, goal)\n        elif algorithm == 'Dijkstra':\n            return self.dijkstra(start, goal)\n        elif algorithm == 'BFS':\n            return self.bfs(start, goal)\n\npygame.init()\ngrid = np.array([[0, 1, 0, 0], [0, 1, 0, 1], [0, 0, 0, 0], [1, 1, 1, 0]])\npathfinder = Pathfinding(grid)\nstart = (0, 0)\ngoal = (3, 3)\nalgorithm = 'A*'\npath = pathfinder.find_path(algorithm, start, goal)\nprint(path)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.4285714285714284,
      "pep8_compliance": null,
      "comment_density": 0.009433962264150943,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.4285714285714284,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Develop a pathfinding function with multiple algorithms",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a class that implements a pathfinding function with multiple algorithms for a 2D grid-based game?",
      "role": "user"
    },
    "chosen_code": "import pygame\nimport numpy as np\nimport networkx as nx\nfrom typing import Tuple, List, Union\n\nclass Pathfinding:\n    def __init__(self, grid: np.ndarray) -> None:\n        \"\"\"\n        Initialize the Pathfinding class with a grid.\n        \n        Args:\n            grid (np.ndarray): A 2D numpy array representing the grid where 0 is walkable and 1 is an obstacle.\n        \"\"\"\n        self.grid = grid\n        self.graph = self.create_graph()\n\n    def create_graph(self) -> nx.Graph:\n        \"\"\"\n        Create a graph representation of the grid.\n        \n        Returns:\n            nx.Graph: A networkx graph representing the walkable paths in the grid.\n        \"\"\"\n        graph = nx.Graph()\n        rows, cols = self.grid.shape\n        for r in range(rows):\n            for c in range(cols):\n                if self.grid[r, c] == 0:\n                    if r > 0 and self.grid[r-1, c] == 0:\n                        graph.add_edge((r, c), (r-1, c))\n                    if c > 0 and self.grid[r, c-1] == 0:\n                        graph.add_edge((r, c), (r, c-1))\n                    if r < rows-1 and self.grid[r+1, c] == 0:\n                        graph.add_edge((r, c), (r+1, c))\n                    if c < cols-1 and self.grid[r, c+1] == 0:\n                        graph.add_edge((r, c), (r, c+1))\n        return graph\n\n    def a_star(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find the shortest path using the A* algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return nx.astar_path(self.graph, start, goal)\n\n    def dijkstra(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find the shortest path using Dijkstra's algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return nx.dijkstra_path(self.graph, start, goal)\n\n    def bfs(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find a path using the BFS algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return list(nx.bfs_edges(self.graph, start))\n\n    def find_path(self, algorithm: str, start: Tuple[int, int], goal: Tuple[int, int]) -> Union[List[Tuple[int, int]], None]:\n        \"\"\"\n        Find a path from start to goal using the specified algorithm.\n        \n        Args:\n            algorithm (str): The pathfinding algorithm to use ('A*', 'Dijkstra', 'BFS').\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            Union[List[Tuple[int, int]], None]: The path from start to goal, or None if the algorithm is not recognized.\n        \"\"\"\n        if algorithm == 'A*':\n            return self.a_star(start, goal)\n        elif algorithm == 'Dijkstra':\n            return self.dijkstra(start, goal)\n        elif algorithm == 'BFS':\n            return self.bfs(start, goal)\n        return None\n\n# Initialize pygame and the grid.\npygame.init()\ngrid = np.array([[0, 1, 0, 0], [0, 1, 0, 1], [0, 0, 0, 0], [1, 1, 1, 0]])\npathfinder = Pathfinding(grid)\nstart = (0, 0)\ngoal = (3, 3)\nalgorithm = 'A*'\npath = pathfinder.find_path(algorithm, start, goal)\nprint(path)",
    "rejected_code": "import pygame\nimport numpy as np\nimport networkx as nx\n\nclass Pathfinding:\n    def __init__(self, grid):\n        self.grid = grid\n        self.graph = self.create_graph()\n\n    def create_graph(self):\n        graph = nx.Graph()\n        rows, cols = self.grid.shape\n        for r in range(rows):\n            for c in range(cols):\n                if self.grid[r, c] == 0:\n                    if r > 0 and self.grid[r-1, c] == 0:\n                        graph.add_edge((r, c), (r-1, c))\n                    if c > 0 and self.grid[r, c-1] == 0:\n                        graph.add_edge((r, c), (r, c-1))\n                    if r < rows-1 and self.grid[r+1, c] == 0:\n                        graph.add_edge((r, c), (r+1, c))\n                    if c < cols-1 and self.grid[r, c+1] == 0:\n                        graph.add_edge((r, c), (r, c+1))\n        return graph\n\n    def a_star(self, start, goal):\n        return nx.astar_path(self.graph, start, goal)\n\n    def dijkstra(self, start, goal):\n        return nx.dijkstra_path(self.graph, start, goal)\n\n    def bfs(self, start, goal):\n        return nx.bfs_edges(self.graph, start)\n\n    def find_path(self, algorithm, start, goal):\n        if algorithm == 'A*':\n            return self.a_star(start, goal)\n        elif algorithm == 'Dijkstra':\n            return self.dijkstra(start, goal)\n        elif algorithm == 'BFS':\n            return self.bfs(start, goal)\n\npygame.init()\ngrid = np.array([[0, 1, 0, 0], [0, 1, 0, 1], [0, 0, 0, 0], [1, 1, 1, 0]])\npathfinder = Pathfinding(grid)\nstart = (0, 0)\ngoal = (3, 3)\nalgorithm = 'A*'\npath = pathfinder.find_path(algorithm, start, goal)\nprint(path)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.4285714285714284,
      "pep8_compliance": null,
      "comment_density": 0.009433962264150943,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.4285714285714284,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "games and simulation",
    "task": "Develop a pathfinding function with multiple algorithms",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you create a class with a method that takes specific input types and returns a pathfinding solution for a 2D grid-based game?",
      "role": "user"
    },
    "chosen_code": "import pygame\nimport numpy as np\nimport networkx as nx\nfrom typing import Tuple, List, Union\n\nclass Pathfinding:\n    def __init__(self, grid: np.ndarray) -> None:\n        \"\"\"\n        Initialize the Pathfinding class with a grid.\n        \n        Args:\n            grid (np.ndarray): A 2D numpy array representing the grid where 0 is walkable and 1 is an obstacle.\n        \"\"\"\n        self.grid = grid\n        self.graph = self.create_graph()\n\n    def create_graph(self) -> nx.Graph:\n        \"\"\"\n        Create a graph representation of the grid.\n        \n        Returns:\n            nx.Graph: A networkx graph representing the walkable paths in the grid.\n        \"\"\"\n        graph = nx.Graph()\n        rows, cols = self.grid.shape\n        for r in range(rows):\n            for c in range(cols):\n                if self.grid[r, c] == 0:\n                    if r > 0 and self.grid[r-1, c] == 0:\n                        graph.add_edge((r, c), (r-1, c))\n                    if c > 0 and self.grid[r, c-1] == 0:\n                        graph.add_edge((r, c), (r, c-1))\n                    if r < rows-1 and self.grid[r+1, c] == 0:\n                        graph.add_edge((r, c), (r+1, c))\n                    if c < cols-1 and self.grid[r, c+1] == 0:\n                        graph.add_edge((r, c), (r, c+1))\n        return graph\n\n    def a_star(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find the shortest path using the A* algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return nx.astar_path(self.graph, start, goal)\n\n    def dijkstra(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find the shortest path using Dijkstra's algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return nx.dijkstra_path(self.graph, start, goal)\n\n    def bfs(self, start: Tuple[int, int], goal: Tuple[int, int]) -> List[Tuple[int, int]]:\n        \"\"\"\n        Find a path using the BFS algorithm.\n        \n        Args:\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            List[Tuple[int, int]]: The path from start to goal.\n        \"\"\"\n        return list(nx.bfs_edges(self.graph, start))\n\n    def find_path(self, algorithm: str, start: Tuple[int, int], goal: Tuple[int, int]) -> Union[List[Tuple[int, int]], None]:\n        \"\"\"\n        Find a path from start to goal using the specified algorithm.\n        \n        Args:\n            algorithm (str): The pathfinding algorithm to use ('A*', 'Dijkstra', 'BFS').\n            start (Tuple[int, int]): The starting coordinates.\n            goal (Tuple[int, int]): The goal coordinates.\n        \n        Returns:\n            Union[List[Tuple[int, int]], None]: The path from start to goal, or None if the algorithm is not recognized.\n        \"\"\"\n        if algorithm == 'A*':\n            return self.a_star(start, goal)\n        elif algorithm == 'Dijkstra':\n            return self.dijkstra(start, goal)\n        elif algorithm == 'BFS':\n            return self.bfs(start, goal)\n        return None\n\n# Initialize pygame and the grid.\npygame.init()\ngrid = np.array([[0, 1, 0, 0], [0, 1, 0, 1], [0, 0, 0, 0], [1, 1, 1, 0]])\npathfinder = Pathfinding(grid)\nstart = (0, 0)\ngoal = (3, 3)\nalgorithm = 'A*'\npath = pathfinder.find_path(algorithm, start, goal)\nprint(path)",
    "rejected_code": "import pygame\nimport numpy as np\nimport networkx as nx\n\nclass Pathfinding:\n    def __init__(self, grid):\n        self.grid = grid\n        self.graph = self.create_graph()\n\n    def create_graph(self):\n        graph = nx.Graph()\n        rows, cols = self.grid.shape\n        for r in range(rows):\n            for c in range(cols):\n                if self.grid[r, c] == 0:\n                    if r > 0 and self.grid[r-1, c] == 0:\n                        graph.add_edge((r, c), (r-1, c))\n                    if c > 0 and self.grid[r, c-1] == 0:\n                        graph.add_edge((r, c), (r, c-1))\n                    if r < rows-1 and self.grid[r+1, c] == 0:\n                        graph.add_edge((r, c), (r+1, c))\n                    if c < cols-1 and self.grid[r, c+1] == 0:\n                        graph.add_edge((r, c), (r, c+1))\n        return graph\n\n    def a_star(self, start, goal):\n        return nx.astar_path(self.graph, start, goal)\n\n    def dijkstra(self, start, goal):\n        return nx.dijkstra_path(self.graph, start, goal)\n\n    def bfs(self, start, goal):\n        return nx.bfs_edges(self.graph, start)\n\n    def find_path(self, algorithm, start, goal):\n        if algorithm == 'A*':\n            return self.a_star(start, goal)\n        elif algorithm == 'Dijkstra':\n            return self.dijkstra(start, goal)\n        elif algorithm == 'BFS':\n            return self.bfs(start, goal)\n\npygame.init()\ngrid = np.array([[0, 1, 0, 0], [0, 1, 0, 1], [0, 0, 0, 0], [1, 1, 1, 0]])\npathfinder = Pathfinding(grid)\nstart = (0, 0)\ngoal = (3, 3)\nalgorithm = 'A*'\npath = pathfinder.find_path(algorithm, start, goal)\nprint(path)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.4285714285714284,
      "pep8_compliance": null,
      "comment_density": 0.009433962264150943,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.4285714285714284,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'pygame'"
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Develop a response parsing function with error handling",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide a Python code example that fetches and parses weather data from an API with error handling?",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom typing import Dict, Any, Union\n\n\ndef fetch_weather(city: str) -> Union[Dict[str, Any], Dict[str, str]]:\n    \"\"\"\n    Fetches the current weather data for a given city from the weather API.\n\n    Args:\n        city (str): The name of the city to fetch weather data for.\n\n    Returns:\n        Union[Dict[str, Any], Dict[str, str]]: A dictionary containing weather data or an error message.\n    \"\"\"\n    url = f'https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}'\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an error for bad responses (4xx and 5xx)\n        return parse_weather_response(response.json())\n    except RequestException as e:\n        return {'error': 'API request failed', 'details': str(e)}\n    except ValueError:\n        return {'error': 'Failed to parse JSON response'}\n\n\ndef parse_weather_response(data: Dict[str, Any]) -> Dict[str, Union[str, float]]:\n    \"\"\"\n    Parses the JSON response from the weather API.\n\n    Args:\n        data (Dict[str, Any]): The JSON data returned from the API.\n\n    Returns:\n        Dict[str, Union[str, float]]: A dictionary containing parsed weather information or an error message.\n    \"\"\"\n    if 'current' in data:\n        return {\n            'temperature': data['current']['temp_c'],\n            'condition': data['current']['condition']['text'],\n            'city': data['location']['name']\n        }\n    return {'error': 'Invalid response structure'}\n\n\nif __name__ == '__main__':\n    result = fetch_weather('London')\n    print(result)",
    "rejected_code": "import requests\nfrom requests.exceptions import RequestException\n\ndef fetch_weather(city):\n    url = f'https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}'\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        return parse_weather_response(response.json())\n    except RequestException as e:\n        return {'error': 'API request failed', 'details': str(e)}\n    except ValueError:\n        return {'error': 'Failed to parse JSON response'}\n\n\ndef parse_weather_response(data):\n    if 'current' in data:\n        return {\n            'temperature': data['current']['temp_c'],\n            'condition': data['current']['condition']['text'],\n            'city': data['location']['name']\n        }\n    return {'error': 'Invalid response structure'}\n\nresult = fetch_weather('London')\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'error': 'API request failed', 'details': '403 Client Error: Forbidden for url: https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=London'}",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'error': 'API request failed', 'details': '403 Client Error: Forbidden for url: https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=London'}",
        "error": ""
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Develop a response parsing function with error handling",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python function that fetches and parses weather data from an API with error handling.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom typing import Dict, Any, Union\n\n\ndef fetch_weather(city: str) -> Union[Dict[str, Any], Dict[str, str]]:\n    \"\"\"\n    Fetches the current weather data for a given city from the weather API.\n\n    Args:\n        city (str): The name of the city to fetch weather data for.\n\n    Returns:\n        Union[Dict[str, Any], Dict[str, str]]: A dictionary containing weather data or an error message.\n    \"\"\"\n    url = f'https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}'\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an error for bad responses (4xx and 5xx)\n        return parse_weather_response(response.json())\n    except RequestException as e:\n        return {'error': 'API request failed', 'details': str(e)}\n    except ValueError:\n        return {'error': 'Failed to parse JSON response'}\n\n\ndef parse_weather_response(data: Dict[str, Any]) -> Dict[str, Union[str, float]]:\n    \"\"\"\n    Parses the JSON response from the weather API.\n\n    Args:\n        data (Dict[str, Any]): The JSON data returned from the API.\n\n    Returns:\n        Dict[str, Union[str, float]]: A dictionary containing parsed weather information or an error message.\n    \"\"\"\n    if 'current' in data:\n        return {\n            'temperature': data['current']['temp_c'],\n            'condition': data['current']['condition']['text'],\n            'city': data['location']['name']\n        }\n    return {'error': 'Invalid response structure'}\n\n\nif __name__ == '__main__':\n    result = fetch_weather('London')\n    print(result)",
    "rejected_code": "import requests\nfrom requests.exceptions import RequestException\n\ndef fetch_weather(city):\n    url = f'https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}'\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        return parse_weather_response(response.json())\n    except RequestException as e:\n        return {'error': 'API request failed', 'details': str(e)}\n    except ValueError:\n        return {'error': 'Failed to parse JSON response'}\n\n\ndef parse_weather_response(data):\n    if 'current' in data:\n        return {\n            'temperature': data['current']['temp_c'],\n            'condition': data['current']['condition']['text'],\n            'city': data['location']['name']\n        }\n    return {'error': 'Invalid response structure'}\n\nresult = fetch_weather('London')\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'error': 'API request failed', 'details': '403 Client Error: Forbidden for url: https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=London'}",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'error': 'API request failed', 'details': '403 Client Error: Forbidden for url: https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=London'}",
        "error": ""
      }
    }
  },
  {
    "domain": "api and integration",
    "task": "Develop a response parsing function with error handling",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you create a Python function that takes a string as input (city name) and returns a dictionary with weather data or an error message?",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom requests.exceptions import RequestException\nfrom typing import Dict, Any, Union\n\n\ndef fetch_weather(city: str) -> Union[Dict[str, Any], Dict[str, str]]:\n    \"\"\"\n    Fetches the current weather data for a given city from the weather API.\n\n    Args:\n        city (str): The name of the city to fetch weather data for.\n\n    Returns:\n        Union[Dict[str, Any], Dict[str, str]]: A dictionary containing weather data or an error message.\n    \"\"\"\n    url = f'https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}'\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an error for bad responses (4xx and 5xx)\n        return parse_weather_response(response.json())\n    except RequestException as e:\n        return {'error': 'API request failed', 'details': str(e)}\n    except ValueError:\n        return {'error': 'Failed to parse JSON response'}\n\n\ndef parse_weather_response(data: Dict[str, Any]) -> Dict[str, Union[str, float]]:\n    \"\"\"\n    Parses the JSON response from the weather API.\n\n    Args:\n        data (Dict[str, Any]): The JSON data returned from the API.\n\n    Returns:\n        Dict[str, Union[str, float]]: A dictionary containing parsed weather information or an error message.\n    \"\"\"\n    if 'current' in data:\n        return {\n            'temperature': data['current']['temp_c'],\n            'condition': data['current']['condition']['text'],\n            'city': data['location']['name']\n        }\n    return {'error': 'Invalid response structure'}\n\n\nif __name__ == '__main__':\n    result = fetch_weather('London')\n    print(result)",
    "rejected_code": "import requests\nfrom requests.exceptions import RequestException\n\ndef fetch_weather(city):\n    url = f'https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={city}'\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        return parse_weather_response(response.json())\n    except RequestException as e:\n        return {'error': 'API request failed', 'details': str(e)}\n    except ValueError:\n        return {'error': 'Failed to parse JSON response'}\n\n\ndef parse_weather_response(data):\n    if 'current' in data:\n        return {\n            'temperature': data['current']['temp_c'],\n            'condition': data['current']['condition']['text'],\n            'city': data['location']['name']\n        }\n    return {'error': 'Invalid response structure'}\n\nresult = fetch_weather('London')\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'error': 'API request failed', 'details': '403 Client Error: Forbidden for url: https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=London'}",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "{'error': 'API request failed', 'details': '403 Client Error: Forbidden for url: https://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=London'}",
        "error": ""
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Create a sensor data collection and processing system",
    "code_form": "collector class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide code for a sensor data collection and processing system for a smart greenhouse?",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nimport random\nimport time\nfrom typing import Literal\n\nclass SensorCollector:\n    \"\"\"\n    A class that collects temperature and humidity data from sensors and publishes\n    this data to a specified MQTT broker topic.\n    \"\"\"\n\n    def __init__(self, broker: str, topic: str) -> None:\n        \"\"\"\n        Initializes the SensorCollector with the MQTT broker address and topic.\n\n        :param broker: The address of the MQTT broker.\n        :param topic: The topic to publish sensor data.\n        \"\"\"\n        self.broker: str = broker\n        self.topic: str = topic\n        self.client: mqtt.Client = mqtt.Client()\n        self.client.connect(self.broker)\n\n    def read_temperature(self) -> float:\n        \"\"\"\n        Simulates reading the temperature from a sensor.\n\n        :return: A float representing the temperature in degrees Celsius.\n        \"\"\"\n        return random.uniform(15.0, 30.0)\n\n    def read_humidity(self) -> float:\n        \"\"\"\n        Simulates reading the humidity from a sensor.\n\n        :return: A float representing the humidity percentage.\n        \"\"\"\n        return random.uniform(30.0, 90.0)\n\n    def publish_data(self) -> None:\n        \"\"\"\n        Continuously collects temperature and humidity data and publishes it to\n        the specified MQTT topic every 10 seconds.\n        \"\"\"\n        while True:\n            temperature: float = self.read_temperature()\n            humidity: float = self.read_humidity()\n            payload: str = f'Temperature: {temperature:.2f}C, Humidity: {humidity:.2f}%'\n            self.client.publish(self.topic, payload)\n            time.sleep(10)\n\nif __name__ == '__main__':\n    collector = SensorCollector('mqtt.eclipse.org', 'greenhouse/sensors')\n    collector.publish_data()",
    "rejected_code": "import paho.mqtt.client as mqtt\nimport random\nimport time\n\nclass SensorCollector:\n    def __init__(self, broker, topic):\n        self.broker = broker\n        self.topic = topic\n        self.client = mqtt.Client()\n        self.client.connect(self.broker)\n\n    def read_temperature(self):\n        return random.uniform(15.0, 30.0)\n\n    def read_humidity(self):\n        return random.uniform(30.0, 90.0)\n\n    def publish_data(self):\n        while True:\n            temperature = self.read_temperature()\n            humidity = self.read_humidity()\n            payload = f'Temperature: {temperature:.2f}C, Humidity: {humidity:.2f}%'\n            self.client.publish(self.topic, payload)\n            time.sleep(10)\n\nif __name__ == '__main__':\n    collector = SensorCollector('mqtt.eclipse.org', 'greenhouse/sensors')\n    collector.publish_data()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Create a sensor data collection and processing system",
    "code_form": "collector class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class that implements a sensor data collection and processing system for a smart greenhouse.",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nimport random\nimport time\nfrom typing import Literal\n\nclass SensorCollector:\n    \"\"\"\n    A class that collects temperature and humidity data from sensors and publishes\n    this data to a specified MQTT broker topic.\n    \"\"\"\n\n    def __init__(self, broker: str, topic: str) -> None:\n        \"\"\"\n        Initializes the SensorCollector with the MQTT broker address and topic.\n\n        :param broker: The address of the MQTT broker.\n        :param topic: The topic to publish sensor data.\n        \"\"\"\n        self.broker: str = broker\n        self.topic: str = topic\n        self.client: mqtt.Client = mqtt.Client()\n        self.client.connect(self.broker)\n\n    def read_temperature(self) -> float:\n        \"\"\"\n        Simulates reading the temperature from a sensor.\n\n        :return: A float representing the temperature in degrees Celsius.\n        \"\"\"\n        return random.uniform(15.0, 30.0)\n\n    def read_humidity(self) -> float:\n        \"\"\"\n        Simulates reading the humidity from a sensor.\n\n        :return: A float representing the humidity percentage.\n        \"\"\"\n        return random.uniform(30.0, 90.0)\n\n    def publish_data(self) -> None:\n        \"\"\"\n        Continuously collects temperature and humidity data and publishes it to\n        the specified MQTT topic every 10 seconds.\n        \"\"\"\n        while True:\n            temperature: float = self.read_temperature()\n            humidity: float = self.read_humidity()\n            payload: str = f'Temperature: {temperature:.2f}C, Humidity: {humidity:.2f}%'\n            self.client.publish(self.topic, payload)\n            time.sleep(10)\n\nif __name__ == '__main__':\n    collector = SensorCollector('mqtt.eclipse.org', 'greenhouse/sensors')\n    collector.publish_data()",
    "rejected_code": "import paho.mqtt.client as mqtt\nimport random\nimport time\n\nclass SensorCollector:\n    def __init__(self, broker, topic):\n        self.broker = broker\n        self.topic = topic\n        self.client = mqtt.Client()\n        self.client.connect(self.broker)\n\n    def read_temperature(self):\n        return random.uniform(15.0, 30.0)\n\n    def read_humidity(self):\n        return random.uniform(30.0, 90.0)\n\n    def publish_data(self):\n        while True:\n            temperature = self.read_temperature()\n            humidity = self.read_humidity()\n            payload = f'Temperature: {temperature:.2f}C, Humidity: {humidity:.2f}%'\n            self.client.publish(self.topic, payload)\n            time.sleep(10)\n\nif __name__ == '__main__':\n    collector = SensorCollector('mqtt.eclipse.org', 'greenhouse/sensors')\n    collector.publish_data()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Create a sensor data collection and processing system",
    "code_form": "collector class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a class that collects and processes sensor data for a smart greenhouse, ensuring to specify input/output types.",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nimport random\nimport time\nfrom typing import Literal\n\nclass SensorCollector:\n    \"\"\"\n    A class that collects temperature and humidity data from sensors and publishes\n    this data to a specified MQTT broker topic.\n    \"\"\"\n\n    def __init__(self, broker: str, topic: str) -> None:\n        \"\"\"\n        Initializes the SensorCollector with the MQTT broker address and topic.\n\n        :param broker: The address of the MQTT broker.\n        :param topic: The topic to publish sensor data.\n        \"\"\"\n        self.broker: str = broker\n        self.topic: str = topic\n        self.client: mqtt.Client = mqtt.Client()\n        self.client.connect(self.broker)\n\n    def read_temperature(self) -> float:\n        \"\"\"\n        Simulates reading the temperature from a sensor.\n\n        :return: A float representing the temperature in degrees Celsius.\n        \"\"\"\n        return random.uniform(15.0, 30.0)\n\n    def read_humidity(self) -> float:\n        \"\"\"\n        Simulates reading the humidity from a sensor.\n\n        :return: A float representing the humidity percentage.\n        \"\"\"\n        return random.uniform(30.0, 90.0)\n\n    def publish_data(self) -> None:\n        \"\"\"\n        Continuously collects temperature and humidity data and publishes it to\n        the specified MQTT topic every 10 seconds.\n        \"\"\"\n        while True:\n            temperature: float = self.read_temperature()\n            humidity: float = self.read_humidity()\n            payload: str = f'Temperature: {temperature:.2f}C, Humidity: {humidity:.2f}%'\n            self.client.publish(self.topic, payload)\n            time.sleep(10)\n\nif __name__ == '__main__':\n    collector = SensorCollector('mqtt.eclipse.org', 'greenhouse/sensors')\n    collector.publish_data()",
    "rejected_code": "import paho.mqtt.client as mqtt\nimport random\nimport time\n\nclass SensorCollector:\n    def __init__(self, broker, topic):\n        self.broker = broker\n        self.topic = topic\n        self.client = mqtt.Client()\n        self.client.connect(self.broker)\n\n    def read_temperature(self):\n        return random.uniform(15.0, 30.0)\n\n    def read_humidity(self):\n        return random.uniform(30.0, 90.0)\n\n    def publish_data(self):\n        while True:\n            temperature = self.read_temperature()\n            humidity = self.read_humidity()\n            payload = f'Temperature: {temperature:.2f}C, Humidity: {humidity:.2f}%'\n            self.client.publish(self.topic, payload)\n            time.sleep(10)\n\nif __name__ == '__main__':\n    collector = SensorCollector('mqtt.eclipse.org', 'greenhouse/sensors')\n    collector.publish_data()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Implement a message routing function for IoT devices",
    "code_form": "router function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to implement a message routing function for IoT devices?",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nfrom typing import Any, Callable, Dict, Optional\n\n\ndef on_message(client: mqtt.Client, userdata: Optional[Any], message: mqtt.MQTTMessage) -> None:\n    \"\"\"\n    Callback function that is called when a message is received from the MQTT broker.\n\n    Args:\n        client: The MQTT client instance.\n        userdata: User-defined data of any type that is passed into the callback.\n        message: The received MQTT message, containing the topic and payload.\n    \"\"\"\n    topic = message.topic\n    payload = message.payload.decode()\n    route_message(topic, payload)\n\n\ndef route_message(topic: str, payload: str) -> None:\n    \"\"\"\n    Routes the incoming message to the appropriate handler based on the topic.\n\n    Args:\n        topic: The topic of the received message.\n        payload: The payload of the received message as a string.\n    \"\"\"\n    if 'temperature' in topic:\n        handle_temperature(float(payload))\n    elif 'humidity' in topic:\n        handle_humidity(float(payload))\n    elif 'light/control' in topic:\n        handle_light_control(payload)\n\n\ndef handle_temperature(value: float) -> None:\n    \"\"\"\n    Handles temperature readings received from the temperature sensor.\n\n    Args:\n        value: The temperature value in degrees Celsius.\n    \"\"\"\n    print(f'Temperature reading: {value}\u00b0C')\n\n\ndef handle_humidity(value: float) -> None:\n    \"\"\"\n    Handles humidity readings received from the humidity sensor.\n\n    Args:\n        value: The humidity value as a percentage.\n    \"\"\"\n    print(f'Humidity reading: {value}%')\n\n\ndef handle_light_control(command: str) -> None:\n    \"\"\"\n    Controls the light based on the command received.\n\n    Args:\n        command: The command to control the light ('on' or 'off').\n    \"\"\"\n    if command == 'on':\n        print('Turning the light ON')\n    elif command == 'off':\n        print('Turning the light OFF')\n\n\n# MQTT Client setup\nclient = mqtt.Client()\nclient.on_message = on_message\nclient.connect('mqtt_broker_address')\nclient.subscribe('home/temperature')\nclient.subscribe('home/humidity')\nclient.subscribe('home/light/control')\nclient.loop_start()",
    "rejected_code": "import paho.mqtt.client as mqtt\n\ndef on_message(client, userdata, message):\n    topic = message.topic\n    payload = message.payload.decode()\n    route_message(topic, payload)\n\n\ndef route_message(topic, payload):\n    if 'temperature' in topic:\n        handle_temperature(float(payload))\n    elif 'humidity' in topic:\n        handle_humidity(float(payload))\n    elif 'light/control' in topic:\n        handle_light_control(payload)\n\n\ndef handle_temperature(value):\n    print(f'Temperature reading: {value}\u0000b0C')\n\n\ndef handle_humidity(value):\n    print(f'Humidity reading: {value}%')\n\n\ndef handle_light_control(command):\n    if command == 'on':\n        print('Turning the light ON')\n    elif command == 'off':\n        print('Turning the light OFF')\n\n\nclient = mqtt.Client()\nclient.on_message = on_message\nclient.connect('mqtt_broker_address')\nclient.subscribe('home/temperature')\nclient.subscribe('home/humidity')\nclient.subscribe('home/light/control')\nclient.loop_start()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.013333333333333334,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Implement a message routing function for IoT devices",
    "code_form": "router function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a Python function that implements a message routing function for IoT devices.",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nfrom typing import Any, Callable, Dict, Optional\n\n\ndef on_message(client: mqtt.Client, userdata: Optional[Any], message: mqtt.MQTTMessage) -> None:\n    \"\"\"\n    Callback function that is called when a message is received from the MQTT broker.\n\n    Args:\n        client: The MQTT client instance.\n        userdata: User-defined data of any type that is passed into the callback.\n        message: The received MQTT message, containing the topic and payload.\n    \"\"\"\n    topic = message.topic\n    payload = message.payload.decode()\n    route_message(topic, payload)\n\n\ndef route_message(topic: str, payload: str) -> None:\n    \"\"\"\n    Routes the incoming message to the appropriate handler based on the topic.\n\n    Args:\n        topic: The topic of the received message.\n        payload: The payload of the received message as a string.\n    \"\"\"\n    if 'temperature' in topic:\n        handle_temperature(float(payload))\n    elif 'humidity' in topic:\n        handle_humidity(float(payload))\n    elif 'light/control' in topic:\n        handle_light_control(payload)\n\n\ndef handle_temperature(value: float) -> None:\n    \"\"\"\n    Handles temperature readings received from the temperature sensor.\n\n    Args:\n        value: The temperature value in degrees Celsius.\n    \"\"\"\n    print(f'Temperature reading: {value}\u00b0C')\n\n\ndef handle_humidity(value: float) -> None:\n    \"\"\"\n    Handles humidity readings received from the humidity sensor.\n\n    Args:\n        value: The humidity value as a percentage.\n    \"\"\"\n    print(f'Humidity reading: {value}%')\n\n\ndef handle_light_control(command: str) -> None:\n    \"\"\"\n    Controls the light based on the command received.\n\n    Args:\n        command: The command to control the light ('on' or 'off').\n    \"\"\"\n    if command == 'on':\n        print('Turning the light ON')\n    elif command == 'off':\n        print('Turning the light OFF')\n\n\n# MQTT Client setup\nclient = mqtt.Client()\nclient.on_message = on_message\nclient.connect('mqtt_broker_address')\nclient.subscribe('home/temperature')\nclient.subscribe('home/humidity')\nclient.subscribe('home/light/control')\nclient.loop_start()",
    "rejected_code": "import paho.mqtt.client as mqtt\n\ndef on_message(client, userdata, message):\n    topic = message.topic\n    payload = message.payload.decode()\n    route_message(topic, payload)\n\n\ndef route_message(topic, payload):\n    if 'temperature' in topic:\n        handle_temperature(float(payload))\n    elif 'humidity' in topic:\n        handle_humidity(float(payload))\n    elif 'light/control' in topic:\n        handle_light_control(payload)\n\n\ndef handle_temperature(value):\n    print(f'Temperature reading: {value}\u0000b0C')\n\n\ndef handle_humidity(value):\n    print(f'Humidity reading: {value}%')\n\n\ndef handle_light_control(command):\n    if command == 'on':\n        print('Turning the light ON')\n    elif command == 'off':\n        print('Turning the light OFF')\n\n\nclient = mqtt.Client()\nclient.on_message = on_message\nclient.connect('mqtt_broker_address')\nclient.subscribe('home/temperature')\nclient.subscribe('home/humidity')\nclient.subscribe('home/light/control')\nclient.loop_start()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.013333333333333334,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Implement a message routing function for IoT devices",
    "code_form": "router function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python function with type annotations that implements a message routing function for IoT devices, specifying input and output types.",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nfrom typing import Any, Callable, Dict, Optional\n\n\ndef on_message(client: mqtt.Client, userdata: Optional[Any], message: mqtt.MQTTMessage) -> None:\n    \"\"\"\n    Callback function that is called when a message is received from the MQTT broker.\n\n    Args:\n        client: The MQTT client instance.\n        userdata: User-defined data of any type that is passed into the callback.\n        message: The received MQTT message, containing the topic and payload.\n    \"\"\"\n    topic = message.topic\n    payload = message.payload.decode()\n    route_message(topic, payload)\n\n\ndef route_message(topic: str, payload: str) -> None:\n    \"\"\"\n    Routes the incoming message to the appropriate handler based on the topic.\n\n    Args:\n        topic: The topic of the received message.\n        payload: The payload of the received message as a string.\n    \"\"\"\n    if 'temperature' in topic:\n        handle_temperature(float(payload))\n    elif 'humidity' in topic:\n        handle_humidity(float(payload))\n    elif 'light/control' in topic:\n        handle_light_control(payload)\n\n\ndef handle_temperature(value: float) -> None:\n    \"\"\"\n    Handles temperature readings received from the temperature sensor.\n\n    Args:\n        value: The temperature value in degrees Celsius.\n    \"\"\"\n    print(f'Temperature reading: {value}\u00b0C')\n\n\ndef handle_humidity(value: float) -> None:\n    \"\"\"\n    Handles humidity readings received from the humidity sensor.\n\n    Args:\n        value: The humidity value as a percentage.\n    \"\"\"\n    print(f'Humidity reading: {value}%')\n\n\ndef handle_light_control(command: str) -> None:\n    \"\"\"\n    Controls the light based on the command received.\n\n    Args:\n        command: The command to control the light ('on' or 'off').\n    \"\"\"\n    if command == 'on':\n        print('Turning the light ON')\n    elif command == 'off':\n        print('Turning the light OFF')\n\n\n# MQTT Client setup\nclient = mqtt.Client()\nclient.on_message = on_message\nclient.connect('mqtt_broker_address')\nclient.subscribe('home/temperature')\nclient.subscribe('home/humidity')\nclient.subscribe('home/light/control')\nclient.loop_start()",
    "rejected_code": "import paho.mqtt.client as mqtt\n\ndef on_message(client, userdata, message):\n    topic = message.topic\n    payload = message.payload.decode()\n    route_message(topic, payload)\n\n\ndef route_message(topic, payload):\n    if 'temperature' in topic:\n        handle_temperature(float(payload))\n    elif 'humidity' in topic:\n        handle_humidity(float(payload))\n    elif 'light/control' in topic:\n        handle_light_control(payload)\n\n\ndef handle_temperature(value):\n    print(f'Temperature reading: {value}\u0000b0C')\n\n\ndef handle_humidity(value):\n    print(f'Humidity reading: {value}%')\n\n\ndef handle_light_control(command):\n    if command == 'on':\n        print('Turning the light ON')\n    elif command == 'off':\n        print('Turning the light OFF')\n\n\nclient = mqtt.Client()\nclient.on_message = on_message\nclient.connect('mqtt_broker_address')\nclient.subscribe('home/temperature')\nclient.subscribe('home/humidity')\nclient.subscribe('home/light/control')\nclient.loop_start()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.013333333333333334,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Build a sequence alignment and comparison system",
    "code_form": "aligner class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to build a sequence alignment and comparison system for gene sequences from multiple species?",
      "role": "user"
    },
    "chosen_code": "from Bio import AlignIO\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio import SeqIO\nfrom Bio.SeqRecord import SeqRecord\nfrom typing import List\n\nclass Aligner:\n    \"\"\"\n    A class to perform multiple sequence alignment on a collection of sequences.\n    \"\"\"\n\n    def __init__(self, sequences: List[SeqRecord]) -> None:\n        \"\"\"\n        Initializes the Aligner with a list of sequence records.\n        \n        :param sequences: A list of SeqRecord objects representing sequences to align.\n        \"\"\"\n        self.sequences = sequences\n\n    def perform_alignment(self) -> MultipleSeqAlignment:\n        \"\"\"\n        Performs the alignment of the provided sequences.\n        \n        :return: A MultipleSeqAlignment object containing the aligned sequences.\n        \"\"\"\n        alignment = MultipleSeqAlignment(self.sequences)\n        return alignment\n\ndef main(input_file: str, output_file: str) -> None:\n    \"\"\"\n    Reads sequences from a FASTA file, aligns them, and writes the output to a file.\n    \n    :param input_file: Path to the input FASTA file containing sequences.\n    :param output_file: Path to the output file where aligned sequences will be saved.\n    \"\"\"\n    sequences = []\n    for record in SeqIO.parse(input_file, 'fasta'):\n        sequences.append(record)\n\n    aligner = Aligner(sequences)\n    aligned_sequences = aligner.perform_alignment()\n    AlignIO.write(aligned_sequences, output_file, 'clustal')\n\nif __name__ == '__main__':\n    main('species_sequences.fasta', 'aligned_output.aln')",
    "rejected_code": "from Bio import AlignIO\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio import SeqIO\n\nclass Aligner:\n    def __init__(self, sequences):\n        self.sequences = sequences\n\n    def perform_alignment(self):\n        alignment = MultipleSeqAlignment(self.sequences)\n        return alignment\n\nsequences = []\nfor record in SeqIO.parse('species_sequences.fasta', 'fasta'):\n    sequences.append(record)\n\naligner = Aligner(sequences)\naligned_sequences = aligner.perform_alignment()\nAlignIO.write(aligned_sequences, 'aligned_output.aln', 'clustal')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Build a sequence alignment and comparison system",
    "code_form": "aligner class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Could you write a class in Python that implements a sequence alignment and comparison system for gene sequences from multiple species?",
      "role": "user"
    },
    "chosen_code": "from Bio import AlignIO\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio import SeqIO\nfrom Bio.SeqRecord import SeqRecord\nfrom typing import List\n\nclass Aligner:\n    \"\"\"\n    A class to perform multiple sequence alignment on a collection of sequences.\n    \"\"\"\n\n    def __init__(self, sequences: List[SeqRecord]) -> None:\n        \"\"\"\n        Initializes the Aligner with a list of sequence records.\n        \n        :param sequences: A list of SeqRecord objects representing sequences to align.\n        \"\"\"\n        self.sequences = sequences\n\n    def perform_alignment(self) -> MultipleSeqAlignment:\n        \"\"\"\n        Performs the alignment of the provided sequences.\n        \n        :return: A MultipleSeqAlignment object containing the aligned sequences.\n        \"\"\"\n        alignment = MultipleSeqAlignment(self.sequences)\n        return alignment\n\ndef main(input_file: str, output_file: str) -> None:\n    \"\"\"\n    Reads sequences from a FASTA file, aligns them, and writes the output to a file.\n    \n    :param input_file: Path to the input FASTA file containing sequences.\n    :param output_file: Path to the output file where aligned sequences will be saved.\n    \"\"\"\n    sequences = []\n    for record in SeqIO.parse(input_file, 'fasta'):\n        sequences.append(record)\n\n    aligner = Aligner(sequences)\n    aligned_sequences = aligner.perform_alignment()\n    AlignIO.write(aligned_sequences, output_file, 'clustal')\n\nif __name__ == '__main__':\n    main('species_sequences.fasta', 'aligned_output.aln')",
    "rejected_code": "from Bio import AlignIO\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio import SeqIO\n\nclass Aligner:\n    def __init__(self, sequences):\n        self.sequences = sequences\n\n    def perform_alignment(self):\n        alignment = MultipleSeqAlignment(self.sequences)\n        return alignment\n\nsequences = []\nfor record in SeqIO.parse('species_sequences.fasta', 'fasta'):\n    sequences.append(record)\n\naligner = Aligner(sequences)\naligned_sequences = aligner.perform_alignment()\nAlignIO.write(aligned_sequences, 'aligned_output.aln', 'clustal')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Build a sequence alignment and comparison system",
    "code_form": "aligner class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please generate a Python class that implements a sequence alignment and comparison system, specifying that the input is a list of sequence records and the output is an aligned sequence object.",
      "role": "user"
    },
    "chosen_code": "from Bio import AlignIO\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio import SeqIO\nfrom Bio.SeqRecord import SeqRecord\nfrom typing import List\n\nclass Aligner:\n    \"\"\"\n    A class to perform multiple sequence alignment on a collection of sequences.\n    \"\"\"\n\n    def __init__(self, sequences: List[SeqRecord]) -> None:\n        \"\"\"\n        Initializes the Aligner with a list of sequence records.\n        \n        :param sequences: A list of SeqRecord objects representing sequences to align.\n        \"\"\"\n        self.sequences = sequences\n\n    def perform_alignment(self) -> MultipleSeqAlignment:\n        \"\"\"\n        Performs the alignment of the provided sequences.\n        \n        :return: A MultipleSeqAlignment object containing the aligned sequences.\n        \"\"\"\n        alignment = MultipleSeqAlignment(self.sequences)\n        return alignment\n\ndef main(input_file: str, output_file: str) -> None:\n    \"\"\"\n    Reads sequences from a FASTA file, aligns them, and writes the output to a file.\n    \n    :param input_file: Path to the input FASTA file containing sequences.\n    :param output_file: Path to the output file where aligned sequences will be saved.\n    \"\"\"\n    sequences = []\n    for record in SeqIO.parse(input_file, 'fasta'):\n        sequences.append(record)\n\n    aligner = Aligner(sequences)\n    aligned_sequences = aligner.perform_alignment()\n    AlignIO.write(aligned_sequences, output_file, 'clustal')\n\nif __name__ == '__main__':\n    main('species_sequences.fasta', 'aligned_output.aln')",
    "rejected_code": "from Bio import AlignIO\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio import SeqIO\n\nclass Aligner:\n    def __init__(self, sequences):\n        self.sequences = sequences\n\n    def perform_alignment(self):\n        alignment = MultipleSeqAlignment(self.sequences)\n        return alignment\n\nsequences = []\nfor record in SeqIO.parse('species_sequences.fasta', 'fasta'):\n    sequences.append(record)\n\naligner = Aligner(sequences)\naligned_sequences = aligner.perform_alignment()\nAlignIO.write(aligned_sequences, 'aligned_output.aln', 'clustal')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Implement a gene expression analysis function",
    "code_form": "analyzer function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to analyze gene expression data and identify differentially expressed genes.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nfrom typing import Tuple, Any, pd\n\n\ndef analyze_gene_expression(file_path: str) -> pd.DataFrame:\n    \"\"\"\n    Analyzes gene expression data from RNA-Seq experiments to identify differentially expressed genes\n    between treated and control conditions.\n    \n    Parameters:\n    file_path (str): The path to the CSV file containing gene expression data with columns 'gene_id', 'treated', and 'control'.\n    \n    Returns:\n    pd.DataFrame: A DataFrame containing significant genes with their log2 fold change,\n                   where the absolute log2 fold change is greater than 1.\n    \"\"\"\n    # Load gene expression data from the specified CSV file\n    data: pd.DataFrame = pd.read_csv(file_path)\n    \n    # Calculate the log2 fold change between treated and control conditions\n    data['log2_fold_change'] = (data['treated'] + 1).apply(np.log2) - (data['control'] + 1).apply(np.log2)\n    \n    # Filter significant genes based on the absolute log2 fold change threshold\n    significant_genes: pd.DataFrame = data[data['log2_fold_change'].abs() > 1]\n    \n    # Return the DataFrame containing only gene IDs and their log2 fold changes\n    return significant_genes[['gene_id', 'log2_fold_change']]\n\n\n# Example usage of the analyze_gene_expression function\nif __name__ == '__main__':\n    result: pd.DataFrame = analyze_gene_expression('gene_expression_data.csv')\n    print(result)",
    "rejected_code": "import pandas as pd\n\ndef analyze_gene_expression(file_path):\n    data = pd.read_csv(file_path)\n    data['log2_fold_change'] = (data['treated'] + 1).apply(lambda x: np.log2(x)) - (data['control'] + 1).apply(lambda x: np.log2(x))\n    significant_genes = data[data['log2_fold_change'].abs() > 1]\n    return significant_genes[['gene_id', 'log2_fold_change']]\n\nresult = analyze_gene_expression('gene_expression_data.csv')\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.14705882352941177,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nImportError: cannot import name 'pd' from 'typing' (/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/typing.py)"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 9, in <module>\n  File \"<string>\", line 4, in analyze_gene_expression\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 873, in get_handle\n    handle = open(\n             ^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'gene_expression_data.csv'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Implement a gene expression analysis function",
    "code_form": "analyzer function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a function that analyzes gene expression data and identifies differentially expressed genes.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nfrom typing import Tuple, Any, pd\n\n\ndef analyze_gene_expression(file_path: str) -> pd.DataFrame:\n    \"\"\"\n    Analyzes gene expression data from RNA-Seq experiments to identify differentially expressed genes\n    between treated and control conditions.\n    \n    Parameters:\n    file_path (str): The path to the CSV file containing gene expression data with columns 'gene_id', 'treated', and 'control'.\n    \n    Returns:\n    pd.DataFrame: A DataFrame containing significant genes with their log2 fold change,\n                   where the absolute log2 fold change is greater than 1.\n    \"\"\"\n    # Load gene expression data from the specified CSV file\n    data: pd.DataFrame = pd.read_csv(file_path)\n    \n    # Calculate the log2 fold change between treated and control conditions\n    data['log2_fold_change'] = (data['treated'] + 1).apply(np.log2) - (data['control'] + 1).apply(np.log2)\n    \n    # Filter significant genes based on the absolute log2 fold change threshold\n    significant_genes: pd.DataFrame = data[data['log2_fold_change'].abs() > 1]\n    \n    # Return the DataFrame containing only gene IDs and their log2 fold changes\n    return significant_genes[['gene_id', 'log2_fold_change']]\n\n\n# Example usage of the analyze_gene_expression function\nif __name__ == '__main__':\n    result: pd.DataFrame = analyze_gene_expression('gene_expression_data.csv')\n    print(result)",
    "rejected_code": "import pandas as pd\n\ndef analyze_gene_expression(file_path):\n    data = pd.read_csv(file_path)\n    data['log2_fold_change'] = (data['treated'] + 1).apply(lambda x: np.log2(x)) - (data['control'] + 1).apply(lambda x: np.log2(x))\n    significant_genes = data[data['log2_fold_change'].abs() > 1]\n    return significant_genes[['gene_id', 'log2_fold_change']]\n\nresult = analyze_gene_expression('gene_expression_data.csv')\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.14705882352941177,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nImportError: cannot import name 'pd' from 'typing' (/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/typing.py)"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 9, in <module>\n  File \"<string>\", line 4, in analyze_gene_expression\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 873, in get_handle\n    handle = open(\n             ^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'gene_expression_data.csv'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Implement a gene expression analysis function",
    "code_form": "analyzer function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a function that takes a string as input (file path) and returns a pandas DataFrame containing the results of the gene expression analysis.",
      "role": "user"
    },
    "chosen_code": "import pandas as pd\nimport numpy as np\nfrom typing import Tuple, Any, pd\n\n\ndef analyze_gene_expression(file_path: str) -> pd.DataFrame:\n    \"\"\"\n    Analyzes gene expression data from RNA-Seq experiments to identify differentially expressed genes\n    between treated and control conditions.\n    \n    Parameters:\n    file_path (str): The path to the CSV file containing gene expression data with columns 'gene_id', 'treated', and 'control'.\n    \n    Returns:\n    pd.DataFrame: A DataFrame containing significant genes with their log2 fold change,\n                   where the absolute log2 fold change is greater than 1.\n    \"\"\"\n    # Load gene expression data from the specified CSV file\n    data: pd.DataFrame = pd.read_csv(file_path)\n    \n    # Calculate the log2 fold change between treated and control conditions\n    data['log2_fold_change'] = (data['treated'] + 1).apply(np.log2) - (data['control'] + 1).apply(np.log2)\n    \n    # Filter significant genes based on the absolute log2 fold change threshold\n    significant_genes: pd.DataFrame = data[data['log2_fold_change'].abs() > 1]\n    \n    # Return the DataFrame containing only gene IDs and their log2 fold changes\n    return significant_genes[['gene_id', 'log2_fold_change']]\n\n\n# Example usage of the analyze_gene_expression function\nif __name__ == '__main__':\n    result: pd.DataFrame = analyze_gene_expression('gene_expression_data.csv')\n    print(result)",
    "rejected_code": "import pandas as pd\n\ndef analyze_gene_expression(file_path):\n    data = pd.read_csv(file_path)\n    data['log2_fold_change'] = (data['treated'] + 1).apply(lambda x: np.log2(x)) - (data['control'] + 1).apply(lambda x: np.log2(x))\n    significant_genes = data[data['log2_fold_change'].abs() > 1]\n    return significant_genes[['gene_id', 'log2_fold_change']]\n\nresult = analyze_gene_expression('gene_expression_data.csv')\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.14705882352941177,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nImportError: cannot import name 'pd' from 'typing' (/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/typing.py)"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 9, in <module>\n  File \"<string>\", line 4, in analyze_gene_expression\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/Users/theopezel/anaconda3/envs/dpo-env/lib/python3.11/site-packages/pandas/io/common.py\", line 873, in get_handle\n    handle = open(\n             ^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'gene_expression_data.csv'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Build a device connection management class with auto-discovery",
    "code_form": "manager class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide code to build a device connection management class with auto-discovery for IoT devices using MQTT?",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nfrom typing import Dict, Any\n\nclass DeviceManager:\n    \"\"\"\n    A class to manage IoT devices in a smart home system using MQTT.\n    It handles device discovery, connection management, and data publishing.\n    \"\"\"\n\n    def __init__(self, broker_address: str) -> None:\n        \"\"\"\n        Initializes the DeviceManager with the MQTT broker address.\n\n        Args:\n            broker_address (str): The address of the MQTT broker.\n        \"\"\"\n        self.broker_address: str = broker_address\n        self.client: mqtt.Client = mqtt.Client()\n        self.devices: Dict[str, bool] = {}\n        self.client.on_message = self.on_message\n\n    def connect(self) -> None:\n        \"\"\"\n        Connects to the MQTT broker and starts the loop for processing messages.\n        Subscribes to the 'device/discover' topic to listen for device discovery messages.\n        \"\"\"\n        self.client.connect(self.broker_address)\n        self.client.loop_start()\n        self.client.subscribe('device/discover')\n\n    def on_message(self, client: mqtt.Client, userdata: Any, msg: mqtt.MQTTMessage) -> None:\n        \"\"\"\n        Callback method that is called when a message is received on a subscribed topic.\n        It decodes the message payload and adds the device if it is not already present.\n\n        Args:\n            client (mqtt.Client): The client instance for this callback.\n            userdata (Any): The private user data as set in Client() or subscribe().\n            msg (mqtt.MQTTMessage): The message instance that contains the topic and payload.\n        \"\"\"\n        device_info: str = msg.payload.decode()\n        self.add_device(device_info)\n\n    def add_device(self, device_info: str) -> None:\n        \"\"\"\n        Adds a new device to the manager if it is not already present.\n\n        Args:\n            device_info (str): The identifier for the device to be added.\n        \"\"\"\n        if device_info not in self.devices:\n            self.devices[device_info] = True\n            print(f'Device added: {device_info}')\n\n    def publish_data(self, device_info: str, data: Any) -> None:\n        \"\"\"\n        Publishes data to the specified device topic if the device is managed.\n\n        Args:\n            device_info (str): The identifier for the device.\n            data (Any): The data to be published to the device.\n        \"\"\"\n        if device_info in self.devices:\n            self.client.publish(f'device/{device_info}/data', data)\n\n    def disconnect(self) -> None:\n        \"\"\"\n        Stops the MQTT loop and disconnects from the broker.\n        \"\"\"\n        self.client.loop_stop()\n        self.client.disconnect()\n\n# Example usage\nif __name__ == '__main__':\n    manager = DeviceManager('mqtt.example.com')\n    manager.connect()",
    "rejected_code": "import paho.mqtt.client as mqtt\n\nclass DeviceManager:\n    def __init__(self, broker_address):\n        self.broker_address = broker_address\n        self.client = mqtt.Client()\n        self.devices = {}\n        self.client.on_message = self.on_message\n\n    def connect(self):\n        self.client.connect(self.broker_address)\n        self.client.loop_start()\n        self.client.subscribe('device/discover')\n\n    def on_message(self, client, userdata, msg):\n        device_info = msg.payload.decode()\n        self.add_device(device_info)\n\n    def add_device(self, device_info):\n        if device_info not in self.devices:\n            self.devices[device_info] = True\n            print(f'Device added: {device_info}')\n\n    def publish_data(self, device_info, data):\n        if device_info in self.devices:\n            self.client.publish(f'device/{device_info}/data', data)\n\n    def disconnect(self):\n        self.client.loop_stop()\n        self.client.disconnect()\n\nmanager = DeviceManager('mqtt.example.com')\nmanager.connect()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.013157894736842105,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Build a device connection management class with auto-discovery",
    "code_form": "manager class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a class that implements a device connection management system with auto-discovery for IoT devices using MQTT.",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nfrom typing import Dict, Any\n\nclass DeviceManager:\n    \"\"\"\n    A class to manage IoT devices in a smart home system using MQTT.\n    It handles device discovery, connection management, and data publishing.\n    \"\"\"\n\n    def __init__(self, broker_address: str) -> None:\n        \"\"\"\n        Initializes the DeviceManager with the MQTT broker address.\n\n        Args:\n            broker_address (str): The address of the MQTT broker.\n        \"\"\"\n        self.broker_address: str = broker_address\n        self.client: mqtt.Client = mqtt.Client()\n        self.devices: Dict[str, bool] = {}\n        self.client.on_message = self.on_message\n\n    def connect(self) -> None:\n        \"\"\"\n        Connects to the MQTT broker and starts the loop for processing messages.\n        Subscribes to the 'device/discover' topic to listen for device discovery messages.\n        \"\"\"\n        self.client.connect(self.broker_address)\n        self.client.loop_start()\n        self.client.subscribe('device/discover')\n\n    def on_message(self, client: mqtt.Client, userdata: Any, msg: mqtt.MQTTMessage) -> None:\n        \"\"\"\n        Callback method that is called when a message is received on a subscribed topic.\n        It decodes the message payload and adds the device if it is not already present.\n\n        Args:\n            client (mqtt.Client): The client instance for this callback.\n            userdata (Any): The private user data as set in Client() or subscribe().\n            msg (mqtt.MQTTMessage): The message instance that contains the topic and payload.\n        \"\"\"\n        device_info: str = msg.payload.decode()\n        self.add_device(device_info)\n\n    def add_device(self, device_info: str) -> None:\n        \"\"\"\n        Adds a new device to the manager if it is not already present.\n\n        Args:\n            device_info (str): The identifier for the device to be added.\n        \"\"\"\n        if device_info not in self.devices:\n            self.devices[device_info] = True\n            print(f'Device added: {device_info}')\n\n    def publish_data(self, device_info: str, data: Any) -> None:\n        \"\"\"\n        Publishes data to the specified device topic if the device is managed.\n\n        Args:\n            device_info (str): The identifier for the device.\n            data (Any): The data to be published to the device.\n        \"\"\"\n        if device_info in self.devices:\n            self.client.publish(f'device/{device_info}/data', data)\n\n    def disconnect(self) -> None:\n        \"\"\"\n        Stops the MQTT loop and disconnects from the broker.\n        \"\"\"\n        self.client.loop_stop()\n        self.client.disconnect()\n\n# Example usage\nif __name__ == '__main__':\n    manager = DeviceManager('mqtt.example.com')\n    manager.connect()",
    "rejected_code": "import paho.mqtt.client as mqtt\n\nclass DeviceManager:\n    def __init__(self, broker_address):\n        self.broker_address = broker_address\n        self.client = mqtt.Client()\n        self.devices = {}\n        self.client.on_message = self.on_message\n\n    def connect(self):\n        self.client.connect(self.broker_address)\n        self.client.loop_start()\n        self.client.subscribe('device/discover')\n\n    def on_message(self, client, userdata, msg):\n        device_info = msg.payload.decode()\n        self.add_device(device_info)\n\n    def add_device(self, device_info):\n        if device_info not in self.devices:\n            self.devices[device_info] = True\n            print(f'Device added: {device_info}')\n\n    def publish_data(self, device_info, data):\n        if device_info in self.devices:\n            self.client.publish(f'device/{device_info}/data', data)\n\n    def disconnect(self):\n        self.client.loop_stop()\n        self.client.disconnect()\n\nmanager = DeviceManager('mqtt.example.com')\nmanager.connect()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.013157894736842105,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Build a device connection management class with auto-discovery",
    "code_form": "manager class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a class that manages device connections with auto-discovery using MQTT, ensuring to include type annotations for input and output.",
      "role": "user"
    },
    "chosen_code": "import paho.mqtt.client as mqtt\nfrom typing import Dict, Any\n\nclass DeviceManager:\n    \"\"\"\n    A class to manage IoT devices in a smart home system using MQTT.\n    It handles device discovery, connection management, and data publishing.\n    \"\"\"\n\n    def __init__(self, broker_address: str) -> None:\n        \"\"\"\n        Initializes the DeviceManager with the MQTT broker address.\n\n        Args:\n            broker_address (str): The address of the MQTT broker.\n        \"\"\"\n        self.broker_address: str = broker_address\n        self.client: mqtt.Client = mqtt.Client()\n        self.devices: Dict[str, bool] = {}\n        self.client.on_message = self.on_message\n\n    def connect(self) -> None:\n        \"\"\"\n        Connects to the MQTT broker and starts the loop for processing messages.\n        Subscribes to the 'device/discover' topic to listen for device discovery messages.\n        \"\"\"\n        self.client.connect(self.broker_address)\n        self.client.loop_start()\n        self.client.subscribe('device/discover')\n\n    def on_message(self, client: mqtt.Client, userdata: Any, msg: mqtt.MQTTMessage) -> None:\n        \"\"\"\n        Callback method that is called when a message is received on a subscribed topic.\n        It decodes the message payload and adds the device if it is not already present.\n\n        Args:\n            client (mqtt.Client): The client instance for this callback.\n            userdata (Any): The private user data as set in Client() or subscribe().\n            msg (mqtt.MQTTMessage): The message instance that contains the topic and payload.\n        \"\"\"\n        device_info: str = msg.payload.decode()\n        self.add_device(device_info)\n\n    def add_device(self, device_info: str) -> None:\n        \"\"\"\n        Adds a new device to the manager if it is not already present.\n\n        Args:\n            device_info (str): The identifier for the device to be added.\n        \"\"\"\n        if device_info not in self.devices:\n            self.devices[device_info] = True\n            print(f'Device added: {device_info}')\n\n    def publish_data(self, device_info: str, data: Any) -> None:\n        \"\"\"\n        Publishes data to the specified device topic if the device is managed.\n\n        Args:\n            device_info (str): The identifier for the device.\n            data (Any): The data to be published to the device.\n        \"\"\"\n        if device_info in self.devices:\n            self.client.publish(f'device/{device_info}/data', data)\n\n    def disconnect(self) -> None:\n        \"\"\"\n        Stops the MQTT loop and disconnects from the broker.\n        \"\"\"\n        self.client.loop_stop()\n        self.client.disconnect()\n\n# Example usage\nif __name__ == '__main__':\n    manager = DeviceManager('mqtt.example.com')\n    manager.connect()",
    "rejected_code": "import paho.mqtt.client as mqtt\n\nclass DeviceManager:\n    def __init__(self, broker_address):\n        self.broker_address = broker_address\n        self.client = mqtt.Client()\n        self.devices = {}\n        self.client.on_message = self.on_message\n\n    def connect(self):\n        self.client.connect(self.broker_address)\n        self.client.loop_start()\n        self.client.subscribe('device/discover')\n\n    def on_message(self, client, userdata, msg):\n        device_info = msg.payload.decode()\n        self.add_device(device_info)\n\n    def add_device(self, device_info):\n        if device_info not in self.devices:\n            self.devices[device_info] = True\n            print(f'Device added: {device_info}')\n\n    def publish_data(self, device_info, data):\n        if device_info in self.devices:\n            self.client.publish(f'device/{device_info}/data', data)\n\n    def disconnect(self):\n        self.client.loop_stop()\n        self.client.disconnect()\n\nmanager = DeviceManager('mqtt.example.com')\nmanager.connect()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.013157894736842105,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.4285714285714286,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'paho'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Develop a time series data storage function with efficient compression",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to develop a time series data storage function with efficient compression for a smart weather station.",
      "role": "user"
    },
    "chosen_code": "import json\nimport zlib\nfrom influxdb import InfluxDBClient\nimport time\nfrom typing import Dict, Any\n\nclass WeatherStation:\n    def __init__(self, host: str, port: int, user: str, password: str, dbname: str) -> None:\n        \"\"\"\n        Initialize the InfluxDB client for storing weather data.\n        \n        :param host: The hostname of the InfluxDB server.\n        :param port: The port number of the InfluxDB server.\n        :param user: The username for authentication.\n        :param password: The password for authentication.\n        :param dbname: The name of the database to use.\n        \"\"\"  \n        self.client = InfluxDBClient(host, port, user, password, dbname)\n\n    def compress_data(self, data: Dict[str, Any]) -> bytes:\n        \"\"\"\n        Compress the provided data using zlib.\n        \n        :param data: The data to compress, in dictionary format.\n        :return: Compressed data as bytes.\n        \"\"\"  \n        return zlib.compress(json.dumps(data).encode('utf-8'))\n\n    def store_data(self, timestamp: int, temperature: float, humidity: float) -> None:\n        \"\"\"\n        Store the weather data in the InfluxDB database after compressing it.\n        \n        :param timestamp: The timestamp of the data point (in milliseconds).\n        :param temperature: The temperature value to store.\n        :param humidity: The humidity value to store.\n        \"\"\"  \n        data = [{\n            'measurement': 'weather',\n            'tags': {'sensor': 'sensor1'},\n            'time': timestamp,\n            'fields': {'temperature': temperature, 'humidity': humidity}\n        }]\n        compressed_data = self.compress_data(data)\n        # Decompress the data before writing to the database\n        self.client.write_points(json.loads(zlib.decompress(compressed_data).decode('utf-8')))\n\n    def run(self) -> None:\n        \"\"\"\n        Continuously collect and store weather data every minute.\n        \"\"\"  \n        while True:\n            timestamp = int(time.time() * 1000)\n            temperature = 22.5  # Example temperature\n            humidity = 60       # Example humidity\n            self.store_data(timestamp, temperature, humidity)\n            time.sleep(60)\n\nif __name__ == '__main__':\n    weather_station = WeatherStation('localhost', 8086, 'user', 'password', 'weather_db')\n    weather_station.run()",
    "rejected_code": "import json\nimport zlib\nfrom influxdb import InfluxDBClient\n\nclient = InfluxDBClient('localhost', 8086, 'user', 'password', 'weather_db')\n\ndef compress_data(data):\n    return zlib.compress(json.dumps(data).encode('utf-8'))\n\ndef store_data(timestamp, temperature, humidity):\n    data = [{\n        'measurement': 'weather',\n        'tags': {'sensor': 'sensor1'},\n        'time': timestamp,\n        'fields': {'temperature': temperature, 'humidity': humidity}\n    }]\n    compressed_data = compress_data(data)\n    client.write_points(json.loads(zlib.decompress(compressed_data).decode('utf-8')))  \n\nimport time\nwhile True:\n    timestamp = int(time.time() * 1000)\n    temperature = 22.5  # Example temperature\n    humidity = 60       # Example humidity\n    store_data(timestamp, temperature, humidity)\n    time.sleep(60)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.016666666666666666,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'influxdb'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'influxdb'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Develop a time series data storage function with efficient compression",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a Python class that implements a time series data storage function with efficient compression for a smart weather station?",
      "role": "user"
    },
    "chosen_code": "import json\nimport zlib\nfrom influxdb import InfluxDBClient\nimport time\nfrom typing import Dict, Any\n\nclass WeatherStation:\n    def __init__(self, host: str, port: int, user: str, password: str, dbname: str) -> None:\n        \"\"\"\n        Initialize the InfluxDB client for storing weather data.\n        \n        :param host: The hostname of the InfluxDB server.\n        :param port: The port number of the InfluxDB server.\n        :param user: The username for authentication.\n        :param password: The password for authentication.\n        :param dbname: The name of the database to use.\n        \"\"\"  \n        self.client = InfluxDBClient(host, port, user, password, dbname)\n\n    def compress_data(self, data: Dict[str, Any]) -> bytes:\n        \"\"\"\n        Compress the provided data using zlib.\n        \n        :param data: The data to compress, in dictionary format.\n        :return: Compressed data as bytes.\n        \"\"\"  \n        return zlib.compress(json.dumps(data).encode('utf-8'))\n\n    def store_data(self, timestamp: int, temperature: float, humidity: float) -> None:\n        \"\"\"\n        Store the weather data in the InfluxDB database after compressing it.\n        \n        :param timestamp: The timestamp of the data point (in milliseconds).\n        :param temperature: The temperature value to store.\n        :param humidity: The humidity value to store.\n        \"\"\"  \n        data = [{\n            'measurement': 'weather',\n            'tags': {'sensor': 'sensor1'},\n            'time': timestamp,\n            'fields': {'temperature': temperature, 'humidity': humidity}\n        }]\n        compressed_data = self.compress_data(data)\n        # Decompress the data before writing to the database\n        self.client.write_points(json.loads(zlib.decompress(compressed_data).decode('utf-8')))\n\n    def run(self) -> None:\n        \"\"\"\n        Continuously collect and store weather data every minute.\n        \"\"\"  \n        while True:\n            timestamp = int(time.time() * 1000)\n            temperature = 22.5  # Example temperature\n            humidity = 60       # Example humidity\n            self.store_data(timestamp, temperature, humidity)\n            time.sleep(60)\n\nif __name__ == '__main__':\n    weather_station = WeatherStation('localhost', 8086, 'user', 'password', 'weather_db')\n    weather_station.run()",
    "rejected_code": "import json\nimport zlib\nfrom influxdb import InfluxDBClient\n\nclient = InfluxDBClient('localhost', 8086, 'user', 'password', 'weather_db')\n\ndef compress_data(data):\n    return zlib.compress(json.dumps(data).encode('utf-8'))\n\ndef store_data(timestamp, temperature, humidity):\n    data = [{\n        'measurement': 'weather',\n        'tags': {'sensor': 'sensor1'},\n        'time': timestamp,\n        'fields': {'temperature': temperature, 'humidity': humidity}\n    }]\n    compressed_data = compress_data(data)\n    client.write_points(json.loads(zlib.decompress(compressed_data).decode('utf-8')))  \n\nimport time\nwhile True:\n    timestamp = int(time.time() * 1000)\n    temperature = 22.5  # Example temperature\n    humidity = 60       # Example humidity\n    store_data(timestamp, temperature, humidity)\n    time.sleep(60)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.016666666666666666,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'influxdb'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'influxdb'"
      }
    }
  },
  {
    "domain": "iot and embedded systems",
    "task": "Develop a time series data storage function with efficient compression",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "I need a Python class that includes a method for storing time series data with efficient compression. Please specify the input and output types.",
      "role": "user"
    },
    "chosen_code": "import json\nimport zlib\nfrom influxdb import InfluxDBClient\nimport time\nfrom typing import Dict, Any\n\nclass WeatherStation:\n    def __init__(self, host: str, port: int, user: str, password: str, dbname: str) -> None:\n        \"\"\"\n        Initialize the InfluxDB client for storing weather data.\n        \n        :param host: The hostname of the InfluxDB server.\n        :param port: The port number of the InfluxDB server.\n        :param user: The username for authentication.\n        :param password: The password for authentication.\n        :param dbname: The name of the database to use.\n        \"\"\"  \n        self.client = InfluxDBClient(host, port, user, password, dbname)\n\n    def compress_data(self, data: Dict[str, Any]) -> bytes:\n        \"\"\"\n        Compress the provided data using zlib.\n        \n        :param data: The data to compress, in dictionary format.\n        :return: Compressed data as bytes.\n        \"\"\"  \n        return zlib.compress(json.dumps(data).encode('utf-8'))\n\n    def store_data(self, timestamp: int, temperature: float, humidity: float) -> None:\n        \"\"\"\n        Store the weather data in the InfluxDB database after compressing it.\n        \n        :param timestamp: The timestamp of the data point (in milliseconds).\n        :param temperature: The temperature value to store.\n        :param humidity: The humidity value to store.\n        \"\"\"  \n        data = [{\n            'measurement': 'weather',\n            'tags': {'sensor': 'sensor1'},\n            'time': timestamp,\n            'fields': {'temperature': temperature, 'humidity': humidity}\n        }]\n        compressed_data = self.compress_data(data)\n        # Decompress the data before writing to the database\n        self.client.write_points(json.loads(zlib.decompress(compressed_data).decode('utf-8')))\n\n    def run(self) -> None:\n        \"\"\"\n        Continuously collect and store weather data every minute.\n        \"\"\"  \n        while True:\n            timestamp = int(time.time() * 1000)\n            temperature = 22.5  # Example temperature\n            humidity = 60       # Example humidity\n            self.store_data(timestamp, temperature, humidity)\n            time.sleep(60)\n\nif __name__ == '__main__':\n    weather_station = WeatherStation('localhost', 8086, 'user', 'password', 'weather_db')\n    weather_station.run()",
    "rejected_code": "import json\nimport zlib\nfrom influxdb import InfluxDBClient\n\nclient = InfluxDBClient('localhost', 8086, 'user', 'password', 'weather_db')\n\ndef compress_data(data):\n    return zlib.compress(json.dumps(data).encode('utf-8'))\n\ndef store_data(timestamp, temperature, humidity):\n    data = [{\n        'measurement': 'weather',\n        'tags': {'sensor': 'sensor1'},\n        'time': timestamp,\n        'fields': {'temperature': temperature, 'humidity': humidity}\n    }]\n    compressed_data = compress_data(data)\n    client.write_points(json.loads(zlib.decompress(compressed_data).decode('utf-8')))  \n\nimport time\nwhile True:\n    timestamp = int(time.time() * 1000)\n    temperature = 22.5  # Example temperature\n    humidity = 60       # Example humidity\n    store_data(timestamp, temperature, humidity)\n    time.sleep(60)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.4,
      "pep8_compliance": null,
      "comment_density": 0.016666666666666666,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'influxdb'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 3, in <module>\nModuleNotFoundError: No module named 'influxdb'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Create a phylogenetic tree construction class with multiple methods",
    "code_form": "tree builder class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code to create a phylogenetic tree construction class with multiple methods for analyzing genetic sequences.",
      "role": "user"
    },
    "chosen_code": "from Bio import AlignIO\nfrom Bio.Phylo import draw\nfrom Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio.Phylo.BaseTree import TreeNode\nfrom typing import Optional\n\nclass PhyloTreeBuilder:\n    \"\"\"\n    A class to construct phylogenetic trees from multiple sequence alignments.\n\n    This class allows the user to load sequence data from FASTA files,\n    calculate distance matrices, and construct phylogenetic trees using\n    different methods such as Neighbor-Joining and UPGMA.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the PhyloTreeBuilder with no alignments.\n        \"\"\"\n        self.alignments: Optional[MultipleSeqAlignment] = None\n\n    def load_sequences(self, file_path: str) -> None:\n        \"\"\"\n        Load sequences from a FASTA file into the alignments attribute.\n\n        Args:\n            file_path (str): The path to the FASTA file containing sequences.\n        \"\"\"\n        self.alignments = AlignIO.read(file_path, 'fasta')\n\n    def calculate_distance_matrix(self) -> DistanceCalculator:\n        \"\"\"\n        Calculate the distance matrix from the loaded alignments.\n\n        Returns:\n            DistanceCalculator: The distance matrix calculated using the identity method.\n        \"\"\"\n        calculator = DistanceCalculator('identity')\n        return calculator.get_distance(self.alignments)\n\n    def construct_nj_tree(self) -> TreeNode:\n        \"\"\"\n        Construct a phylogenetic tree using the Neighbor-Joining method.\n\n        Returns:\n            TreeNode: The constructed Neighbor-Joining tree.\n        \"\"\"\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.nj(dm)\n\n    def construct_upgma_tree(self) -> TreeNode:\n        \"\"\"\n        Construct a phylogenetic tree using the UPGMA method.\n\n        Returns:\n            TreeNode: The constructed UPGMA tree.\n        \"\"\"\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.upgma(dm)\n\n    def visualize_tree(self, tree: TreeNode) -> None:\n        \"\"\"\n        Visualize the given phylogenetic tree.\n\n        Args:\n            tree (TreeNode): The phylogenetic tree to visualize.\n        \"\"\"\n        draw(tree)\n\n# Example usage:\n# builder = PhyloTreeBuilder()\n# builder.load_sequences('sequences.fasta')\n# nj_tree = builder.construct_nj_tree()\n# builder.visualize_tree(nj_tree)",
    "rejected_code": "from Bio import AlignIO\nfrom Bio.Phylo import Tree\nfrom Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n\nclass PhyloTreeBuilder:\n    def __init__(self):\n        self.alignments = None\n    \n    def load_sequences(self, file_path):\n        self.alignments = AlignIO.read(file_path, 'fasta')\n    \n    def calculate_distance_matrix(self):\n        calculator = DistanceCalculator('identity')\n        return calculator.get_distance(self.alignments)\n    \n    def construct_nj_tree(self):\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.nj(dm)\n    \n    def construct_upgma_tree(self):\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.upgma(dm)\n    \n    def visualize_tree(self, tree):\n        Tree.plot(tree)\n\n# Example usage:\n# builder = PhyloTreeBuilder()\n# builder.load_sequences('sequences.fasta')\n# nj_tree = builder.construct_nj_tree()\n# builder.visualize_tree(nj_tree)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1428571428571428,
      "pep8_compliance": null,
      "comment_density": 0.06493506493506493,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1428571428571428,
      "pep8_compliance": null,
      "comment_density": 0.15151515151515152,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Create a phylogenetic tree construction class with multiple methods",
    "code_form": "tree builder class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a Python class that constructs a phylogenetic tree from genetic sequences using different methods.",
      "role": "user"
    },
    "chosen_code": "from Bio import AlignIO\nfrom Bio.Phylo import draw\nfrom Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio.Phylo.BaseTree import TreeNode\nfrom typing import Optional\n\nclass PhyloTreeBuilder:\n    \"\"\"\n    A class to construct phylogenetic trees from multiple sequence alignments.\n\n    This class allows the user to load sequence data from FASTA files,\n    calculate distance matrices, and construct phylogenetic trees using\n    different methods such as Neighbor-Joining and UPGMA.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the PhyloTreeBuilder with no alignments.\n        \"\"\"\n        self.alignments: Optional[MultipleSeqAlignment] = None\n\n    def load_sequences(self, file_path: str) -> None:\n        \"\"\"\n        Load sequences from a FASTA file into the alignments attribute.\n\n        Args:\n            file_path (str): The path to the FASTA file containing sequences.\n        \"\"\"\n        self.alignments = AlignIO.read(file_path, 'fasta')\n\n    def calculate_distance_matrix(self) -> DistanceCalculator:\n        \"\"\"\n        Calculate the distance matrix from the loaded alignments.\n\n        Returns:\n            DistanceCalculator: The distance matrix calculated using the identity method.\n        \"\"\"\n        calculator = DistanceCalculator('identity')\n        return calculator.get_distance(self.alignments)\n\n    def construct_nj_tree(self) -> TreeNode:\n        \"\"\"\n        Construct a phylogenetic tree using the Neighbor-Joining method.\n\n        Returns:\n            TreeNode: The constructed Neighbor-Joining tree.\n        \"\"\"\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.nj(dm)\n\n    def construct_upgma_tree(self) -> TreeNode:\n        \"\"\"\n        Construct a phylogenetic tree using the UPGMA method.\n\n        Returns:\n            TreeNode: The constructed UPGMA tree.\n        \"\"\"\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.upgma(dm)\n\n    def visualize_tree(self, tree: TreeNode) -> None:\n        \"\"\"\n        Visualize the given phylogenetic tree.\n\n        Args:\n            tree (TreeNode): The phylogenetic tree to visualize.\n        \"\"\"\n        draw(tree)\n\n# Example usage:\n# builder = PhyloTreeBuilder()\n# builder.load_sequences('sequences.fasta')\n# nj_tree = builder.construct_nj_tree()\n# builder.visualize_tree(nj_tree)",
    "rejected_code": "from Bio import AlignIO\nfrom Bio.Phylo import Tree\nfrom Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n\nclass PhyloTreeBuilder:\n    def __init__(self):\n        self.alignments = None\n    \n    def load_sequences(self, file_path):\n        self.alignments = AlignIO.read(file_path, 'fasta')\n    \n    def calculate_distance_matrix(self):\n        calculator = DistanceCalculator('identity')\n        return calculator.get_distance(self.alignments)\n    \n    def construct_nj_tree(self):\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.nj(dm)\n    \n    def construct_upgma_tree(self):\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.upgma(dm)\n    \n    def visualize_tree(self, tree):\n        Tree.plot(tree)\n\n# Example usage:\n# builder = PhyloTreeBuilder()\n# builder.load_sequences('sequences.fasta')\n# nj_tree = builder.construct_nj_tree()\n# builder.visualize_tree(nj_tree)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1428571428571428,
      "pep8_compliance": null,
      "comment_density": 0.06493506493506493,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1428571428571428,
      "pep8_compliance": null,
      "comment_density": 0.15151515151515152,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Create a phylogenetic tree construction class with multiple methods",
    "code_form": "tree builder class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python class that takes input as sequence files in FASTA format and outputs a phylogenetic tree, with clear input and output types.",
      "role": "user"
    },
    "chosen_code": "from Bio import AlignIO\nfrom Bio.Phylo import draw\nfrom Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\nfrom Bio.Align import MultipleSeqAlignment\nfrom Bio.Phylo.BaseTree import TreeNode\nfrom typing import Optional\n\nclass PhyloTreeBuilder:\n    \"\"\"\n    A class to construct phylogenetic trees from multiple sequence alignments.\n\n    This class allows the user to load sequence data from FASTA files,\n    calculate distance matrices, and construct phylogenetic trees using\n    different methods such as Neighbor-Joining and UPGMA.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initialize the PhyloTreeBuilder with no alignments.\n        \"\"\"\n        self.alignments: Optional[MultipleSeqAlignment] = None\n\n    def load_sequences(self, file_path: str) -> None:\n        \"\"\"\n        Load sequences from a FASTA file into the alignments attribute.\n\n        Args:\n            file_path (str): The path to the FASTA file containing sequences.\n        \"\"\"\n        self.alignments = AlignIO.read(file_path, 'fasta')\n\n    def calculate_distance_matrix(self) -> DistanceCalculator:\n        \"\"\"\n        Calculate the distance matrix from the loaded alignments.\n\n        Returns:\n            DistanceCalculator: The distance matrix calculated using the identity method.\n        \"\"\"\n        calculator = DistanceCalculator('identity')\n        return calculator.get_distance(self.alignments)\n\n    def construct_nj_tree(self) -> TreeNode:\n        \"\"\"\n        Construct a phylogenetic tree using the Neighbor-Joining method.\n\n        Returns:\n            TreeNode: The constructed Neighbor-Joining tree.\n        \"\"\"\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.nj(dm)\n\n    def construct_upgma_tree(self) -> TreeNode:\n        \"\"\"\n        Construct a phylogenetic tree using the UPGMA method.\n\n        Returns:\n            TreeNode: The constructed UPGMA tree.\n        \"\"\"\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.upgma(dm)\n\n    def visualize_tree(self, tree: TreeNode) -> None:\n        \"\"\"\n        Visualize the given phylogenetic tree.\n\n        Args:\n            tree (TreeNode): The phylogenetic tree to visualize.\n        \"\"\"\n        draw(tree)\n\n# Example usage:\n# builder = PhyloTreeBuilder()\n# builder.load_sequences('sequences.fasta')\n# nj_tree = builder.construct_nj_tree()\n# builder.visualize_tree(nj_tree)",
    "rejected_code": "from Bio import AlignIO\nfrom Bio.Phylo import Tree\nfrom Bio.Phylo.TreeConstruction import DistanceCalculator, DistanceTreeConstructor\n\nclass PhyloTreeBuilder:\n    def __init__(self):\n        self.alignments = None\n    \n    def load_sequences(self, file_path):\n        self.alignments = AlignIO.read(file_path, 'fasta')\n    \n    def calculate_distance_matrix(self):\n        calculator = DistanceCalculator('identity')\n        return calculator.get_distance(self.alignments)\n    \n    def construct_nj_tree(self):\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.nj(dm)\n    \n    def construct_upgma_tree(self):\n        dm = self.calculate_distance_matrix()\n        constructor = DistanceTreeConstructor()\n        return constructor.upgma(dm)\n    \n    def visualize_tree(self, tree):\n        Tree.plot(tree)\n\n# Example usage:\n# builder = PhyloTreeBuilder()\n# builder.load_sequences('sequences.fasta')\n# nj_tree = builder.construct_nj_tree()\n# builder.visualize_tree(nj_tree)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.1428571428571428,
      "pep8_compliance": null,
      "comment_density": 0.06493506493506493,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.1428571428571428,
      "pep8_compliance": null,
      "comment_density": 0.15151515151515152,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Develop a protein structure prediction function",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Write a Python function to predict the 3D structure of a protein from its amino acid sequence.",
      "role": "user"
    },
    "chosen_code": "from Bio.PDB import PDBIO, StructureBuilder\nfrom typing import Union\n\n\ndef predict_protein_structure(sequence: str) -> None:\n    \"\"\"\n    Predicts the 3D structure of a protein from its amino acid sequence and saves it as a PDB file.\n\n    Args:\n        sequence (str): A string representing the amino acid sequence of the protein.\n\n    Returns:\n        None: The function saves the predicted structure to a file named 'predicted_structure.pdb'.\n    \"\"\"\n    # Initialize the structure builder to create a new protein structure\n    builder = StructureBuilder.StructureBuilder()\n    # Create a new model for the protein\n    model = builder.get_structure('Protein', 'temp.pdb')\n\n    # Iterate over each amino acid in the sequence\n    for aa in sequence:\n        # Initialize a new residue for the current amino acid\n        builder.init_residue(aa, ' ', 1, ' ')\n        # Add the residue to the structure\n        builder.add_residue()\n\n    # Prepare to save the structure to a PDB file\n    io = PDBIO()\n    io.set_structure(model)\n    io.save('predicted_structure.pdb')\n\n# Example usage\nif __name__ == '__main__':\n    protein_sequence: str = 'ACDEFGHIKLMNPQRSTVWY'\n    predict_protein_structure(protein_sequence)",
    "rejected_code": "from Bio.PDB import PDBParser, PDBIO, StructureBuilder\nfrom Bio.Seq import Seq\nfrom Bio.SeqUtils import seq3\nfrom Bio.PDB import build_model\n\ndef predict_protein_structure(sequence):\n    builder = StructureBuilder.StructureBuilder()\n    model = builder.get_structure('Protein', 'temp.pdb')\n    for aa in sequence:\n        builder.init_residue(aa, ' ', 1, ' ')  \n        builder.add_residue()\n    io = PDBIO()\n    io.set_structure(model)\n    io.save('predicted_structure.pdb')\n\nprotein_sequence = 'ACDEFGHIKLMNPQRSTVWY'\npredict_protein_structure(protein_sequence)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.2,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Develop a protein structure prediction function",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Create a Python class that predicts the 3D structure of a protein from its amino acid sequence.",
      "role": "user"
    },
    "chosen_code": "from Bio.PDB import PDBIO, StructureBuilder\nfrom typing import Union\n\n\ndef predict_protein_structure(sequence: str) -> None:\n    \"\"\"\n    Predicts the 3D structure of a protein from its amino acid sequence and saves it as a PDB file.\n\n    Args:\n        sequence (str): A string representing the amino acid sequence of the protein.\n\n    Returns:\n        None: The function saves the predicted structure to a file named 'predicted_structure.pdb'.\n    \"\"\"\n    # Initialize the structure builder to create a new protein structure\n    builder = StructureBuilder.StructureBuilder()\n    # Create a new model for the protein\n    model = builder.get_structure('Protein', 'temp.pdb')\n\n    # Iterate over each amino acid in the sequence\n    for aa in sequence:\n        # Initialize a new residue for the current amino acid\n        builder.init_residue(aa, ' ', 1, ' ')\n        # Add the residue to the structure\n        builder.add_residue()\n\n    # Prepare to save the structure to a PDB file\n    io = PDBIO()\n    io.set_structure(model)\n    io.save('predicted_structure.pdb')\n\n# Example usage\nif __name__ == '__main__':\n    protein_sequence: str = 'ACDEFGHIKLMNPQRSTVWY'\n    predict_protein_structure(protein_sequence)",
    "rejected_code": "from Bio.PDB import PDBParser, PDBIO, StructureBuilder\nfrom Bio.Seq import Seq\nfrom Bio.SeqUtils import seq3\nfrom Bio.PDB import build_model\n\ndef predict_protein_structure(sequence):\n    builder = StructureBuilder.StructureBuilder()\n    model = builder.get_structure('Protein', 'temp.pdb')\n    for aa in sequence:\n        builder.init_residue(aa, ' ', 1, ' ')  \n        builder.add_residue()\n    io = PDBIO()\n    io.set_structure(model)\n    io.save('predicted_structure.pdb')\n\nprotein_sequence = 'ACDEFGHIKLMNPQRSTVWY'\npredict_protein_structure(protein_sequence)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.2,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "bioinformatics",
    "task": "Develop a protein structure prediction function",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Develop a Python function that takes a string input of an amino acid sequence and outputs a PDB file representing the 3D structure of the protein.",
      "role": "user"
    },
    "chosen_code": "from Bio.PDB import PDBIO, StructureBuilder\nfrom typing import Union\n\n\ndef predict_protein_structure(sequence: str) -> None:\n    \"\"\"\n    Predicts the 3D structure of a protein from its amino acid sequence and saves it as a PDB file.\n\n    Args:\n        sequence (str): A string representing the amino acid sequence of the protein.\n\n    Returns:\n        None: The function saves the predicted structure to a file named 'predicted_structure.pdb'.\n    \"\"\"\n    # Initialize the structure builder to create a new protein structure\n    builder = StructureBuilder.StructureBuilder()\n    # Create a new model for the protein\n    model = builder.get_structure('Protein', 'temp.pdb')\n\n    # Iterate over each amino acid in the sequence\n    for aa in sequence:\n        # Initialize a new residue for the current amino acid\n        builder.init_residue(aa, ' ', 1, ' ')\n        # Add the residue to the structure\n        builder.add_residue()\n\n    # Prepare to save the structure to a PDB file\n    io = PDBIO()\n    io.set_structure(model)\n    io.save('predicted_structure.pdb')\n\n# Example usage\nif __name__ == '__main__':\n    protein_sequence: str = 'ACDEFGHIKLMNPQRSTVWY'\n    predict_protein_structure(protein_sequence)",
    "rejected_code": "from Bio.PDB import PDBParser, PDBIO, StructureBuilder\nfrom Bio.Seq import Seq\nfrom Bio.SeqUtils import seq3\nfrom Bio.PDB import build_model\n\ndef predict_protein_structure(sequence):\n    builder = StructureBuilder.StructureBuilder()\n    model = builder.get_structure('Protein', 'temp.pdb')\n    for aa in sequence:\n        builder.init_residue(aa, ' ', 1, ' ')  \n        builder.add_residue()\n    io = PDBIO()\n    io.set_structure(model)\n    io.save('predicted_structure.pdb')\n\nprotein_sequence = 'ACDEFGHIKLMNPQRSTVWY'\npredict_protein_structure(protein_sequence)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.2,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'Bio'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Implement a network traffic analysis function for detecting anomalies",
    "code_form": "analyzer function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to implement a network traffic analysis function for detecting anomalies?",
      "role": "user"
    },
    "chosen_code": "from scapy.all import IP, sniff\nfrom typing import Dict\n\n# Define a threshold for data transfer in bytes\nTHRESHOLD: int = 1000000  # 1 MB\n\n# A dictionary to hold the flow of data for each source IP\nflow: Dict[str, int] = {}\n\ndef analyze_network_traffic(packet) -> None:\n    \"\"\"\n    Analyze the incoming network traffic packet to detect anomalies.\n\n    Args:\n        packet: The network packet being analyzed. It must contain an IP layer.\n    \"\"\"\n    # Check if the packet contains an IP layer\n    if IP in packet:\n        src: str = packet[IP].src  # Source IP address\n        dst: str = packet[IP].dst  # Destination IP address (not used in analysis)\n        data_size: int = len(packet)  # Size of the packet in bytes\n\n        # Update the flow for the source IP\n        flow[src] = flow.get(src, 0) + data_size\n\n        # Check if the flow exceeds the predefined threshold\n        if flow[src] > THRESHOLD:\n            print(f'Anomaly detected from {src}: {flow[src]} bytes')\n\n# Start sniffing the network traffic, calling analyze_network_traffic for each packet\nsniff(prn=analyze_network_traffic, filter='ip', store=0)",
    "rejected_code": "from scapy.all import *\n\nthreshold = 1000000  # bytes\n\ndef analyze_network_traffic(p):\n    if IP in p:\n        src = p[IP].src\n        dst = p[IP].dst\n        data_size = len(p)\n        flow[src] = flow.get(src, 0) + data_size\n        if flow[src] > threshold:\n            print(f'Anomaly detected from {src}: {flow[src]} bytes')\n\nflow = {}\n\nsniff(prn=analyze_network_traffic, filter='ip', store=0)",
    "chosen_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.1935483870967742,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'scapy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'scapy'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Implement a network traffic analysis function for detecting anomalies",
    "code_form": "analyzer function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you provide a function in Python that implements network traffic analysis for detecting anomalies?",
      "role": "user"
    },
    "chosen_code": "from scapy.all import IP, sniff\nfrom typing import Dict\n\n# Define a threshold for data transfer in bytes\nTHRESHOLD: int = 1000000  # 1 MB\n\n# A dictionary to hold the flow of data for each source IP\nflow: Dict[str, int] = {}\n\ndef analyze_network_traffic(packet) -> None:\n    \"\"\"\n    Analyze the incoming network traffic packet to detect anomalies.\n\n    Args:\n        packet: The network packet being analyzed. It must contain an IP layer.\n    \"\"\"\n    # Check if the packet contains an IP layer\n    if IP in packet:\n        src: str = packet[IP].src  # Source IP address\n        dst: str = packet[IP].dst  # Destination IP address (not used in analysis)\n        data_size: int = len(packet)  # Size of the packet in bytes\n\n        # Update the flow for the source IP\n        flow[src] = flow.get(src, 0) + data_size\n\n        # Check if the flow exceeds the predefined threshold\n        if flow[src] > THRESHOLD:\n            print(f'Anomaly detected from {src}: {flow[src]} bytes')\n\n# Start sniffing the network traffic, calling analyze_network_traffic for each packet\nsniff(prn=analyze_network_traffic, filter='ip', store=0)",
    "rejected_code": "from scapy.all import *\n\nthreshold = 1000000  # bytes\n\ndef analyze_network_traffic(p):\n    if IP in p:\n        src = p[IP].src\n        dst = p[IP].dst\n        data_size = len(p)\n        flow[src] = flow.get(src, 0) + data_size\n        if flow[src] > threshold:\n            print(f'Anomaly detected from {src}: {flow[src]} bytes')\n\nflow = {}\n\nsniff(prn=analyze_network_traffic, filter='ip', store=0)",
    "chosen_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.1935483870967742,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'scapy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'scapy'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Implement a network traffic analysis function for detecting anomalies",
    "code_form": "analyzer function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you provide a function in Python that implements network traffic analysis for detecting anomalies, specifying the input as a packet and no return value?",
      "role": "user"
    },
    "chosen_code": "from scapy.all import IP, sniff\nfrom typing import Dict\n\n# Define a threshold for data transfer in bytes\nTHRESHOLD: int = 1000000  # 1 MB\n\n# A dictionary to hold the flow of data for each source IP\nflow: Dict[str, int] = {}\n\ndef analyze_network_traffic(packet) -> None:\n    \"\"\"\n    Analyze the incoming network traffic packet to detect anomalies.\n\n    Args:\n        packet: The network packet being analyzed. It must contain an IP layer.\n    \"\"\"\n    # Check if the packet contains an IP layer\n    if IP in packet:\n        src: str = packet[IP].src  # Source IP address\n        dst: str = packet[IP].dst  # Destination IP address (not used in analysis)\n        data_size: int = len(packet)  # Size of the packet in bytes\n\n        # Update the flow for the source IP\n        flow[src] = flow.get(src, 0) + data_size\n\n        # Check if the flow exceeds the predefined threshold\n        if flow[src] > THRESHOLD:\n            print(f'Anomaly detected from {src}: {flow[src]} bytes')\n\n# Start sniffing the network traffic, calling analyze_network_traffic for each packet\nsniff(prn=analyze_network_traffic, filter='ip', store=0)",
    "rejected_code": "from scapy.all import *\n\nthreshold = 1000000  # bytes\n\ndef analyze_network_traffic(p):\n    if IP in p:\n        src = p[IP].src\n        dst = p[IP].dst\n        data_size = len(p)\n        flow[src] = flow.get(src, 0) + data_size\n        if flow[src] > threshold:\n            print(f'Anomaly detected from {src}: {flow[src]} bytes')\n\nflow = {}\n\nsniff(prn=analyze_network_traffic, filter='ip', store=0)",
    "chosen_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.1935483870967742,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'scapy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'scapy'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Create a secure password management system with encryption",
    "code_form": "manager class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide Python code for a secure password management system that encrypts passwords before storing them and allows secure retrieval.",
      "role": "user"
    },
    "chosen_code": "from cryptography.fernet import Fernet\nimport json\nfrom typing import Optional, Dict\n\nclass PasswordManager:\n    \"\"\"\n    A class to manage passwords securely, allowing for encryption and decryption.\n    This class provides methods to add, retrieve, save, and load passwords.\n    \"\"\"\n\n    def __init__(self, key: Optional[bytes] = None) -> None:\n        \"\"\"\n        Initializes the PasswordManager with a given encryption key or generates a new one.\n\n        :param key: Optional; a bytes object representing the encryption key. If None, a new key is generated.\n        \"\"\"\n        self.key: bytes = key if key else Fernet.generate_key()\n        self.cipher: Fernet = Fernet(self.key)\n        self.passwords: Dict[str, str] = {}  # Store service-password pairs\n\n    def add_password(self, service: str, password: str) -> None:\n        \"\"\"\n        Encrypts the given password and associates it with the specified service.\n\n        :param service: The name of the service for which the password is being stored.\n        :param password: The plaintext password to be encrypted and stored.\n        \"\"\"\n        encrypted_password: str = self.cipher.encrypt(password.encode()).decode()\n        self.passwords[service] = encrypted_password\n\n    def get_password(self, service: str) -> Optional[str]:\n        \"\"\"\n        Retrieves the decrypted password associated with the specified service.\n\n        :param service: The name of the service for which the password is being retrieved.\n        :return: The decrypted password if it exists, otherwise None.\n        \"\"\"\n        encrypted_password: Optional[str] = self.passwords.get(service)\n        if encrypted_password:\n            return self.cipher.decrypt(encrypted_password.encode()).decode()\n        return None\n\n    def save_to_file(self, filename: str) -> None:\n        \"\"\"\n        Saves the encrypted passwords to a file in JSON format.\n\n        :param filename: The name of the file to which the passwords will be saved.\n        \"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.passwords, f)\n\n    def load_from_file(self, filename: str) -> None:\n        \"\"\"\n        Loads encrypted passwords from a file in JSON format.\n\n        :param filename: The name of the file from which the passwords will be loaded.\n        \"\"\"\n        with open(filename, 'r') as f:\n            self.passwords = json.load(f)\n\n# Example usage\nif __name__ == '__main__':\n    manager = PasswordManager()\n    manager.add_password('email', 'secure_password123')\n    manager.save_to_file('passwords.json')\n    manager.load_from_file('passwords.json')\n    print(manager.get_password('email'))",
    "rejected_code": "from cryptography.fernet import Fernet\nimport json\n\nclass PasswordManager:\n    def __init__(self, key=None):\n        if key is None:\n            self.key = Fernet.generate_key()\n        else:\n            self.key = key\n        self.cipher = Fernet(self.key)\n        self.passwords = {}\n\n    def add_password(self, service, password):\n        encrypted_password = self.cipher.encrypt(password.encode()).decode()\n        self.passwords[service] = encrypted_password\n\n    def get_password(self, service):\n        encrypted_password = self.passwords.get(service)\n        if encrypted_password:\n            return self.cipher.decrypt(encrypted_password.encode()).decode()\n        return None\n\n    def save_to_file(self, filename):\n        with open(filename, 'w') as f:\n            json.dump(self.passwords, f)\n\n    def load_from_file(self, filename):\n        with open(filename, 'r') as f:\n            self.passwords = json.load(f)\n\nmanager = PasswordManager()\nmanager.add_password('email', 'secure_password123')\nmanager.save_to_file('passwords.json')\nmanager.load_from_file('passwords.json')\nprint(manager.get_password('email'))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.014925373134328358,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Create a secure password management system with encryption",
    "code_form": "manager class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a Python class that implements a secure password management system with encryption for storing and retrieving passwords.",
      "role": "user"
    },
    "chosen_code": "from cryptography.fernet import Fernet\nimport json\nfrom typing import Optional, Dict\n\nclass PasswordManager:\n    \"\"\"\n    A class to manage passwords securely, allowing for encryption and decryption.\n    This class provides methods to add, retrieve, save, and load passwords.\n    \"\"\"\n\n    def __init__(self, key: Optional[bytes] = None) -> None:\n        \"\"\"\n        Initializes the PasswordManager with a given encryption key or generates a new one.\n\n        :param key: Optional; a bytes object representing the encryption key. If None, a new key is generated.\n        \"\"\"\n        self.key: bytes = key if key else Fernet.generate_key()\n        self.cipher: Fernet = Fernet(self.key)\n        self.passwords: Dict[str, str] = {}  # Store service-password pairs\n\n    def add_password(self, service: str, password: str) -> None:\n        \"\"\"\n        Encrypts the given password and associates it with the specified service.\n\n        :param service: The name of the service for which the password is being stored.\n        :param password: The plaintext password to be encrypted and stored.\n        \"\"\"\n        encrypted_password: str = self.cipher.encrypt(password.encode()).decode()\n        self.passwords[service] = encrypted_password\n\n    def get_password(self, service: str) -> Optional[str]:\n        \"\"\"\n        Retrieves the decrypted password associated with the specified service.\n\n        :param service: The name of the service for which the password is being retrieved.\n        :return: The decrypted password if it exists, otherwise None.\n        \"\"\"\n        encrypted_password: Optional[str] = self.passwords.get(service)\n        if encrypted_password:\n            return self.cipher.decrypt(encrypted_password.encode()).decode()\n        return None\n\n    def save_to_file(self, filename: str) -> None:\n        \"\"\"\n        Saves the encrypted passwords to a file in JSON format.\n\n        :param filename: The name of the file to which the passwords will be saved.\n        \"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.passwords, f)\n\n    def load_from_file(self, filename: str) -> None:\n        \"\"\"\n        Loads encrypted passwords from a file in JSON format.\n\n        :param filename: The name of the file from which the passwords will be loaded.\n        \"\"\"\n        with open(filename, 'r') as f:\n            self.passwords = json.load(f)\n\n# Example usage\nif __name__ == '__main__':\n    manager = PasswordManager()\n    manager.add_password('email', 'secure_password123')\n    manager.save_to_file('passwords.json')\n    manager.load_from_file('passwords.json')\n    print(manager.get_password('email'))",
    "rejected_code": "from cryptography.fernet import Fernet\nimport json\n\nclass PasswordManager:\n    def __init__(self, key=None):\n        if key is None:\n            self.key = Fernet.generate_key()\n        else:\n            self.key = key\n        self.cipher = Fernet(self.key)\n        self.passwords = {}\n\n    def add_password(self, service, password):\n        encrypted_password = self.cipher.encrypt(password.encode()).decode()\n        self.passwords[service] = encrypted_password\n\n    def get_password(self, service):\n        encrypted_password = self.passwords.get(service)\n        if encrypted_password:\n            return self.cipher.decrypt(encrypted_password.encode()).decode()\n        return None\n\n    def save_to_file(self, filename):\n        with open(filename, 'w') as f:\n            json.dump(self.passwords, f)\n\n    def load_from_file(self, filename):\n        with open(filename, 'r') as f:\n            self.passwords = json.load(f)\n\nmanager = PasswordManager()\nmanager.add_password('email', 'secure_password123')\nmanager.save_to_file('passwords.json')\nmanager.load_from_file('passwords.json')\nprint(manager.get_password('email'))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.014925373134328358,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Create a secure password management system with encryption",
    "code_form": "manager class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Create a Python class that manages passwords securely, specifying the input types for methods and the expected output types.",
      "role": "user"
    },
    "chosen_code": "from cryptography.fernet import Fernet\nimport json\nfrom typing import Optional, Dict\n\nclass PasswordManager:\n    \"\"\"\n    A class to manage passwords securely, allowing for encryption and decryption.\n    This class provides methods to add, retrieve, save, and load passwords.\n    \"\"\"\n\n    def __init__(self, key: Optional[bytes] = None) -> None:\n        \"\"\"\n        Initializes the PasswordManager with a given encryption key or generates a new one.\n\n        :param key: Optional; a bytes object representing the encryption key. If None, a new key is generated.\n        \"\"\"\n        self.key: bytes = key if key else Fernet.generate_key()\n        self.cipher: Fernet = Fernet(self.key)\n        self.passwords: Dict[str, str] = {}  # Store service-password pairs\n\n    def add_password(self, service: str, password: str) -> None:\n        \"\"\"\n        Encrypts the given password and associates it with the specified service.\n\n        :param service: The name of the service for which the password is being stored.\n        :param password: The plaintext password to be encrypted and stored.\n        \"\"\"\n        encrypted_password: str = self.cipher.encrypt(password.encode()).decode()\n        self.passwords[service] = encrypted_password\n\n    def get_password(self, service: str) -> Optional[str]:\n        \"\"\"\n        Retrieves the decrypted password associated with the specified service.\n\n        :param service: The name of the service for which the password is being retrieved.\n        :return: The decrypted password if it exists, otherwise None.\n        \"\"\"\n        encrypted_password: Optional[str] = self.passwords.get(service)\n        if encrypted_password:\n            return self.cipher.decrypt(encrypted_password.encode()).decode()\n        return None\n\n    def save_to_file(self, filename: str) -> None:\n        \"\"\"\n        Saves the encrypted passwords to a file in JSON format.\n\n        :param filename: The name of the file to which the passwords will be saved.\n        \"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.passwords, f)\n\n    def load_from_file(self, filename: str) -> None:\n        \"\"\"\n        Loads encrypted passwords from a file in JSON format.\n\n        :param filename: The name of the file from which the passwords will be loaded.\n        \"\"\"\n        with open(filename, 'r') as f:\n            self.passwords = json.load(f)\n\n# Example usage\nif __name__ == '__main__':\n    manager = PasswordManager()\n    manager.add_password('email', 'secure_password123')\n    manager.save_to_file('passwords.json')\n    manager.load_from_file('passwords.json')\n    print(manager.get_password('email'))",
    "rejected_code": "from cryptography.fernet import Fernet\nimport json\n\nclass PasswordManager:\n    def __init__(self, key=None):\n        if key is None:\n            self.key = Fernet.generate_key()\n        else:\n            self.key = key\n        self.cipher = Fernet(self.key)\n        self.passwords = {}\n\n    def add_password(self, service, password):\n        encrypted_password = self.cipher.encrypt(password.encode()).decode()\n        self.passwords[service] = encrypted_password\n\n    def get_password(self, service):\n        encrypted_password = self.passwords.get(service)\n        if encrypted_password:\n            return self.cipher.decrypt(encrypted_password.encode()).decode()\n        return None\n\n    def save_to_file(self, filename):\n        with open(filename, 'w') as f:\n            json.dump(self.passwords, f)\n\n    def load_from_file(self, filename):\n        with open(filename, 'r') as f:\n            self.passwords = json.load(f)\n\nmanager = PasswordManager()\nmanager.add_password('email', 'secure_password123')\nmanager.save_to_file('passwords.json')\nmanager.load_from_file('passwords.json')\nprint(manager.get_password('email'))",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.014925373134328358,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Build a security scanning class for vulnerability detection",
    "code_form": "scanner class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide a Python code example that builds a security scanning class for vulnerability detection in a web application.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom typing import List\n\nclass Scanner:\n    \"\"\"\n    A class to scan a web application for potential SQL injection vulnerabilities.\n    This class utilizes the requests library to simulate HTTP requests and checks\n    for common SQL injection patterns in the responses.\n    \"\"\"\n\n    def __init__(self, url: str) -> None:\n        \"\"\"\n        Initializes the Scanner with a target URL.\n\n        :param url: The base URL of the web application to scan.\n        \"\"\"\n        self.url = url\n\n    def scan_for_sql_injection(self) -> None:\n        \"\"\"\n        Scans the target URL for potential SQL injection vulnerabilities by sending\n        crafted payloads and analyzing the responses.\n        \"\"\"\n        payloads: List[str] = [\"' OR '1'='1\", \"' OR '1'='1' -- \", \"' OR '1'='1' /* \"]\n        for payload in payloads:\n            response = requests.get(self.url + payload)\n            if self.is_vulnerable(response.text):\n                print(f'Potential SQL injection vulnerability found with payload: {payload}')\n\n    def is_vulnerable(self, response: str) -> bool:\n        \"\"\"\n        Checks if the response indicates a potential SQL injection vulnerability.\n\n        :param response: The response text from the HTTP request.\n        :return: True if a vulnerability is detected, otherwise False.\n        \"\"\"\n        return \"error\" in response.lower() or \"sql\" in response.lower()\n\n# Example usage:\nif __name__ == '__main__':\n    scanner = Scanner('http://example.com/page?param=')\n    scanner.scan_for_sql_injection()",
    "rejected_code": "import requests\n\nclass Scanner:\n    def __init__(self, url):\n        self.url = url\n\n    def scan_for_sql_injection(self):\n        payloads = [\"' OR '1'='1\", \"' OR '1'='1' -- \", \"' OR '1'='1' /* \"]\n        for payload in payloads:\n            response = requests.get(self.url + payload)\n            if self.is_vulnerable(response.text):\n                print(f'Potential SQL injection vulnerability found with payload: {payload}')\n\n    def is_vulnerable(self, response):\n        if \"error\" in response.lower() or \"sql\" in response.lower():\n            return True\n        return False\n\nscanner = Scanner('http://example.com/page?param=')\nscanner.scan_for_sql_injection()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.023809523809523808,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Build a security scanning class for vulnerability detection",
    "code_form": "scanner class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you write a class in Python that implements a security scanner for detecting vulnerabilities in web applications?",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom typing import List\n\nclass Scanner:\n    \"\"\"\n    A class to scan a web application for potential SQL injection vulnerabilities.\n    This class utilizes the requests library to simulate HTTP requests and checks\n    for common SQL injection patterns in the responses.\n    \"\"\"\n\n    def __init__(self, url: str) -> None:\n        \"\"\"\n        Initializes the Scanner with a target URL.\n\n        :param url: The base URL of the web application to scan.\n        \"\"\"\n        self.url = url\n\n    def scan_for_sql_injection(self) -> None:\n        \"\"\"\n        Scans the target URL for potential SQL injection vulnerabilities by sending\n        crafted payloads and analyzing the responses.\n        \"\"\"\n        payloads: List[str] = [\"' OR '1'='1\", \"' OR '1'='1' -- \", \"' OR '1'='1' /* \"]\n        for payload in payloads:\n            response = requests.get(self.url + payload)\n            if self.is_vulnerable(response.text):\n                print(f'Potential SQL injection vulnerability found with payload: {payload}')\n\n    def is_vulnerable(self, response: str) -> bool:\n        \"\"\"\n        Checks if the response indicates a potential SQL injection vulnerability.\n\n        :param response: The response text from the HTTP request.\n        :return: True if a vulnerability is detected, otherwise False.\n        \"\"\"\n        return \"error\" in response.lower() or \"sql\" in response.lower()\n\n# Example usage:\nif __name__ == '__main__':\n    scanner = Scanner('http://example.com/page?param=')\n    scanner.scan_for_sql_injection()",
    "rejected_code": "import requests\n\nclass Scanner:\n    def __init__(self, url):\n        self.url = url\n\n    def scan_for_sql_injection(self):\n        payloads = [\"' OR '1'='1\", \"' OR '1'='1' -- \", \"' OR '1'='1' /* \"]\n        for payload in payloads:\n            response = requests.get(self.url + payload)\n            if self.is_vulnerable(response.text):\n                print(f'Potential SQL injection vulnerability found with payload: {payload}')\n\n    def is_vulnerable(self, response):\n        if \"error\" in response.lower() or \"sql\" in response.lower():\n            return True\n        return False\n\nscanner = Scanner('http://example.com/page?param=')\nscanner.scan_for_sql_injection()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.023809523809523808,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Build a security scanning class for vulnerability detection",
    "code_form": "scanner class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python class that scans a web application for vulnerabilities, specifying input as a URL and output as a list of detected vulnerabilities.",
      "role": "user"
    },
    "chosen_code": "import requests\nfrom typing import List\n\nclass Scanner:\n    \"\"\"\n    A class to scan a web application for potential SQL injection vulnerabilities.\n    This class utilizes the requests library to simulate HTTP requests and checks\n    for common SQL injection patterns in the responses.\n    \"\"\"\n\n    def __init__(self, url: str) -> None:\n        \"\"\"\n        Initializes the Scanner with a target URL.\n\n        :param url: The base URL of the web application to scan.\n        \"\"\"\n        self.url = url\n\n    def scan_for_sql_injection(self) -> None:\n        \"\"\"\n        Scans the target URL for potential SQL injection vulnerabilities by sending\n        crafted payloads and analyzing the responses.\n        \"\"\"\n        payloads: List[str] = [\"' OR '1'='1\", \"' OR '1'='1' -- \", \"' OR '1'='1' /* \"]\n        for payload in payloads:\n            response = requests.get(self.url + payload)\n            if self.is_vulnerable(response.text):\n                print(f'Potential SQL injection vulnerability found with payload: {payload}')\n\n    def is_vulnerable(self, response: str) -> bool:\n        \"\"\"\n        Checks if the response indicates a potential SQL injection vulnerability.\n\n        :param response: The response text from the HTTP request.\n        :return: True if a vulnerability is detected, otherwise False.\n        \"\"\"\n        return \"error\" in response.lower() or \"sql\" in response.lower()\n\n# Example usage:\nif __name__ == '__main__':\n    scanner = Scanner('http://example.com/page?param=')\n    scanner.scan_for_sql_injection()",
    "rejected_code": "import requests\n\nclass Scanner:\n    def __init__(self, url):\n        self.url = url\n\n    def scan_for_sql_injection(self):\n        payloads = [\"' OR '1'='1\", \"' OR '1'='1' -- \", \"' OR '1'='1' /* \"]\n        for payload in payloads:\n            response = requests.get(self.url + payload)\n            if self.is_vulnerable(response.text):\n                print(f'Potential SQL injection vulnerability found with payload: {payload}')\n\n    def is_vulnerable(self, response):\n        if \"error\" in response.lower() or \"sql\" in response.lower():\n            return True\n        return False\n\nscanner = Scanner('http://example.com/page?param=')\nscanner.scan_for_sql_injection()",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.25,
      "pep8_compliance": null,
      "comment_density": 0.023809523809523808,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": true,
        "output": "",
        "error": ""
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Implement a signal processing function for noise reduction",
    "code_form": "processor function",
    "prompt_type": "default",
    "prompt": {
      "content": "Write Python code to implement a noise reduction function for audio processing using the librosa library.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport numpy as np\nfrom typing import Union\n\n\ndef noise_reduction(audio_path: str, output_path: str = 'cleaned_audio.wav') -> None:\n    \"\"\"\n    Reduces background noise from an audio file using a simple noise reduction technique.\n\n    Parameters:\n    audio_path (str): The path to the input audio file.\n    output_path (str): The path where the cleaned audio will be saved. Defaults to 'cleaned_audio.wav'.\n\n    Returns:\n    None: The function saves the cleaned audio to the specified output path.\n    \"\"\"\n    # Load the audio file\n    y, sr = librosa.load(audio_path, sr=None)\n\n    # Extract a sample of noise from the beginning of the audio\n    noise_clip = y[0:int(sr * 0.5)]  # First 0.5 seconds as noise profile\n\n    # Calculate the noise profile (mean absolute value)\n    noise_profile = np.mean(np.abs(noise_clip))\n\n    # Create a reduced noise signal by zeroing out values below the noise profile\n    reduced_noise = np.where(np.abs(y) < noise_profile, 0, y)\n\n    # Save the cleaned audio to the specified output path\n    librosa.output.write_wav(output_path, reduced_noise, sr)\n\n\n# Example usage of the noise reduction function\nif __name__ == '__main__':\n    noise_reduction('guitar_recording.wav')",
    "rejected_code": "import librosa\nimport numpy as np\n\ndef noise_reduction(audio_path):\n    y, sr = librosa.load(audio_path)\n    noise_clip = y[0:int(sr*0.5)]\n    noise_profile = np.mean(np.abs(noise_clip))\n    reduced_noise = np.where(np.abs(y) < noise_profile, 0, y)\n    librosa.output.write_wav('cleaned_audio.wav', reduced_noise, sr)\n\nnoise_reduction('guitar_recording.wav')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.17142857142857143,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Implement a signal processing function for noise reduction",
    "code_form": "processor function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Create a function in Python that performs noise reduction on an audio file using the librosa library.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport numpy as np\nfrom typing import Union\n\n\ndef noise_reduction(audio_path: str, output_path: str = 'cleaned_audio.wav') -> None:\n    \"\"\"\n    Reduces background noise from an audio file using a simple noise reduction technique.\n\n    Parameters:\n    audio_path (str): The path to the input audio file.\n    output_path (str): The path where the cleaned audio will be saved. Defaults to 'cleaned_audio.wav'.\n\n    Returns:\n    None: The function saves the cleaned audio to the specified output path.\n    \"\"\"\n    # Load the audio file\n    y, sr = librosa.load(audio_path, sr=None)\n\n    # Extract a sample of noise from the beginning of the audio\n    noise_clip = y[0:int(sr * 0.5)]  # First 0.5 seconds as noise profile\n\n    # Calculate the noise profile (mean absolute value)\n    noise_profile = np.mean(np.abs(noise_clip))\n\n    # Create a reduced noise signal by zeroing out values below the noise profile\n    reduced_noise = np.where(np.abs(y) < noise_profile, 0, y)\n\n    # Save the cleaned audio to the specified output path\n    librosa.output.write_wav(output_path, reduced_noise, sr)\n\n\n# Example usage of the noise reduction function\nif __name__ == '__main__':\n    noise_reduction('guitar_recording.wav')",
    "rejected_code": "import librosa\nimport numpy as np\n\ndef noise_reduction(audio_path):\n    y, sr = librosa.load(audio_path)\n    noise_clip = y[0:int(sr*0.5)]\n    noise_profile = np.mean(np.abs(noise_clip))\n    reduced_noise = np.where(np.abs(y) < noise_profile, 0, y)\n    librosa.output.write_wav('cleaned_audio.wav', reduced_noise, sr)\n\nnoise_reduction('guitar_recording.wav')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.17142857142857143,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Implement a signal processing function for noise reduction",
    "code_form": "processor function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Provide a Python function that takes a string input for the audio file path and outputs a cleaned audio file using the librosa library.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport numpy as np\nfrom typing import Union\n\n\ndef noise_reduction(audio_path: str, output_path: str = 'cleaned_audio.wav') -> None:\n    \"\"\"\n    Reduces background noise from an audio file using a simple noise reduction technique.\n\n    Parameters:\n    audio_path (str): The path to the input audio file.\n    output_path (str): The path where the cleaned audio will be saved. Defaults to 'cleaned_audio.wav'.\n\n    Returns:\n    None: The function saves the cleaned audio to the specified output path.\n    \"\"\"\n    # Load the audio file\n    y, sr = librosa.load(audio_path, sr=None)\n\n    # Extract a sample of noise from the beginning of the audio\n    noise_clip = y[0:int(sr * 0.5)]  # First 0.5 seconds as noise profile\n\n    # Calculate the noise profile (mean absolute value)\n    noise_profile = np.mean(np.abs(noise_clip))\n\n    # Create a reduced noise signal by zeroing out values below the noise profile\n    reduced_noise = np.where(np.abs(y) < noise_profile, 0, y)\n\n    # Save the cleaned audio to the specified output path\n    librosa.output.write_wav(output_path, reduced_noise, sr)\n\n\n# Example usage of the noise reduction function\nif __name__ == '__main__':\n    noise_reduction('guitar_recording.wav')",
    "rejected_code": "import librosa\nimport numpy as np\n\ndef noise_reduction(audio_path):\n    y, sr = librosa.load(audio_path)\n    noise_clip = y[0:int(sr*0.5)]\n    noise_profile = np.mean(np.abs(noise_clip))\n    reduced_noise = np.where(np.abs(y) < noise_profile, 0, y)\n    librosa.output.write_wav('cleaned_audio.wav', reduced_noise, sr)\n\nnoise_reduction('guitar_recording.wav')",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.17142857142857143,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Develop a data encryption function with key rotation",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to develop a data encryption function with key rotation.",
      "role": "user"
    },
    "chosen_code": "from cryptography.fernet import Fernet\nimport datetime\nfrom typing import Optional, Tuple, List\n\nclass EncryptionUtility:\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the EncryptionUtility class and rotates the key for the first time.\n        \"\"\"\n        self.keys: List[Tuple[bytes, datetime.datetime]] = []\n        self.rotate_key()\n\n    def rotate_key(self) -> None:\n        \"\"\"\n        Generates a new encryption key, stores it with the current timestamp, and cleans up old keys.\n        \"\"\"\n        key = Fernet.generate_key()\n        self.keys.append((key, datetime.datetime.now()))\n        self.cleanup_keys()\n\n    def cleanup_keys(self) -> None:\n        \"\"\"\n        Removes keys that are older than one month from the keys list.\n        \"\"\"\n        one_month_ago = datetime.datetime.now() - datetime.timedelta(days=30)\n        self.keys = [k for k in self.keys if k[1] > one_month_ago]\n\n    def encrypt(self, data: str) -> str:\n        \"\"\"\n        Encrypts the given data using the most recent key.\n        \n        :param data: The data to be encrypted.\n        :return: The encrypted data as a string.\n        \"\"\"\n        if not self.keys:\n            self.rotate_key()  # Ensure there is at least one key\n        f = Fernet(self.keys[-1][0])\n        return f.encrypt(data.encode()).decode()\n\n    def decrypt(self, token: str) -> Optional[str]:\n        \"\"\"\n        Decrypts the given token using the most recent key that can decrypt it.\n        \n        :param token: The encrypted data to be decrypted.\n        :return: The decrypted data as a string, or None if decryption fails.\n        \"\"\"\n        for key, _ in reversed(self.keys):\n            try:\n                f = Fernet(key)\n                return f.decrypt(token.encode()).decode()\n            except Exception:\n                continue  # Try the next key if decryption fails\n        return None  # Return None if no key can decrypt the token\n\nencryption_util = EncryptionUtility()\n\n# Sample usage:\n# encrypted_data = encryption_util.encrypt('Sensitive Customer Info')\n# decrypted_data = encryption_util.decrypt(encrypted_data)",
    "rejected_code": "from cryptography.fernet import Fernet\nimport datetime\nimport os\n\nclass EncryptionUtility:\n    def __init__(self):\n        self.keys = []\n        self.rotate_key()\n\n    def rotate_key(self):\n        key = Fernet.generate_key()\n        self.keys.append((key, datetime.datetime.now()))\n        self.cleanup_keys()\n\n    def cleanup_keys(self):\n        one_month_ago = datetime.datetime.now() - datetime.timedelta(days=30)\n        self.keys = [k for k in self.keys if k[1] > one_month_ago]\n\n    def encrypt(self, data):\n        if not self.keys:\n            self.rotate_key()\n        f = Fernet(self.keys[-1][0])\n        return f.encrypt(data.encode()).decode()\n\n    def decrypt(self, token):\n        for key, _ in reversed(self.keys):\n            try:\n                f = Fernet(key)\n                return f.decrypt(token.encode()).decode()\n            except:\n                continue\n        return None\n\nencryption_util = EncryptionUtility()\n\n# Sample usage:\n# encrypted_data = encryption_util.encrypt('Sensitive Customer Info')\n# decrypted_data = encryption_util.decrypt(encrypted_data)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.05084745762711865,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.07894736842105263,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Develop a data encryption function with key rotation",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a class that implements a data encryption function with key rotation.",
      "role": "user"
    },
    "chosen_code": "from cryptography.fernet import Fernet\nimport datetime\nfrom typing import Optional, Tuple, List\n\nclass EncryptionUtility:\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the EncryptionUtility class and rotates the key for the first time.\n        \"\"\"\n        self.keys: List[Tuple[bytes, datetime.datetime]] = []\n        self.rotate_key()\n\n    def rotate_key(self) -> None:\n        \"\"\"\n        Generates a new encryption key, stores it with the current timestamp, and cleans up old keys.\n        \"\"\"\n        key = Fernet.generate_key()\n        self.keys.append((key, datetime.datetime.now()))\n        self.cleanup_keys()\n\n    def cleanup_keys(self) -> None:\n        \"\"\"\n        Removes keys that are older than one month from the keys list.\n        \"\"\"\n        one_month_ago = datetime.datetime.now() - datetime.timedelta(days=30)\n        self.keys = [k for k in self.keys if k[1] > one_month_ago]\n\n    def encrypt(self, data: str) -> str:\n        \"\"\"\n        Encrypts the given data using the most recent key.\n        \n        :param data: The data to be encrypted.\n        :return: The encrypted data as a string.\n        \"\"\"\n        if not self.keys:\n            self.rotate_key()  # Ensure there is at least one key\n        f = Fernet(self.keys[-1][0])\n        return f.encrypt(data.encode()).decode()\n\n    def decrypt(self, token: str) -> Optional[str]:\n        \"\"\"\n        Decrypts the given token using the most recent key that can decrypt it.\n        \n        :param token: The encrypted data to be decrypted.\n        :return: The decrypted data as a string, or None if decryption fails.\n        \"\"\"\n        for key, _ in reversed(self.keys):\n            try:\n                f = Fernet(key)\n                return f.decrypt(token.encode()).decode()\n            except Exception:\n                continue  # Try the next key if decryption fails\n        return None  # Return None if no key can decrypt the token\n\nencryption_util = EncryptionUtility()\n\n# Sample usage:\n# encrypted_data = encryption_util.encrypt('Sensitive Customer Info')\n# decrypted_data = encryption_util.decrypt(encrypted_data)",
    "rejected_code": "from cryptography.fernet import Fernet\nimport datetime\nimport os\n\nclass EncryptionUtility:\n    def __init__(self):\n        self.keys = []\n        self.rotate_key()\n\n    def rotate_key(self):\n        key = Fernet.generate_key()\n        self.keys.append((key, datetime.datetime.now()))\n        self.cleanup_keys()\n\n    def cleanup_keys(self):\n        one_month_ago = datetime.datetime.now() - datetime.timedelta(days=30)\n        self.keys = [k for k in self.keys if k[1] > one_month_ago]\n\n    def encrypt(self, data):\n        if not self.keys:\n            self.rotate_key()\n        f = Fernet(self.keys[-1][0])\n        return f.encrypt(data.encode()).decode()\n\n    def decrypt(self, token):\n        for key, _ in reversed(self.keys):\n            try:\n                f = Fernet(key)\n                return f.decrypt(token.encode()).decode()\n            except:\n                continue\n        return None\n\nencryption_util = EncryptionUtility()\n\n# Sample usage:\n# encrypted_data = encryption_util.encrypt('Sensitive Customer Info')\n# decrypted_data = encryption_util.decrypt(encrypted_data)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.05084745762711865,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.07894736842105263,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    }
  },
  {
    "domain": "cybersecurity",
    "task": "Develop a data encryption function with key rotation",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a class that implements a data encryption function with key rotation, where the input is a string and the output is also a string.",
      "role": "user"
    },
    "chosen_code": "from cryptography.fernet import Fernet\nimport datetime\nfrom typing import Optional, Tuple, List\n\nclass EncryptionUtility:\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the EncryptionUtility class and rotates the key for the first time.\n        \"\"\"\n        self.keys: List[Tuple[bytes, datetime.datetime]] = []\n        self.rotate_key()\n\n    def rotate_key(self) -> None:\n        \"\"\"\n        Generates a new encryption key, stores it with the current timestamp, and cleans up old keys.\n        \"\"\"\n        key = Fernet.generate_key()\n        self.keys.append((key, datetime.datetime.now()))\n        self.cleanup_keys()\n\n    def cleanup_keys(self) -> None:\n        \"\"\"\n        Removes keys that are older than one month from the keys list.\n        \"\"\"\n        one_month_ago = datetime.datetime.now() - datetime.timedelta(days=30)\n        self.keys = [k for k in self.keys if k[1] > one_month_ago]\n\n    def encrypt(self, data: str) -> str:\n        \"\"\"\n        Encrypts the given data using the most recent key.\n        \n        :param data: The data to be encrypted.\n        :return: The encrypted data as a string.\n        \"\"\"\n        if not self.keys:\n            self.rotate_key()  # Ensure there is at least one key\n        f = Fernet(self.keys[-1][0])\n        return f.encrypt(data.encode()).decode()\n\n    def decrypt(self, token: str) -> Optional[str]:\n        \"\"\"\n        Decrypts the given token using the most recent key that can decrypt it.\n        \n        :param token: The encrypted data to be decrypted.\n        :return: The decrypted data as a string, or None if decryption fails.\n        \"\"\"\n        for key, _ in reversed(self.keys):\n            try:\n                f = Fernet(key)\n                return f.decrypt(token.encode()).decode()\n            except Exception:\n                continue  # Try the next key if decryption fails\n        return None  # Return None if no key can decrypt the token\n\nencryption_util = EncryptionUtility()\n\n# Sample usage:\n# encrypted_data = encryption_util.encrypt('Sensitive Customer Info')\n# decrypted_data = encryption_util.decrypt(encrypted_data)",
    "rejected_code": "from cryptography.fernet import Fernet\nimport datetime\nimport os\n\nclass EncryptionUtility:\n    def __init__(self):\n        self.keys = []\n        self.rotate_key()\n\n    def rotate_key(self):\n        key = Fernet.generate_key()\n        self.keys.append((key, datetime.datetime.now()))\n        self.cleanup_keys()\n\n    def cleanup_keys(self):\n        one_month_ago = datetime.datetime.now() - datetime.timedelta(days=30)\n        self.keys = [k for k in self.keys if k[1] > one_month_ago]\n\n    def encrypt(self, data):\n        if not self.keys:\n            self.rotate_key()\n        f = Fernet(self.keys[-1][0])\n        return f.encrypt(data.encode()).decode()\n\n    def decrypt(self, token):\n        for key, _ in reversed(self.keys):\n            try:\n                f = Fernet(key)\n                return f.decrypt(token.encode()).decode()\n            except:\n                continue\n        return None\n\nencryption_util = EncryptionUtility()\n\n# Sample usage:\n# encrypted_data = encryption_util.encrypt('Sensitive Customer Info')\n# decrypted_data = encryption_util.decrypt(encrypted_data)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.05084745762711865,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.07894736842105263,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Build an audio feature extraction system for classification",
    "code_form": "extractor class",
    "prompt_type": "default",
    "prompt": {
      "content": "Write Python code to build an audio feature extraction system for classification.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport numpy as np\nfrom typing import Any, Tuple\n\nclass AudioFeatureExtractor:\n    \"\"\"\n    A class to extract audio features from a given audio file.\n    This class focuses on extracting Mel-frequency cepstral coefficients (MFCCs)\n    for audio classification tasks.\n    \"\"\"\n\n    def __init__(self, audio_file: str) -> None:\n        \"\"\"\n        Initialize the AudioFeatureExtractor with the path to the audio file.\n        :param audio_file: Path to the audio file (WAV format).\n        \"\"\"\n        self.audio_file = audio_file\n\n    def extract_features(self) -> np.ndarray:\n        \"\"\"\n        Extract MFCC features from the audio file.\n        :return: A numpy array containing the mean of the MFCCs.\n        \"\"\"\n        # Load the audio file\n        y: np.ndarray, sr: int = librosa.load(self.audio_file, sr=None)\n        # Extract MFCC features\n        mfccs: np.ndarray = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n        # Return the mean of the MFCCs across time frames\n        return np.mean(mfccs.T, axis=0)\n\n# Example usage\nif __name__ == '__main__':\n    extractor = AudioFeatureExtractor('path/to/audio.wav')\n    features: np.ndarray = extractor.extract_features()\n    print(features)",
    "rejected_code": "import librosa\nimport numpy as np\n\nclass AudioFeatureExtractor:\n    def __init__(self, audio_file):\n        self.audio_file = audio_file\n\n    def extract_features(self):\n        y, sr = librosa.load(self.audio_file, sr=None)\n        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n        return np.mean(mfccs.T, axis=0)\n\n# Example usage\nextractor = AudioFeatureExtractor('path/to/audio.wav')\nfeatures = extractor.extract_features()\nprint(features)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.05084745762711865,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0625,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Build an audio feature extraction system for classification",
    "code_form": "extractor class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Write a Python class to build an audio feature extraction system for classification.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport numpy as np\nfrom typing import Any, Tuple\n\nclass AudioFeatureExtractor:\n    \"\"\"\n    A class to extract audio features from a given audio file.\n    This class focuses on extracting Mel-frequency cepstral coefficients (MFCCs)\n    for audio classification tasks.\n    \"\"\"\n\n    def __init__(self, audio_file: str) -> None:\n        \"\"\"\n        Initialize the AudioFeatureExtractor with the path to the audio file.\n        :param audio_file: Path to the audio file (WAV format).\n        \"\"\"\n        self.audio_file = audio_file\n\n    def extract_features(self) -> np.ndarray:\n        \"\"\"\n        Extract MFCC features from the audio file.\n        :return: A numpy array containing the mean of the MFCCs.\n        \"\"\"\n        # Load the audio file\n        y: np.ndarray, sr: int = librosa.load(self.audio_file, sr=None)\n        # Extract MFCC features\n        mfccs: np.ndarray = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n        # Return the mean of the MFCCs across time frames\n        return np.mean(mfccs.T, axis=0)\n\n# Example usage\nif __name__ == '__main__':\n    extractor = AudioFeatureExtractor('path/to/audio.wav')\n    features: np.ndarray = extractor.extract_features()\n    print(features)",
    "rejected_code": "import librosa\nimport numpy as np\n\nclass AudioFeatureExtractor:\n    def __init__(self, audio_file):\n        self.audio_file = audio_file\n\n    def extract_features(self):\n        y, sr = librosa.load(self.audio_file, sr=None)\n        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n        return np.mean(mfccs.T, axis=0)\n\n# Example usage\nextractor = AudioFeatureExtractor('path/to/audio.wav')\nfeatures = extractor.extract_features()\nprint(features)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.05084745762711865,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0625,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Build an audio feature extraction system for classification",
    "code_form": "extractor class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python class that takes a string input for an audio file path and outputs a numpy array of extracted features for classification.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport numpy as np\nfrom typing import Any, Tuple\n\nclass AudioFeatureExtractor:\n    \"\"\"\n    A class to extract audio features from a given audio file.\n    This class focuses on extracting Mel-frequency cepstral coefficients (MFCCs)\n    for audio classification tasks.\n    \"\"\"\n\n    def __init__(self, audio_file: str) -> None:\n        \"\"\"\n        Initialize the AudioFeatureExtractor with the path to the audio file.\n        :param audio_file: Path to the audio file (WAV format).\n        \"\"\"\n        self.audio_file = audio_file\n\n    def extract_features(self) -> np.ndarray:\n        \"\"\"\n        Extract MFCC features from the audio file.\n        :return: A numpy array containing the mean of the MFCCs.\n        \"\"\"\n        # Load the audio file\n        y: np.ndarray, sr: int = librosa.load(self.audio_file, sr=None)\n        # Extract MFCC features\n        mfccs: np.ndarray = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n        # Return the mean of the MFCCs across time frames\n        return np.mean(mfccs.T, axis=0)\n\n# Example usage\nif __name__ == '__main__':\n    extractor = AudioFeatureExtractor('path/to/audio.wav')\n    features: np.ndarray = extractor.extract_features()\n    print(features)",
    "rejected_code": "import librosa\nimport numpy as np\n\nclass AudioFeatureExtractor:\n    def __init__(self, audio_file):\n        self.audio_file = audio_file\n\n    def extract_features(self):\n        y, sr = librosa.load(self.audio_file, sr=None)\n        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n        return np.mean(mfccs.T, axis=0)\n\n# Example usage\nextractor = AudioFeatureExtractor('path/to/audio.wav')\nfeatures = extractor.extract_features()\nprint(features)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.1666666666666665,
      "pep8_compliance": null,
      "comment_density": 0.05084745762711865,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'cryptography'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0625,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Create a beat detection class with tempo estimation",
    "code_form": "detector class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to create a beat detection class with tempo estimation for audio tracks?",
      "role": "user"
    },
    "chosen_code": "import librosa\nfrom typing import List, Tuple\n\nclass BeatDetector:\n    \"\"\"\n    A class to detect beats and estimate the tempo of audio files.\n\n    Attributes:\n        filepath (str): The path to the audio file.\n        audio (np.ndarray): The audio time series data.\n        sr (int): The sampling rate of the audio file.\n        tempo (float): The estimated tempo in beats per minute (BPM).\n        beat_frames (np.ndarray): The frames where beats occur.\n    \"\"\"\n\n    def __init__(self, filepath: str) -> None:\n        \"\"\"\n        Initializes the BeatDetector with the given audio file path.\n\n        Args:\n            filepath (str): The path to the audio file to analyze.\n        \"\"\"\n        self.filepath = filepath\n        self.audio, self.sr = librosa.load(filepath)\n        self.tempo, self.beat_frames = librosa.beat.beat_track(y=self.audio, sr=self.sr)\n\n    def get_beats(self) -> List[float]:\n        \"\"\"\n        Returns the times of the detected beats in seconds.\n\n        Returns:\n            List[float]: A list of beat times in seconds.\n        \"\"\"\n        return librosa.frames_to_time(self.beat_frames, sr=self.sr).tolist()\n\n    def get_tempo(self) -> float:\n        \"\"\"\n        Returns the estimated tempo in beats per minute (BPM).\n\n        Returns:\n            float: The estimated tempo in BPM.\n        \"\"\"\n        return self.tempo\n\n# Example usage:\n# detector = BeatDetector('path_to_audio_file.mp3')\n# print(detector.get_beats())\n# print(detector.get_tempo())",
    "rejected_code": "import librosa\n\nclass BeatDetector:\n    def __init__(self, filepath):\n        self.filepath = filepath\n        self.audio, self.sr = librosa.load(filepath)\n        self.tempo, self.beat_frames = librosa.beat.beat_track(y=self.audio, sr=self.sr)\n\n    def get_beats(self):\n        return librosa.frames_to_time(self.beat_frames, sr=self.sr)\n\n    def get_tempo(self):\n        return self.tempo\n\n# Example usage:\n# detector = BeatDetector('path_to_audio_file.mp3')\n# print(detector.get_beats())\n# print(detector.get_tempo())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.08333333333333333,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.2222222222222222,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Create a beat detection class with tempo estimation",
    "code_form": "detector class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a class in Python that implements beat detection and tempo estimation for audio files.",
      "role": "user"
    },
    "chosen_code": "import librosa\nfrom typing import List, Tuple\n\nclass BeatDetector:\n    \"\"\"\n    A class to detect beats and estimate the tempo of audio files.\n\n    Attributes:\n        filepath (str): The path to the audio file.\n        audio (np.ndarray): The audio time series data.\n        sr (int): The sampling rate of the audio file.\n        tempo (float): The estimated tempo in beats per minute (BPM).\n        beat_frames (np.ndarray): The frames where beats occur.\n    \"\"\"\n\n    def __init__(self, filepath: str) -> None:\n        \"\"\"\n        Initializes the BeatDetector with the given audio file path.\n\n        Args:\n            filepath (str): The path to the audio file to analyze.\n        \"\"\"\n        self.filepath = filepath\n        self.audio, self.sr = librosa.load(filepath)\n        self.tempo, self.beat_frames = librosa.beat.beat_track(y=self.audio, sr=self.sr)\n\n    def get_beats(self) -> List[float]:\n        \"\"\"\n        Returns the times of the detected beats in seconds.\n\n        Returns:\n            List[float]: A list of beat times in seconds.\n        \"\"\"\n        return librosa.frames_to_time(self.beat_frames, sr=self.sr).tolist()\n\n    def get_tempo(self) -> float:\n        \"\"\"\n        Returns the estimated tempo in beats per minute (BPM).\n\n        Returns:\n            float: The estimated tempo in BPM.\n        \"\"\"\n        return self.tempo\n\n# Example usage:\n# detector = BeatDetector('path_to_audio_file.mp3')\n# print(detector.get_beats())\n# print(detector.get_tempo())",
    "rejected_code": "import librosa\n\nclass BeatDetector:\n    def __init__(self, filepath):\n        self.filepath = filepath\n        self.audio, self.sr = librosa.load(filepath)\n        self.tempo, self.beat_frames = librosa.beat.beat_track(y=self.audio, sr=self.sr)\n\n    def get_beats(self):\n        return librosa.frames_to_time(self.beat_frames, sr=self.sr)\n\n    def get_tempo(self):\n        return self.tempo\n\n# Example usage:\n# detector = BeatDetector('path_to_audio_file.mp3')\n# print(detector.get_beats())\n# print(detector.get_tempo())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.08333333333333333,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.2222222222222222,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Create a beat detection class with tempo estimation",
    "code_form": "detector class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python class that accepts a file path as input and provides methods to return the beat times and tempo in BPM.",
      "role": "user"
    },
    "chosen_code": "import librosa\nfrom typing import List, Tuple\n\nclass BeatDetector:\n    \"\"\"\n    A class to detect beats and estimate the tempo of audio files.\n\n    Attributes:\n        filepath (str): The path to the audio file.\n        audio (np.ndarray): The audio time series data.\n        sr (int): The sampling rate of the audio file.\n        tempo (float): The estimated tempo in beats per minute (BPM).\n        beat_frames (np.ndarray): The frames where beats occur.\n    \"\"\"\n\n    def __init__(self, filepath: str) -> None:\n        \"\"\"\n        Initializes the BeatDetector with the given audio file path.\n\n        Args:\n            filepath (str): The path to the audio file to analyze.\n        \"\"\"\n        self.filepath = filepath\n        self.audio, self.sr = librosa.load(filepath)\n        self.tempo, self.beat_frames = librosa.beat.beat_track(y=self.audio, sr=self.sr)\n\n    def get_beats(self) -> List[float]:\n        \"\"\"\n        Returns the times of the detected beats in seconds.\n\n        Returns:\n            List[float]: A list of beat times in seconds.\n        \"\"\"\n        return librosa.frames_to_time(self.beat_frames, sr=self.sr).tolist()\n\n    def get_tempo(self) -> float:\n        \"\"\"\n        Returns the estimated tempo in beats per minute (BPM).\n\n        Returns:\n            float: The estimated tempo in BPM.\n        \"\"\"\n        return self.tempo\n\n# Example usage:\n# detector = BeatDetector('path_to_audio_file.mp3')\n# print(detector.get_beats())\n# print(detector.get_tempo())",
    "rejected_code": "import librosa\n\nclass BeatDetector:\n    def __init__(self, filepath):\n        self.filepath = filepath\n        self.audio, self.sr = librosa.load(filepath)\n        self.tempo, self.beat_frames = librosa.beat.beat_track(y=self.audio, sr=self.sr)\n\n    def get_beats(self):\n        return librosa.frames_to_time(self.beat_frames, sr=self.sr)\n\n    def get_tempo(self):\n        return self.tempo\n\n# Example usage:\n# detector = BeatDetector('path_to_audio_file.mp3')\n# print(detector.get_beats())\n# print(detector.get_tempo())",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.08333333333333333,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.25,
      "pep8_compliance": null,
      "comment_density": 0.2222222222222222,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Create a spatial analysis system for proximity calculations",
    "code_form": "analyzer class",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to create a spatial analysis system for proximity calculations between schools and parks.",
      "role": "user"
    },
    "chosen_code": "import geopandas as gpd\nfrom shapely.geometry import Point, BaseGeometry\nfrom typing import List, Dict, Union\n\nclass ProximityAnalyzer:\n    \"\"\"\n    A class to analyze the proximity of schools to parks.\n\n    Attributes:\n        schools (GeoDataFrame): A GeoDataFrame containing school locations.\n        parks (GeoDataFrame): A GeoDataFrame containing park locations.\n    \"\"\"\n\n    def __init__(self, schools_file: str, parks_file: str) -> None:\n        \"\"\"\n        Initializes the ProximityAnalyzer with school and park data.\n\n        Args:\n            schools_file (str): Path to the GeoJSON file containing school data.\n            parks_file (str): Path to the GeoJSON file containing park data.\n        \"\"\"\n        self.schools = gpd.read_file(schools_file)\n        self.parks = gpd.read_file(parks_file)\n\n    def calculate_proximity(self, distance: float) -> gpd.GeoDataFrame:\n        \"\"\"\n        Calculates which parks are within a specified distance from each school.\n\n        Args:\n            distance (float): The maximum distance (in meters) to consider for proximity.\n\n        Returns:\n            GeoDataFrame: A GeoDataFrame containing school names and their nearby parks.\n        \"\"\"\n        # Calculate the centroid of each school's geometry\n        self.schools['geometry'] = self.schools['geometry'].apply(lambda geom: geom.centroid)\n\n        # Identify nearby parks within the specified distance\n        self.schools['nearby_parks'] = self.schools.geometry.apply(\n            lambda school_geom: self.parks[self.parks.distance(school_geom) <= distance]\n        )\n\n        return self.schools[['name', 'nearby_parks']]\n\n# Example of how to use the ProximityAnalyzer class\nif __name__ == '__main__':\n    analyzer = ProximityAnalyzer('schools.geojson', 'parks.geojson')\n    result = analyzer.calculate_proximity(500)\n    print(result)",
    "rejected_code": "import geopandas as gpd\nfrom shapely.geometry import Point\n\nclass ProximityAnalyzer:\n    def __init__(self, schools_file, parks_file):\n        self.schools = gpd.read_file(schools_file)\n        self.parks = gpd.read_file(parks_file)\n\n    def calculate_proximity(self, distance):\n        self.schools['geometry'] = self.schools['geometry'].apply(lambda x: x.centroid)\n        self.schools['nearby_parks'] = self.schools.geometry.apply(lambda x: self.parks[self.parks.distance(x) <= distance])\n        return self.schools[['name', 'nearby_parks']]\n\nanalyzer = ProximityAnalyzer('schools.geojson', 'parks.geojson')\nresult = analyzer.calculate_proximity(500)\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.061224489795918366,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Create a spatial analysis system for proximity calculations",
    "code_form": "analyzer class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please provide a class implementation for a spatial analysis system that calculates proximity between schools and parks.",
      "role": "user"
    },
    "chosen_code": "import geopandas as gpd\nfrom shapely.geometry import Point, BaseGeometry\nfrom typing import List, Dict, Union\n\nclass ProximityAnalyzer:\n    \"\"\"\n    A class to analyze the proximity of schools to parks.\n\n    Attributes:\n        schools (GeoDataFrame): A GeoDataFrame containing school locations.\n        parks (GeoDataFrame): A GeoDataFrame containing park locations.\n    \"\"\"\n\n    def __init__(self, schools_file: str, parks_file: str) -> None:\n        \"\"\"\n        Initializes the ProximityAnalyzer with school and park data.\n\n        Args:\n            schools_file (str): Path to the GeoJSON file containing school data.\n            parks_file (str): Path to the GeoJSON file containing park data.\n        \"\"\"\n        self.schools = gpd.read_file(schools_file)\n        self.parks = gpd.read_file(parks_file)\n\n    def calculate_proximity(self, distance: float) -> gpd.GeoDataFrame:\n        \"\"\"\n        Calculates which parks are within a specified distance from each school.\n\n        Args:\n            distance (float): The maximum distance (in meters) to consider for proximity.\n\n        Returns:\n            GeoDataFrame: A GeoDataFrame containing school names and their nearby parks.\n        \"\"\"\n        # Calculate the centroid of each school's geometry\n        self.schools['geometry'] = self.schools['geometry'].apply(lambda geom: geom.centroid)\n\n        # Identify nearby parks within the specified distance\n        self.schools['nearby_parks'] = self.schools.geometry.apply(\n            lambda school_geom: self.parks[self.parks.distance(school_geom) <= distance]\n        )\n\n        return self.schools[['name', 'nearby_parks']]\n\n# Example of how to use the ProximityAnalyzer class\nif __name__ == '__main__':\n    analyzer = ProximityAnalyzer('schools.geojson', 'parks.geojson')\n    result = analyzer.calculate_proximity(500)\n    print(result)",
    "rejected_code": "import geopandas as gpd\nfrom shapely.geometry import Point\n\nclass ProximityAnalyzer:\n    def __init__(self, schools_file, parks_file):\n        self.schools = gpd.read_file(schools_file)\n        self.parks = gpd.read_file(parks_file)\n\n    def calculate_proximity(self, distance):\n        self.schools['geometry'] = self.schools['geometry'].apply(lambda x: x.centroid)\n        self.schools['nearby_parks'] = self.schools.geometry.apply(lambda x: self.parks[self.parks.distance(x) <= distance])\n        return self.schools[['name', 'nearby_parks']]\n\nanalyzer = ProximityAnalyzer('schools.geojson', 'parks.geojson')\nresult = analyzer.calculate_proximity(500)\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.061224489795918366,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Create a spatial analysis system for proximity calculations",
    "code_form": "analyzer class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Please provide a class implementation for a spatial analysis system that calculates proximity between schools and parks, specifying input types as file paths and output types as a GeoDataFrame.",
      "role": "user"
    },
    "chosen_code": "import geopandas as gpd\nfrom shapely.geometry import Point, BaseGeometry\nfrom typing import List, Dict, Union\n\nclass ProximityAnalyzer:\n    \"\"\"\n    A class to analyze the proximity of schools to parks.\n\n    Attributes:\n        schools (GeoDataFrame): A GeoDataFrame containing school locations.\n        parks (GeoDataFrame): A GeoDataFrame containing park locations.\n    \"\"\"\n\n    def __init__(self, schools_file: str, parks_file: str) -> None:\n        \"\"\"\n        Initializes the ProximityAnalyzer with school and park data.\n\n        Args:\n            schools_file (str): Path to the GeoJSON file containing school data.\n            parks_file (str): Path to the GeoJSON file containing park data.\n        \"\"\"\n        self.schools = gpd.read_file(schools_file)\n        self.parks = gpd.read_file(parks_file)\n\n    def calculate_proximity(self, distance: float) -> gpd.GeoDataFrame:\n        \"\"\"\n        Calculates which parks are within a specified distance from each school.\n\n        Args:\n            distance (float): The maximum distance (in meters) to consider for proximity.\n\n        Returns:\n            GeoDataFrame: A GeoDataFrame containing school names and their nearby parks.\n        \"\"\"\n        # Calculate the centroid of each school's geometry\n        self.schools['geometry'] = self.schools['geometry'].apply(lambda geom: geom.centroid)\n\n        # Identify nearby parks within the specified distance\n        self.schools['nearby_parks'] = self.schools.geometry.apply(\n            lambda school_geom: self.parks[self.parks.distance(school_geom) <= distance]\n        )\n\n        return self.schools[['name', 'nearby_parks']]\n\n# Example of how to use the ProximityAnalyzer class\nif __name__ == '__main__':\n    analyzer = ProximityAnalyzer('schools.geojson', 'parks.geojson')\n    result = analyzer.calculate_proximity(500)\n    print(result)",
    "rejected_code": "import geopandas as gpd\nfrom shapely.geometry import Point\n\nclass ProximityAnalyzer:\n    def __init__(self, schools_file, parks_file):\n        self.schools = gpd.read_file(schools_file)\n        self.parks = gpd.read_file(parks_file)\n\n    def calculate_proximity(self, distance):\n        self.schools['geometry'] = self.schools['geometry'].apply(lambda x: x.centroid)\n        self.schools['nearby_parks'] = self.schools.geometry.apply(lambda x: self.parks[self.parks.distance(x) <= distance])\n        return self.schools[['name', 'nearby_parks']]\n\nanalyzer = ProximityAnalyzer('schools.geojson', 'parks.geojson')\nresult = analyzer.calculate_proximity(500)\nprint(result)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.061224489795918366,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 1.3333333333333333,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Develop an audio effects application function with multiple transformations",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Write Python code to create an audio effects application that allows users to apply transformations like reverb, pitch shifting, and speed change to an audio file.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport soundfile as sf\nimport numpy as np\nfrom typing import Union\n\n\ndef apply_effects(input_file: str, output_file: str, pitch_shift: int = 0, speed_change: float = 1.0, reverb_amount: float = 0.5) -> None:\n    \"\"\"\n    Apply audio effects to the input sound file and save the modified audio to the output file.\n\n    Parameters:\n        input_file (str): Path to the input audio file.\n        output_file (str): Path where the output audio file will be saved.\n        pitch_shift (int): Number of semitones to shift the pitch. Positive values increase pitch, negative values decrease it.\n        speed_change (float): Factor by which to change the speed of the audio. Values greater than 1.0 speed it up, values less than 1.0 slow it down.\n        reverb_amount (float): Amount of reverb to apply. A value of 0.0 applies no reverb, while higher values increase the effect.\n\n    Returns:\n        None: The function saves the processed audio directly to the output file.\n    \"\"\"\n    # Load the audio file\n    y, sr = librosa.load(input_file, sr=None)\n\n    # Apply pitch shifting if specified\n    if pitch_shift != 0:\n        y = librosa.effects.pitch_shift(y, sr, n_steps=pitch_shift)\n\n    # Apply speed change if specified\n    if speed_change != 1.0:\n        y = librosa.effects.time_stretch(y, speed_change)\n\n    # Apply reverb effect using convolution\n    reverb_kernel = np.ones(int(sr * reverb_amount)) / int(sr * reverb_amount)\n    reverb = np.convolve(y, reverb_kernel, mode='same')\n\n    # Save the modified audio to the output file\n    sf.write(output_file, reverb, sr)\n\n\n# Example usage of the apply_effects function\nif __name__ == '__main__':\n    apply_effects('input.wav', 'output.wav', pitch_shift=2, speed_change=1.2, reverb_amount=0.3)",
    "rejected_code": "import librosa\nimport soundfile as sf\nimport numpy as np\n\ndef apply_effects(input_file, output_file, pitch_shift=0, speed_change=1.0, reverb_amount=0.5):\n    y, sr = librosa.load(input_file)\n    if pitch_shift != 0:\n        y = librosa.effects.pitch_shift(y, sr, n_steps=pitch_shift)\n    if speed_change != 1.0:\n        y = librosa.effects.time_stretch(y, speed_change)\n    reverb = np.convolve(y, np.ones(int(sr * reverb_amount))/int(sr * reverb_amount), mode='same')\n    sf.write(output_file, reverb, sr)\n\napply_effects('input.wav', 'output.wav', pitch_shift=2, speed_change=1.2, reverb_amount=0.3)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.14285714285714285,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Develop an audio effects application function with multiple transformations",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Create a function in Python that implements an audio effects application allowing users to apply transformations like reverb, pitch shifting, and speed change to an audio file.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport soundfile as sf\nimport numpy as np\nfrom typing import Union\n\n\ndef apply_effects(input_file: str, output_file: str, pitch_shift: int = 0, speed_change: float = 1.0, reverb_amount: float = 0.5) -> None:\n    \"\"\"\n    Apply audio effects to the input sound file and save the modified audio to the output file.\n\n    Parameters:\n        input_file (str): Path to the input audio file.\n        output_file (str): Path where the output audio file will be saved.\n        pitch_shift (int): Number of semitones to shift the pitch. Positive values increase pitch, negative values decrease it.\n        speed_change (float): Factor by which to change the speed of the audio. Values greater than 1.0 speed it up, values less than 1.0 slow it down.\n        reverb_amount (float): Amount of reverb to apply. A value of 0.0 applies no reverb, while higher values increase the effect.\n\n    Returns:\n        None: The function saves the processed audio directly to the output file.\n    \"\"\"\n    # Load the audio file\n    y, sr = librosa.load(input_file, sr=None)\n\n    # Apply pitch shifting if specified\n    if pitch_shift != 0:\n        y = librosa.effects.pitch_shift(y, sr, n_steps=pitch_shift)\n\n    # Apply speed change if specified\n    if speed_change != 1.0:\n        y = librosa.effects.time_stretch(y, speed_change)\n\n    # Apply reverb effect using convolution\n    reverb_kernel = np.ones(int(sr * reverb_amount)) / int(sr * reverb_amount)\n    reverb = np.convolve(y, reverb_kernel, mode='same')\n\n    # Save the modified audio to the output file\n    sf.write(output_file, reverb, sr)\n\n\n# Example usage of the apply_effects function\nif __name__ == '__main__':\n    apply_effects('input.wav', 'output.wav', pitch_shift=2, speed_change=1.2, reverb_amount=0.3)",
    "rejected_code": "import librosa\nimport soundfile as sf\nimport numpy as np\n\ndef apply_effects(input_file, output_file, pitch_shift=0, speed_change=1.0, reverb_amount=0.5):\n    y, sr = librosa.load(input_file)\n    if pitch_shift != 0:\n        y = librosa.effects.pitch_shift(y, sr, n_steps=pitch_shift)\n    if speed_change != 1.0:\n        y = librosa.effects.time_stretch(y, speed_change)\n    reverb = np.convolve(y, np.ones(int(sr * reverb_amount))/int(sr * reverb_amount), mode='same')\n    sf.write(output_file, reverb, sr)\n\napply_effects('input.wav', 'output.wav', pitch_shift=2, speed_change=1.2, reverb_amount=0.3)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.14285714285714285,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "audio processing",
    "task": "Develop an audio effects application function with multiple transformations",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a Python function that takes specific input types (str, str, int, float, float) and returns None, implementing an audio effects application for applying transformations like reverb, pitch shifting, and speed change.",
      "role": "user"
    },
    "chosen_code": "import librosa\nimport soundfile as sf\nimport numpy as np\nfrom typing import Union\n\n\ndef apply_effects(input_file: str, output_file: str, pitch_shift: int = 0, speed_change: float = 1.0, reverb_amount: float = 0.5) -> None:\n    \"\"\"\n    Apply audio effects to the input sound file and save the modified audio to the output file.\n\n    Parameters:\n        input_file (str): Path to the input audio file.\n        output_file (str): Path where the output audio file will be saved.\n        pitch_shift (int): Number of semitones to shift the pitch. Positive values increase pitch, negative values decrease it.\n        speed_change (float): Factor by which to change the speed of the audio. Values greater than 1.0 speed it up, values less than 1.0 slow it down.\n        reverb_amount (float): Amount of reverb to apply. A value of 0.0 applies no reverb, while higher values increase the effect.\n\n    Returns:\n        None: The function saves the processed audio directly to the output file.\n    \"\"\"\n    # Load the audio file\n    y, sr = librosa.load(input_file, sr=None)\n\n    # Apply pitch shifting if specified\n    if pitch_shift != 0:\n        y = librosa.effects.pitch_shift(y, sr, n_steps=pitch_shift)\n\n    # Apply speed change if specified\n    if speed_change != 1.0:\n        y = librosa.effects.time_stretch(y, speed_change)\n\n    # Apply reverb effect using convolution\n    reverb_kernel = np.ones(int(sr * reverb_amount)) / int(sr * reverb_amount)\n    reverb = np.convolve(y, reverb_kernel, mode='same')\n\n    # Save the modified audio to the output file\n    sf.write(output_file, reverb, sr)\n\n\n# Example usage of the apply_effects function\nif __name__ == '__main__':\n    apply_effects('input.wav', 'output.wav', pitch_shift=2, speed_change=1.2, reverb_amount=0.3)",
    "rejected_code": "import librosa\nimport soundfile as sf\nimport numpy as np\n\ndef apply_effects(input_file, output_file, pitch_shift=0, speed_change=1.0, reverb_amount=0.5):\n    y, sr = librosa.load(input_file)\n    if pitch_shift != 0:\n        y = librosa.effects.pitch_shift(y, sr, n_steps=pitch_shift)\n    if speed_change != 1.0:\n        y = librosa.effects.time_stretch(y, speed_change)\n    reverb = np.convolve(y, np.ones(int(sr * reverb_amount))/int(sr * reverb_amount), mode='same')\n    sf.write(output_file, reverb, sr)\n\napply_effects('input.wav', 'output.wav', pitch_shift=2, speed_change=1.2, reverb_amount=0.3)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.14285714285714285,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'librosa'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Build a geocoding class with multiple service providers",
    "code_form": "geocoder class",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to build a geocoding class with multiple service providers for converting addresses into geographic coordinates?",
      "role": "user"
    },
    "chosen_code": "from typing import List, Tuple, Dict, Optional\nfrom geopy.geocoders import Nominatim, GoogleV3\nfrom geopy.exc import GeocoderTimedOut, GeocoderServiceError\n\nclass Geocoder:\n    \"\"\"\n    A class to perform geocoding using multiple service providers.\n    This ensures redundancy and reliability in retrieving location data.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the Geocoder with a list of geocoding services.\n        \"\"\"\n        self.geocoders = [\n            Nominatim(user_agent='geoapi'),\n            GoogleV3(api_key='YOUR_API_KEY')\n        ]\n\n    def geocode(self, address: str) -> Optional[Tuple[float, float]]:\n        \"\"\"\n        Geocode a single address to latitude and longitude.\n\n        Args:\n            address (str): The address to geocode.\n\n        Returns:\n            Optional[Tuple[float, float]]: A tuple containing latitude and longitude if successful, otherwise None.\n        \"\"\"\n        for geocoder in self.geocoders:\n            try:\n                location = geocoder.geocode(address)\n                if location:\n                    return (location.latitude, location.longitude)\n            except (GeocoderTimedOut, GeocoderServiceError) as e:\n                print(f'Geocoding error with {geocoder}: {e}')  # Log the error\n                continue\n        return None\n\n    def geocode_multiple(self, addresses: List[str]) -> Dict[str, Optional[Tuple[float, float]]]:\n        \"\"\"\n        Geocode multiple addresses to their corresponding latitude and longitude.\n\n        Args:\n            addresses (List[str]): A list of addresses to geocode.\n\n        Returns:\n            Dict[str, Optional[Tuple[float, float]]]: A dictionary mapping addresses to their coordinates or None if not found.\n        \"\"\"\n        return {address: self.geocode(address) for address in addresses}\n\n\nif __name__ == '__main__':\n    addresses = [\n        '1600 Amphitheatre Parkway, Mountain View, CA',\n        '1 Infinite Loop, Cupertino, CA'\n    ]\n    geocoder = Geocoder()\n    coordinates = geocoder.geocode_multiple(addresses)\n    print(coordinates)",
    "rejected_code": "from geopy.geocoders import Nominatim, GoogleV3\n\nclass Geocoder:\n    def __init__(self):\n        self.geocoders = [Nominatim(user_agent='geoapi'), GoogleV3(api_key='YOUR_API_KEY')]\n\n    def geocode(self, address):\n        for geocoder in self.geocoders:\n            try:\n                location = geocoder.geocode(address)\n                if location:\n                    return (location.latitude, location.longitude)\n            except Exception:\n                continue\n        return None\n\naddresses = ['1600 Amphitheatre Parkway, Mountain View, CA', '1 Infinite Loop, Cupertino, CA']\ngeocoder = Geocoder()\ncoordinates = {address: geocoder.geocode(address) for address in addresses}\nprint(coordinates)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'geopy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopy'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Build a geocoding class with multiple service providers",
    "code_form": "geocoder class",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Please write a Python class that implements a geocoding service with multiple providers to convert addresses into geographic coordinates.",
      "role": "user"
    },
    "chosen_code": "from typing import List, Tuple, Dict, Optional\nfrom geopy.geocoders import Nominatim, GoogleV3\nfrom geopy.exc import GeocoderTimedOut, GeocoderServiceError\n\nclass Geocoder:\n    \"\"\"\n    A class to perform geocoding using multiple service providers.\n    This ensures redundancy and reliability in retrieving location data.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the Geocoder with a list of geocoding services.\n        \"\"\"\n        self.geocoders = [\n            Nominatim(user_agent='geoapi'),\n            GoogleV3(api_key='YOUR_API_KEY')\n        ]\n\n    def geocode(self, address: str) -> Optional[Tuple[float, float]]:\n        \"\"\"\n        Geocode a single address to latitude and longitude.\n\n        Args:\n            address (str): The address to geocode.\n\n        Returns:\n            Optional[Tuple[float, float]]: A tuple containing latitude and longitude if successful, otherwise None.\n        \"\"\"\n        for geocoder in self.geocoders:\n            try:\n                location = geocoder.geocode(address)\n                if location:\n                    return (location.latitude, location.longitude)\n            except (GeocoderTimedOut, GeocoderServiceError) as e:\n                print(f'Geocoding error with {geocoder}: {e}')  # Log the error\n                continue\n        return None\n\n    def geocode_multiple(self, addresses: List[str]) -> Dict[str, Optional[Tuple[float, float]]]:\n        \"\"\"\n        Geocode multiple addresses to their corresponding latitude and longitude.\n\n        Args:\n            addresses (List[str]): A list of addresses to geocode.\n\n        Returns:\n            Dict[str, Optional[Tuple[float, float]]]: A dictionary mapping addresses to their coordinates or None if not found.\n        \"\"\"\n        return {address: self.geocode(address) for address in addresses}\n\n\nif __name__ == '__main__':\n    addresses = [\n        '1600 Amphitheatre Parkway, Mountain View, CA',\n        '1 Infinite Loop, Cupertino, CA'\n    ]\n    geocoder = Geocoder()\n    coordinates = geocoder.geocode_multiple(addresses)\n    print(coordinates)",
    "rejected_code": "from geopy.geocoders import Nominatim, GoogleV3\n\nclass Geocoder:\n    def __init__(self):\n        self.geocoders = [Nominatim(user_agent='geoapi'), GoogleV3(api_key='YOUR_API_KEY')]\n\n    def geocode(self, address):\n        for geocoder in self.geocoders:\n            try:\n                location = geocoder.geocode(address)\n                if location:\n                    return (location.latitude, location.longitude)\n            except Exception:\n                continue\n        return None\n\naddresses = ['1600 Amphitheatre Parkway, Mountain View, CA', '1 Infinite Loop, Cupertino, CA']\ngeocoder = Geocoder()\ncoordinates = {address: geocoder.geocode(address) for address in addresses}\nprint(coordinates)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'geopy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopy'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Build a geocoding class with multiple service providers",
    "code_form": "geocoder class",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Could you write a Python class that takes a list of addresses as input and returns a dictionary of geographic coordinates (latitude and longitude) as output?",
      "role": "user"
    },
    "chosen_code": "from typing import List, Tuple, Dict, Optional\nfrom geopy.geocoders import Nominatim, GoogleV3\nfrom geopy.exc import GeocoderTimedOut, GeocoderServiceError\n\nclass Geocoder:\n    \"\"\"\n    A class to perform geocoding using multiple service providers.\n    This ensures redundancy and reliability in retrieving location data.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"\n        Initializes the Geocoder with a list of geocoding services.\n        \"\"\"\n        self.geocoders = [\n            Nominatim(user_agent='geoapi'),\n            GoogleV3(api_key='YOUR_API_KEY')\n        ]\n\n    def geocode(self, address: str) -> Optional[Tuple[float, float]]:\n        \"\"\"\n        Geocode a single address to latitude and longitude.\n\n        Args:\n            address (str): The address to geocode.\n\n        Returns:\n            Optional[Tuple[float, float]]: A tuple containing latitude and longitude if successful, otherwise None.\n        \"\"\"\n        for geocoder in self.geocoders:\n            try:\n                location = geocoder.geocode(address)\n                if location:\n                    return (location.latitude, location.longitude)\n            except (GeocoderTimedOut, GeocoderServiceError) as e:\n                print(f'Geocoding error with {geocoder}: {e}')  # Log the error\n                continue\n        return None\n\n    def geocode_multiple(self, addresses: List[str]) -> Dict[str, Optional[Tuple[float, float]]]:\n        \"\"\"\n        Geocode multiple addresses to their corresponding latitude and longitude.\n\n        Args:\n            addresses (List[str]): A list of addresses to geocode.\n\n        Returns:\n            Dict[str, Optional[Tuple[float, float]]]: A dictionary mapping addresses to their coordinates or None if not found.\n        \"\"\"\n        return {address: self.geocode(address) for address in addresses}\n\n\nif __name__ == '__main__':\n    addresses = [\n        '1600 Amphitheatre Parkway, Mountain View, CA',\n        '1 Infinite Loop, Cupertino, CA'\n    ]\n    geocoder = Geocoder()\n    coordinates = geocoder.geocode_multiple(addresses)\n    print(coordinates)",
    "rejected_code": "from geopy.geocoders import Nominatim, GoogleV3\n\nclass Geocoder:\n    def __init__(self):\n        self.geocoders = [Nominatim(user_agent='geoapi'), GoogleV3(api_key='YOUR_API_KEY')]\n\n    def geocode(self, address):\n        for geocoder in self.geocoders:\n            try:\n                location = geocoder.geocode(address)\n                if location:\n                    return (location.latitude, location.longitude)\n            except Exception:\n                continue\n        return None\n\naddresses = ['1600 Amphitheatre Parkway, Mountain View, CA', '1 Infinite Loop, Cupertino, CA']\ngeocoder = Geocoder()\ncoordinates = {address: geocoder.geocode(address) for address in addresses}\nprint(coordinates)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.5,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 2, in <module>\nModuleNotFoundError: No module named 'geopy'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 3.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopy'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Implement a map projection conversion function with accuracy metrics",
    "code_form": "converter function",
    "prompt_type": "default",
    "prompt": {
      "content": "Please provide code to convert geographic coordinates from WGS84 to UTM Zone 33N and calculate accuracy metrics.",
      "role": "user"
    },
    "chosen_code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom pyproj import Proj, transform\nfrom typing import List, Tuple\n\n\ndef convert_coordinates(coords: List[Tuple[float, float]]) -> List[Tuple[float, float]]:\n    \"\"\"\n    Convert geographic coordinates from WGS84 to UTM Zone 33N.\n\n    Args:\n        coords (List[Tuple[float, float]]): A list of tuples containing latitude and longitude in WGS84.\n\n    Returns:\n        List[Tuple[float, float]]: A list of tuples containing the converted coordinates in UTM Zone 33N.\n    \"\"\"\n    # Define the projection for WGS84 and UTM Zone 33N\n    wgs84 = Proj('EPSG:4326')\n    utm = Proj('EPSG:32633')\n    projected_coords = []\n\n    # Transform each coordinate from WGS84 to UTM\n    for coord in coords:\n        x, y = transform(wgs84, utm, coord[0], coord[1])\n        projected_coords.append((x, y))\n    return projected_coords\n\n\ndef calculate_accuracy(original_coords: List[Tuple[float, float]], projected_coords: List[Tuple[float, float]]) -> List[float]:\n    \"\"\"\n    Calculate the accuracy of the projected coordinates by measuring distances to original coordinates.\n\n    Args:\n        original_coords (List[Tuple[float, float]]): A list of original coordinates in WGS84.\n        projected_coords (List[Tuple[float, float]]): A list of projected coordinates in UTM.\n\n    Returns:\n        List[float]: A list of distances between original and projected coordinates in meters.\n    \"\"\"\n    distances = []\n\n    # Calculate distances between original and projected points\n    for i in range(len(original_coords)):\n        original_point = Point(original_coords[i])\n        projected_point = Point(projected_coords[i])\n        distances.append(original_point.distance(projected_point))\n    return distances\n\n\n# Example usage\noriginal_coordinates: List[Tuple[float, float]] = [(13.4050, 52.5200), (13.4055, 52.5205)]\nprojected_coordinates: List[Tuple[float, float]] = convert_coordinates(original_coordinates)\naccuracy_metrics: List[float] = calculate_accuracy(original_coordinates, projected_coordinates)\n\n# Print the results\nprint('Projected Coordinates:', projected_coordinates)\nprint('Accuracy Metrics (Distances in meters):', accuracy_metrics)",
    "rejected_code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom pyproj import Proj, transform\n\ndef convert_coordinates(coords):\n    wgs84 = Proj('EPSG:4326')\n    utm = Proj('EPSG:32633')\n    projected_coords = []\n    for coord in coords:\n        x, y = transform(wgs84, utm, coord[0], coord[1])\n        projected_coords.append((x, y))\n    return projected_coords\n\ndef calculate_accuracy(original_coords, projected_coords):\n    distances = []\n    for i in range(len(original_coords)):\n        original_point = Point(original_coords[i])\n        projected_point = Point(projected_coords[i])\n        distances.append(original_point.distance(projected_point))\n    return distances\n\noriginal_coordinates = [(13.4050, 52.5200), (13.4055, 52.5205)]\nprojected_coordinates = convert_coordinates(original_coordinates)\naccuracy_metrics = calculate_accuracy(original_coordinates, projected_coordinates)\nprint('Projected Coordinates:', projected_coordinates)\nprint('Accuracy Metrics (Distances in meters):', accuracy_metrics)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.08771929824561403,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Implement a map projection conversion function with accuracy metrics",
    "code_form": "converter function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you provide a function to convert geographic coordinates from WGS84 to UTM Zone 33N and calculate accuracy metrics?",
      "role": "user"
    },
    "chosen_code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom pyproj import Proj, transform\nfrom typing import List, Tuple\n\n\ndef convert_coordinates(coords: List[Tuple[float, float]]) -> List[Tuple[float, float]]:\n    \"\"\"\n    Convert geographic coordinates from WGS84 to UTM Zone 33N.\n\n    Args:\n        coords (List[Tuple[float, float]]): A list of tuples containing latitude and longitude in WGS84.\n\n    Returns:\n        List[Tuple[float, float]]: A list of tuples containing the converted coordinates in UTM Zone 33N.\n    \"\"\"\n    # Define the projection for WGS84 and UTM Zone 33N\n    wgs84 = Proj('EPSG:4326')\n    utm = Proj('EPSG:32633')\n    projected_coords = []\n\n    # Transform each coordinate from WGS84 to UTM\n    for coord in coords:\n        x, y = transform(wgs84, utm, coord[0], coord[1])\n        projected_coords.append((x, y))\n    return projected_coords\n\n\ndef calculate_accuracy(original_coords: List[Tuple[float, float]], projected_coords: List[Tuple[float, float]]) -> List[float]:\n    \"\"\"\n    Calculate the accuracy of the projected coordinates by measuring distances to original coordinates.\n\n    Args:\n        original_coords (List[Tuple[float, float]]): A list of original coordinates in WGS84.\n        projected_coords (List[Tuple[float, float]]): A list of projected coordinates in UTM.\n\n    Returns:\n        List[float]: A list of distances between original and projected coordinates in meters.\n    \"\"\"\n    distances = []\n\n    # Calculate distances between original and projected points\n    for i in range(len(original_coords)):\n        original_point = Point(original_coords[i])\n        projected_point = Point(projected_coords[i])\n        distances.append(original_point.distance(projected_point))\n    return distances\n\n\n# Example usage\noriginal_coordinates: List[Tuple[float, float]] = [(13.4050, 52.5200), (13.4055, 52.5205)]\nprojected_coordinates: List[Tuple[float, float]] = convert_coordinates(original_coordinates)\naccuracy_metrics: List[float] = calculate_accuracy(original_coordinates, projected_coordinates)\n\n# Print the results\nprint('Projected Coordinates:', projected_coordinates)\nprint('Accuracy Metrics (Distances in meters):', accuracy_metrics)",
    "rejected_code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom pyproj import Proj, transform\n\ndef convert_coordinates(coords):\n    wgs84 = Proj('EPSG:4326')\n    utm = Proj('EPSG:32633')\n    projected_coords = []\n    for coord in coords:\n        x, y = transform(wgs84, utm, coord[0], coord[1])\n        projected_coords.append((x, y))\n    return projected_coords\n\ndef calculate_accuracy(original_coords, projected_coords):\n    distances = []\n    for i in range(len(original_coords)):\n        original_point = Point(original_coords[i])\n        projected_point = Point(projected_coords[i])\n        distances.append(original_point.distance(projected_point))\n    return distances\n\noriginal_coordinates = [(13.4050, 52.5200), (13.4055, 52.5205)]\nprojected_coordinates = convert_coordinates(original_coordinates)\naccuracy_metrics = calculate_accuracy(original_coordinates, projected_coordinates)\nprint('Projected Coordinates:', projected_coordinates)\nprint('Accuracy Metrics (Distances in meters):', accuracy_metrics)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.08771929824561403,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Implement a map projection conversion function with accuracy metrics",
    "code_form": "converter function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Write a function that takes a list of geographic coordinates in WGS84 and returns their converted coordinates in UTM Zone 33N along with accuracy metrics, specifying input and output types.",
      "role": "user"
    },
    "chosen_code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom pyproj import Proj, transform\nfrom typing import List, Tuple\n\n\ndef convert_coordinates(coords: List[Tuple[float, float]]) -> List[Tuple[float, float]]:\n    \"\"\"\n    Convert geographic coordinates from WGS84 to UTM Zone 33N.\n\n    Args:\n        coords (List[Tuple[float, float]]): A list of tuples containing latitude and longitude in WGS84.\n\n    Returns:\n        List[Tuple[float, float]]: A list of tuples containing the converted coordinates in UTM Zone 33N.\n    \"\"\"\n    # Define the projection for WGS84 and UTM Zone 33N\n    wgs84 = Proj('EPSG:4326')\n    utm = Proj('EPSG:32633')\n    projected_coords = []\n\n    # Transform each coordinate from WGS84 to UTM\n    for coord in coords:\n        x, y = transform(wgs84, utm, coord[0], coord[1])\n        projected_coords.append((x, y))\n    return projected_coords\n\n\ndef calculate_accuracy(original_coords: List[Tuple[float, float]], projected_coords: List[Tuple[float, float]]) -> List[float]:\n    \"\"\"\n    Calculate the accuracy of the projected coordinates by measuring distances to original coordinates.\n\n    Args:\n        original_coords (List[Tuple[float, float]]): A list of original coordinates in WGS84.\n        projected_coords (List[Tuple[float, float]]): A list of projected coordinates in UTM.\n\n    Returns:\n        List[float]: A list of distances between original and projected coordinates in meters.\n    \"\"\"\n    distances = []\n\n    # Calculate distances between original and projected points\n    for i in range(len(original_coords)):\n        original_point = Point(original_coords[i])\n        projected_point = Point(projected_coords[i])\n        distances.append(original_point.distance(projected_point))\n    return distances\n\n\n# Example usage\noriginal_coordinates: List[Tuple[float, float]] = [(13.4050, 52.5200), (13.4055, 52.5205)]\nprojected_coordinates: List[Tuple[float, float]] = convert_coordinates(original_coordinates)\naccuracy_metrics: List[float] = calculate_accuracy(original_coordinates, projected_coordinates)\n\n# Print the results\nprint('Projected Coordinates:', projected_coordinates)\nprint('Accuracy Metrics (Distances in meters):', accuracy_metrics)",
    "rejected_code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom pyproj import Proj, transform\n\ndef convert_coordinates(coords):\n    wgs84 = Proj('EPSG:4326')\n    utm = Proj('EPSG:32633')\n    projected_coords = []\n    for coord in coords:\n        x, y = transform(wgs84, utm, coord[0], coord[1])\n        projected_coords.append((x, y))\n    return projected_coords\n\ndef calculate_accuracy(original_coords, projected_coords):\n    distances = []\n    for i in range(len(original_coords)):\n        original_point = Point(original_coords[i])\n        projected_point = Point(projected_coords[i])\n        distances.append(original_point.distance(projected_point))\n    return distances\n\noriginal_coordinates = [(13.4050, 52.5200), (13.4055, 52.5205)]\nprojected_coordinates = convert_coordinates(original_coordinates)\naccuracy_metrics = calculate_accuracy(original_coordinates, projected_coordinates)\nprint('Projected Coordinates:', projected_coordinates)\nprint('Accuracy Metrics (Distances in meters):', accuracy_metrics)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.08771929824561403,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'geopandas'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Develop a route optimization function with constraints",
    "code_form": "utility function",
    "prompt_type": "default",
    "prompt": {
      "content": "Can you provide Python code to optimize delivery routes for a company considering constraints like avoiding toll roads and minimizing travel time?",
      "role": "user"
    },
    "chosen_code": "import osmnx as ox\nimport networkx as nx\nfrom typing import List, Optional, Tuple\n\n\ndef optimize_route(start_point: Tuple[float, float],\n                   end_point: Tuple[float, float],\n                   max_distance: float) -> Optional[List[int]]:\n    \"\"\"\n    Optimizes the delivery route from a starting point to an endpoint while considering\n    constraints such as maximum distance.\n\n    Args:\n        start_point (Tuple[float, float]): A tuple representing the latitude and longitude\n            of the starting point.\n        end_point (Tuple[float, float]): A tuple representing the latitude and longitude\n            of the endpoint.\n        max_distance (float): The maximum allowable distance for the route in meters.\n\n    Returns:\n        Optional[List[int]]: A list of node IDs representing the optimal route, or None\n            if no valid route exists within the maximum distance.\n    \"\"\"\n    # Fetch the road network for the specified area\n    G = ox.graph_from_place('Downtown, City, Country', network_type='drive')\n    G = ox.add_edge_speeds(G)  # Add speed information to edges\n    G = ox.add_edge_travel_times(G)  # Add travel time information to edges\n\n    # Find the nearest nodes to the start and end points\n    start_node = ox.distance.nearest_nodes(G, start_point[0], start_point[1])\n    end_node = ox.distance.nearest_nodes(G, end_point[0], end_point[1])\n\n    # Calculate the shortest path based on travel time\n    route = nx.shortest_path(G, start_node, end_node, weight='travel_time')\n    # Calculate the total length of the route\n    route_length = nx.path_weight(G, route, weight='length')\n\n    # Check if the route length exceeds the maximum distance\n    if route_length > max_distance:\n        return None  # Return None if the route is too long\n\n    return route  # Return the optimal route as a list of node IDs\n\n\n# Example usage\nif __name__ == '__main__':\n    start = (-122.4194, 37.7749)  # Starting point (longitude, latitude)\n    end = (-122.4294, 37.7799)    # Ending point (longitude, latitude)\n    max_dist = 5000                # Maximum distance in meters\n    optimal_route = optimize_route(start, end, max_dist)\n    print(optimal_route)  # Print the optimal route or None if not found",
    "rejected_code": "import osmnx as ox\nimport networkx as nx\n\ndef optimize_route(start_point, end_point, max_distance):\n    G = ox.graph_from_place('Downtown, City, Country', network_type='drive')\n    G = ox.add_edge_speeds(G)\n    G = ox.add_edge_travel_times(G)\n    start_node = ox.distance.nearest_nodes(G, start_point[0], start_point[1])\n    end_node = ox.distance.nearest_nodes(G, end_point[0], end_point[1])\n    route = nx.shortest_path(G, start_node, end_node, weight='travel_time')\n    route_length = nx.path_weight(G, route, weight='length')\n    if route_length > max_distance:\n        return None\n    return route\n\nstart = (-122.4194, 37.7749)\nend = (-122.4294, 37.7799)\nmax_dist = 5000\noptimal_route = optimize_route(start, end, max_dist)\nprint(optimal_route)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.11764705882352941,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'osmnx'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'osmnx'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Develop a route optimization function with constraints",
    "code_form": "utility function",
    "prompt_type": "code_form",
    "prompt": {
      "content": "Can you provide a Python function to optimize delivery routes for a company considering constraints like avoiding toll roads and minimizing travel time?",
      "role": "user"
    },
    "chosen_code": "import osmnx as ox\nimport networkx as nx\nfrom typing import List, Optional, Tuple\n\n\ndef optimize_route(start_point: Tuple[float, float],\n                   end_point: Tuple[float, float],\n                   max_distance: float) -> Optional[List[int]]:\n    \"\"\"\n    Optimizes the delivery route from a starting point to an endpoint while considering\n    constraints such as maximum distance.\n\n    Args:\n        start_point (Tuple[float, float]): A tuple representing the latitude and longitude\n            of the starting point.\n        end_point (Tuple[float, float]): A tuple representing the latitude and longitude\n            of the endpoint.\n        max_distance (float): The maximum allowable distance for the route in meters.\n\n    Returns:\n        Optional[List[int]]: A list of node IDs representing the optimal route, or None\n            if no valid route exists within the maximum distance.\n    \"\"\"\n    # Fetch the road network for the specified area\n    G = ox.graph_from_place('Downtown, City, Country', network_type='drive')\n    G = ox.add_edge_speeds(G)  # Add speed information to edges\n    G = ox.add_edge_travel_times(G)  # Add travel time information to edges\n\n    # Find the nearest nodes to the start and end points\n    start_node = ox.distance.nearest_nodes(G, start_point[0], start_point[1])\n    end_node = ox.distance.nearest_nodes(G, end_point[0], end_point[1])\n\n    # Calculate the shortest path based on travel time\n    route = nx.shortest_path(G, start_node, end_node, weight='travel_time')\n    # Calculate the total length of the route\n    route_length = nx.path_weight(G, route, weight='length')\n\n    # Check if the route length exceeds the maximum distance\n    if route_length > max_distance:\n        return None  # Return None if the route is too long\n\n    return route  # Return the optimal route as a list of node IDs\n\n\n# Example usage\nif __name__ == '__main__':\n    start = (-122.4194, 37.7749)  # Starting point (longitude, latitude)\n    end = (-122.4294, 37.7799)    # Ending point (longitude, latitude)\n    max_dist = 5000                # Maximum distance in meters\n    optimal_route = optimize_route(start, end, max_dist)\n    print(optimal_route)  # Print the optimal route or None if not found",
    "rejected_code": "import osmnx as ox\nimport networkx as nx\n\ndef optimize_route(start_point, end_point, max_distance):\n    G = ox.graph_from_place('Downtown, City, Country', network_type='drive')\n    G = ox.add_edge_speeds(G)\n    G = ox.add_edge_travel_times(G)\n    start_node = ox.distance.nearest_nodes(G, start_point[0], start_point[1])\n    end_node = ox.distance.nearest_nodes(G, end_point[0], end_point[1])\n    route = nx.shortest_path(G, start_node, end_node, weight='travel_time')\n    route_length = nx.path_weight(G, route, weight='length')\n    if route_length > max_distance:\n        return None\n    return route\n\nstart = (-122.4194, 37.7749)\nend = (-122.4294, 37.7799)\nmax_dist = 5000\noptimal_route = optimize_route(start, end, max_dist)\nprint(optimal_route)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.11764705882352941,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'osmnx'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'osmnx'"
      }
    }
  },
  {
    "domain": "geospatial analysis",
    "task": "Develop a route optimization function with constraints",
    "code_form": "utility function",
    "prompt_type": "code_form_types",
    "prompt": {
      "content": "Can you provide a Python function that takes two tuples for start and end points and a float for the maximum distance, and returns a list of node IDs or None?",
      "role": "user"
    },
    "chosen_code": "import osmnx as ox\nimport networkx as nx\nfrom typing import List, Optional, Tuple\n\n\ndef optimize_route(start_point: Tuple[float, float],\n                   end_point: Tuple[float, float],\n                   max_distance: float) -> Optional[List[int]]:\n    \"\"\"\n    Optimizes the delivery route from a starting point to an endpoint while considering\n    constraints such as maximum distance.\n\n    Args:\n        start_point (Tuple[float, float]): A tuple representing the latitude and longitude\n            of the starting point.\n        end_point (Tuple[float, float]): A tuple representing the latitude and longitude\n            of the endpoint.\n        max_distance (float): The maximum allowable distance for the route in meters.\n\n    Returns:\n        Optional[List[int]]: A list of node IDs representing the optimal route, or None\n            if no valid route exists within the maximum distance.\n    \"\"\"\n    # Fetch the road network for the specified area\n    G = ox.graph_from_place('Downtown, City, Country', network_type='drive')\n    G = ox.add_edge_speeds(G)  # Add speed information to edges\n    G = ox.add_edge_travel_times(G)  # Add travel time information to edges\n\n    # Find the nearest nodes to the start and end points\n    start_node = ox.distance.nearest_nodes(G, start_point[0], start_point[1])\n    end_node = ox.distance.nearest_nodes(G, end_point[0], end_point[1])\n\n    # Calculate the shortest path based on travel time\n    route = nx.shortest_path(G, start_node, end_node, weight='travel_time')\n    # Calculate the total length of the route\n    route_length = nx.path_weight(G, route, weight='length')\n\n    # Check if the route length exceeds the maximum distance\n    if route_length > max_distance:\n        return None  # Return None if the route is too long\n\n    return route  # Return the optimal route as a list of node IDs\n\n\n# Example usage\nif __name__ == '__main__':\n    start = (-122.4194, 37.7749)  # Starting point (longitude, latitude)\n    end = (-122.4294, 37.7799)    # Ending point (longitude, latitude)\n    max_dist = 5000                # Maximum distance in meters\n    optimal_route = optimize_route(start, end, max_dist)\n    print(optimal_route)  # Print the optimal route or None if not found",
    "rejected_code": "import osmnx as ox\nimport networkx as nx\n\ndef optimize_route(start_point, end_point, max_distance):\n    G = ox.graph_from_place('Downtown, City, Country', network_type='drive')\n    G = ox.add_edge_speeds(G)\n    G = ox.add_edge_travel_times(G)\n    start_node = ox.distance.nearest_nodes(G, start_point[0], start_point[1])\n    end_node = ox.distance.nearest_nodes(G, end_point[0], end_point[1])\n    route = nx.shortest_path(G, start_node, end_node, weight='travel_time')\n    route_length = nx.path_weight(G, route, weight='length')\n    if route_length > max_distance:\n        return None\n    return route\n\nstart = (-122.4194, 37.7749)\nend = (-122.4294, 37.7799)\nmax_dist = 5000\noptimal_route = optimize_route(start, end, max_dist)\nprint(optimal_route)",
    "chosen_metrics": {
      "type_annotation_coverage": 1.0,
      "docstring_coverage": 1.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.11764705882352941,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'osmnx'"
      }
    },
    "rejected_metrics": {
      "type_annotation_coverage": 0.0,
      "docstring_coverage": 0.0,
      "code_complexity": 2.0,
      "pep8_compliance": null,
      "comment_density": 0.0,
      "execution_result": {
        "success": false,
        "output": "",
        "error": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'osmnx'"
      }
    }
  }
]